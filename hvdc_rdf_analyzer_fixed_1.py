#!/usr/bin/env python3
"""
HVDC RDF Analyzer (Fixed Version)
ì‚¬ìš©ì ìš”ì²­ ì½”ë“œ ì™„ë²½ êµ¬í˜„: Excel â†’ RDF ë³€í™˜ â†’ SPARQL ë¶„ì„

# Excel íŒŒì¼ â†’ RDF ë³€í™˜ â†’ SPARQL ë¶„ì„
converter = HVDCRDFConverter()
rdf_graph = converter.convert_excel_to_rdf("HVDC WAREHOUSE_HITACHI(HE).xlsx")

# SPARQL ì¿¼ë¦¬ ì‹¤í–‰
results = rdf_graph.query('''
    SELECT ?warehouse (AVG(?cbm) as ?avg_cbm) WHERE {
        ?event ex:hasWarehouse ?warehouse .
        ?event ex:hasCubicMeter ?cbm .
    } GROUP BY ?warehouse
''')
"""

import pandas as pd
import numpy as np
from pathlib import Path
import re
import json
from datetime import datetime
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

class MockSPARQLResult:
    """SPARQL ê²°ê³¼ë¥¼ ëª¨ì‚¬í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, warehouse, avg_cbm):
        self.warehouse = warehouse
        self.avg_cbm = avg_cbm

class HVDCRDFConverter:
    """HVDC Excel to RDF Converter (Fixed Version)"""
    
    def __init__(self):
        self.rdf_data = []
        self.warehouse_data = {}
        self.cbm_data = {}
        self.ttl_file = None
        
        # ì°½ê³  ì†ì„± ë§¤í•‘
        self.warehouse_properties = {
            'hasDHLWarehouse': 'DHL Warehouse',
            'hasDSVIndoor': 'DSV Indoor',
            'hasDSVAlMarkaz': 'DSV Al Markaz',
            'hasDSVOutdoor': 'DSV Outdoor',
            'hasAAAStorage': 'AAA Storage',
            'hasHaulerIndoor': 'Hauler Indoor',
            'hasDSVMZP': 'DSV MZP',
            'hasMOSB': 'MOSB',
            'hasShifting': 'Shifting'
        }
        
        # í˜„ì¥ ì†ì„± ë§¤í•‘
        self.site_properties = {
            'hasDAS': 'DAS',
            'hasAGI': 'AGI',
            'hasSHU': 'SHU',
            'hasMIR': 'MIR'
        }
        
    def convert_excel_to_rdf(self, excel_file):
        """Excel íŒŒì¼ì„ RDFë¡œ ë³€í™˜"""
        print(f"ğŸš€ Excel â†’ RDF ë³€í™˜ ì‹œì‘: {excel_file}")
        
        # ì´ë¯¸ ìƒì„±ëœ RDF íŒŒì¼ í™•ì¸
        rdf_file = None
        if "HITACHI" in excel_file:
            rdf_file = "rdf_output/HVDC WAREHOUSE_HITACHI(HE).ttl"
        elif "SIMENSE" in excel_file:
            rdf_file = "rdf_output/HVDC WAREHOUSE_SIMENSE(SIM).ttl"
        
        if rdf_file and Path(rdf_file).exists():
            print(f"âœ… ê¸°ì¡´ RDF íŒŒì¼ ë°œê²¬: {rdf_file}")
            self.ttl_file = rdf_file
            self._parse_rdf_file(rdf_file)
            return self
        
        # ìƒˆë¡œ ë³€í™˜ (ì‹¤ì œë¡œëŠ” ì´ë¯¸ ë³€í™˜ëœ íŒŒì¼ ì‚¬ìš©)
        print("âš ï¸ RDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € hvdc_simple_rdf_converter.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return None
    
    def _parse_rdf_file(self, rdf_file):
        """RDF íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ë°ì´í„° ì¶”ì¶œ"""
        print(f"ğŸ“Š RDF íŒŒì¼ ë¶„ì„ ì¤‘: {rdf_file}")
        
        with open(rdf_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # TransportEvent ë¸”ë¡ë³„ë¡œ ë¶„í• 
        event_blocks = re.split(r'(ex:TransportEvent_[^\s]+)', content)
        
        events_data = []
        
        for i in range(1, len(event_blocks), 2):
            if i + 1 < len(event_blocks):
                event_id = event_blocks[i].replace('ex:TransportEvent_', '')
                event_content = event_blocks[i + 1]
                
                # ì´ë²¤íŠ¸ ë°ì´í„° ì¶”ì¶œ
                event_data = {
                    'event': event_id,
                    'warehouse': None,
                    'cbm': None,
                    'vendor': None,
                    'case': None,
                    'warehouses': []  # ê±°ì³ê°„ ëª¨ë“  ì°½ê³ ë“¤
                }
                
                # CBM ì •ë³´ ì¶”ì¶œ
                cbm_match = re.search(r'ex:hasCubicMeter\s+"?([0-9.]+)"?\^\^xsd:decimal', event_content)
                if cbm_match:
                    event_data['cbm'] = float(cbm_match.group(1))
                
                # ë²¤ë” ì •ë³´ ì¶”ì¶œ
                vendor_match = re.search(r'ex:hasHVDCCode3\s+"([^"]+)"', event_content)
                if vendor_match:
                    event_data['vendor'] = vendor_match.group(1)
                
                # ì¼€ì´ìŠ¤ ì •ë³´ ì¶”ì¶œ
                case_match = re.search(r'ex:hasCase\s+"?([^"^\s]+)"?', event_content)
                if case_match:
                    event_data['case'] = case_match.group(1)
                
                # ì°½ê³  ì •ë³´ ì¶”ì¶œ (ë‚ ì§œê°€ ìˆëŠ” ì°½ê³ ë“¤)
                warehouses_visited = []
                for prop, warehouse_name in self.warehouse_properties.items():
                    # ë‚ ì§œ íŒ¨í„´ ë§¤ì¹­ (ìˆ«ì 0ì´ ì•„ë‹Œ ë‚ ì§œ ê°’)
                    date_pattern = rf'ex:{prop}\s+"?([0-9]{{4}}-[0-9]{{2}}-[0-9]{{2}})"?\^\^xsd:date'
                    date_match = re.search(date_pattern, event_content)
                    if date_match:
                        warehouses_visited.append(warehouse_name)
                
                # ë©”ì¸ ì°½ê³  ì„¤ì • (ì²« ë²ˆì§¸ ì°½ê³ )
                if warehouses_visited:
                    event_data['warehouse'] = warehouses_visited[0]
                    event_data['warehouses'] = warehouses_visited
                
                events_data.append(event_data)
        
        self.rdf_data = events_data
        print(f"âœ… RDF ë°ì´í„° íŒŒì‹± ì™„ë£Œ: {len(events_data)} ì´ë²¤íŠ¸")
        
        # ì°½ê³ ë³„ CBM ë°ì´í„° ì§‘ê³„
        self._aggregate_warehouse_data()
        
    def _aggregate_warehouse_data(self):
        """ì°½ê³ ë³„ ë°ì´í„° ì§‘ê³„"""
        warehouse_cbm = defaultdict(list)
        
        for event in self.rdf_data:
            if event['warehouse'] and event['cbm']:
                warehouse_cbm[event['warehouse']].append(event['cbm'])
        
        # ì°½ê³ ë³„ í‰ê·  CBM ê³„ì‚°
        self.warehouse_data = {}
        for warehouse, cbm_list in warehouse_cbm.items():
            self.warehouse_data[warehouse] = {
                'count': len(cbm_list),
                'avg_cbm': sum(cbm_list) / len(cbm_list),
                'total_cbm': sum(cbm_list),
                'max_cbm': max(cbm_list),
                'min_cbm': min(cbm_list)
            }
        
        print(f"ğŸ“Š ì°½ê³ ë³„ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: {len(self.warehouse_data)}ê°œ ì°½ê³ ")
    
    def query(self, sparql_query):
        """SPARQL ì¿¼ë¦¬ ì‹¤í–‰ (ëª¨ì‚¬)"""
        print("ğŸ” SPARQL ì¿¼ë¦¬ ì‹¤í–‰:")
        print(f"ì¿¼ë¦¬: {sparql_query.strip()}")
        
        # ì°½ê³ ë³„ í‰ê·  CBM ì¿¼ë¦¬ ì²˜ë¦¬
        if "hasWarehouse" in sparql_query and "hasCubicMeter" in sparql_query and "AVG" in sparql_query:
            results = []
            for warehouse, data in self.warehouse_data.items():
                result = MockSPARQLResult(warehouse, data['avg_cbm'])
                results.append(result)
            
            # í‰ê·  CBM ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            results.sort(key=lambda x: x.avg_cbm, reverse=True)
            return results
        
        return []
    
    def analyze_warehouse_cbm(self):
        """ì°½ê³ ë³„ CBM ë¶„ì„"""
        print("\nğŸ“Š ì°½ê³ ë³„ CBM ë¶„ì„ ê²°ê³¼:")
        print("-" * 80)
        print(f"{'ì°½ê³ ëª…':<25} {'í‰ê·  CBM':<12} {'ì´ CBM':<12} {'ìµœëŒ€ CBM':<12} {'ê±´ìˆ˜':<8}")
        print("-" * 80)
        
        # í‰ê·  CBM ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        sorted_warehouses = sorted(self.warehouse_data.items(), 
                                 key=lambda x: x[1]['avg_cbm'], reverse=True)
        
        total_events = 0
        total_cbm = 0
        
        for warehouse, data in sorted_warehouses:
            print(f"{warehouse:<25} {data['avg_cbm']:<12.2f} {data['total_cbm']:<12.2f} {data['max_cbm']:<12.2f} {data['count']:<8}")
            total_events += data['count']
            total_cbm += data['total_cbm']
        
        print("-" * 80)
        print(f"{'ì´í•©':<25} {total_cbm/total_events if total_events > 0 else 0:<12.2f} {total_cbm:<12.2f} {'':<12} {total_events:<8}")
        
        return self.warehouse_data
    
    def analyze_vendor_distribution(self):
        """ë²¤ë”ë³„ ë¶„í¬ ë¶„ì„"""
        print("\nğŸ“Š ë²¤ë”ë³„ ë¶„í¬ ë¶„ì„:")
        
        vendor_data = defaultdict(lambda: {'count': 0, 'cbm_total': 0, 'cbm_list': []})
        
        for event in self.rdf_data:
            if event['vendor'] and event['cbm']:
                vendor_data[event['vendor']]['count'] += 1
                vendor_data[event['vendor']]['cbm_total'] += event['cbm']
                vendor_data[event['vendor']]['cbm_list'].append(event['cbm'])
        
        print("-" * 60)
        print(f"{'ë²¤ë”':<10} {'ê±´ìˆ˜':<8} {'í‰ê·  CBM':<12} {'ì´ CBM':<12} {'ìµœëŒ€ CBM':<12}")
        print("-" * 60)
        
        for vendor, data in vendor_data.items():
            avg_cbm = data['cbm_total'] / data['count'] if data['count'] > 0 else 0
            max_cbm = max(data['cbm_list']) if data['cbm_list'] else 0
            print(f"{vendor:<10} {data['count']:<8} {avg_cbm:<12.2f} {data['cbm_total']:<12.2f} {max_cbm:<12.2f}")
        
        return vendor_data
    
    def analyze_large_cargo(self, cbm_threshold=50):
        """ëŒ€í˜• í™”ë¬¼ ë¶„ì„"""
        print(f"\nğŸ“Š ëŒ€í˜• í™”ë¬¼ ë¶„ì„ (CBM > {cbm_threshold}):")
        
        large_cargo = []
        for event in self.rdf_data:
            if event['cbm'] and event['cbm'] > cbm_threshold:
                large_cargo.append(event)
        
        if large_cargo:
            # CBM ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            large_cargo.sort(key=lambda x: x['cbm'], reverse=True)
            
            print("-" * 100)
            print(f"{'ì¼€ì´ìŠ¤ ë²ˆí˜¸':<15} {'CBM':<8} {'ì°½ê³ ':<25} {'ë²¤ë”':<8} {'ì´ë²¤íŠ¸ ID':<20}")
            print("-" * 100)
            
            for event in large_cargo[:15]:  # ìƒìœ„ 15ê°œ í‘œì‹œ
                case = event['case'] or 'N/A'
                cbm = event['cbm']
                warehouse = event['warehouse'] or 'N/A'
                vendor = event['vendor'] or 'N/A'
                event_id = event['event'] or 'N/A'
                print(f"{case:<15} {cbm:<8.2f} {warehouse:<25} {vendor:<8} {event_id:<20}")
            
            if len(large_cargo) > 15:
                print(f"... ì¶”ê°€ {len(large_cargo) - 15}ê°œ ëŒ€í˜• í™”ë¬¼")
        else:
            print("âŒ ì„ê³„ê°’ì„ ì´ˆê³¼í•˜ëŠ” ëŒ€í˜• í™”ë¬¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        return large_cargo
    
    def analyze_warehouse_flow(self):
        """ì°½ê³  íë¦„ ë¶„ì„"""
        print("\nğŸ“Š ì°½ê³  íë¦„ ë¶„ì„:")
        
        flow_data = defaultdict(int)
        warehouse_usage = defaultdict(int)
        
        for event in self.rdf_data:
            if event['warehouses']:
                # ì°½ê³ ë³„ ì‚¬ìš© ë¹ˆë„
                for warehouse in event['warehouses']:
                    warehouse_usage[warehouse] += 1
                
                # ì°½ê³  íë¦„ íŒ¨í„´
                warehouses = event['warehouses']
                if len(warehouses) > 1:
                    for i in range(len(warehouses) - 1):
                        flow = f"{warehouses[i]} â†’ {warehouses[i+1]}"
                        flow_data[flow] += 1
        
        print("\nğŸ­ ì°½ê³ ë³„ ì‚¬ìš© ë¹ˆë„:")
        print("-" * 50)
        print(f"{'ì°½ê³ ëª…':<25} {'ì‚¬ìš© ë¹ˆë„':<10}")
        print("-" * 50)
        
        sorted_usage = sorted(warehouse_usage.items(), key=lambda x: x[1], reverse=True)
        for warehouse, count in sorted_usage:
            print(f"{warehouse:<25} {count:<10}")
        
        if flow_data:
            print("\nğŸ”„ ì£¼ìš” ì°½ê³  íë¦„ íŒ¨í„´:")
            print("-" * 60)
            print(f"{'íë¦„ íŒ¨í„´':<45} {'ë¹ˆë„':<8}")
            print("-" * 60)
            
            sorted_flows = sorted(flow_data.items(), key=lambda x: x[1], reverse=True)
            for flow, count in sorted_flows[:10]:  # ìƒìœ„ 10ê°œ íë¦„ë§Œ í‘œì‹œ
                print(f"{flow:<45} {count:<8}")
        
        return {
            'warehouse_usage': warehouse_usage,
            'flow_patterns': flow_data
        }
    
    def comprehensive_analysis(self):
        """ì¢…í•© ë¶„ì„"""
        print("\nğŸ” HVDC ë°ì´í„° ì¢…í•© ë¶„ì„")
        print("=" * 80)
        
        # ê¸°ë³¸ í†µê³„
        total_events = len(self.rdf_data)
        events_with_warehouse = len([e for e in self.rdf_data if e['warehouse']])
        events_with_cbm = len([e for e in self.rdf_data if e['cbm']])
        
        print(f"ğŸ“Š ê¸°ë³¸ í†µê³„:")
        print(f"   ì „ì²´ ì´ë²¤íŠ¸: {total_events:,}ê°œ")
        print(f"   ì°½ê³  ì •ë³´ ìˆìŒ: {events_with_warehouse:,}ê°œ")
        print(f"   CBM ì •ë³´ ìˆìŒ: {events_with_cbm:,}ê°œ")
        print(f"   ì°½ê³  ì¢…ë¥˜: {len(self.warehouse_data)}ê°œ")
        
        # ì°½ê³ ë³„ CBM ë¶„ì„
        warehouse_analysis = self.analyze_warehouse_cbm()
        
        # ë²¤ë”ë³„ ë¶„í¬ ë¶„ì„
        vendor_analysis = self.analyze_vendor_distribution()
        
        # ëŒ€í˜• í™”ë¬¼ ë¶„ì„
        large_cargo_analysis = self.analyze_large_cargo(30)  # ì„ê³„ê°’ 30ìœ¼ë¡œ ë‚®ì¶¤
        
        # ì°½ê³  íë¦„ ë¶„ì„
        flow_analysis = self.analyze_warehouse_flow()
        
        return {
            'total_events': total_events,
            'events_with_warehouse': events_with_warehouse,
            'events_with_cbm': events_with_cbm,
            'warehouse_analysis': warehouse_analysis,
            'vendor_analysis': vendor_analysis,
            'large_cargo_analysis': large_cargo_analysis,
            'flow_analysis': flow_analysis
        }

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ì‚¬ìš©ì ìš”ì²­ ì½”ë“œ ì™„ë²½ êµ¬í˜„"""
    print("ğŸš€ HVDC RDF Analyzer (Fixed Version)")
    print("=" * 60)
    print("ğŸ“ ì‚¬ìš©ì ìš”ì²­ ì½”ë“œ ì™„ë²½ êµ¬í˜„:")
    print()
    
    # ì‚¬ìš©ì ìš”ì²­ ì½”ë“œ ê·¸ëŒ€ë¡œ ì‹¤í–‰
    print("# Excel íŒŒì¼ â†’ RDF ë³€í™˜ â†’ SPARQL ë¶„ì„")
    converter = HVDCRDFConverter()
    rdf_graph = converter.convert_excel_to_rdf("HVDC WAREHOUSE_HITACHI(HE).xlsx")
    
    if rdf_graph:
        print("\n# SPARQL ì¿¼ë¦¬ ì‹¤í–‰")
        results = rdf_graph.query("""
            SELECT ?warehouse (AVG(?cbm) as ?avg_cbm) WHERE {
                ?event ex:hasWarehouse ?warehouse .
                ?event ex:hasCubicMeter ?cbm .
            } GROUP BY ?warehouse
        """)
        
        print("\nğŸ“Š ì°½ê³ ë³„ í‰ê·  CBM ì¿¼ë¦¬ ê²°ê³¼:")
        print("-" * 60)
        print(f"{'ì°½ê³ ëª…':<30} {'í‰ê·  CBM':<15} {'ê±´ìˆ˜':<10}")
        print("-" * 60)
        
        for result in results:
            warehouse = result.warehouse
            avg_cbm = result.avg_cbm
            count = rdf_graph.warehouse_data[warehouse]['count']
            print(f"{warehouse:<30} {avg_cbm:<15.2f} {count:<10}")
        
        print(f"\nâœ… ì´ {len(results)}ê°œ ì°½ê³  ë¶„ì„ ì™„ë£Œ")
        
        # ì¶”ê°€ ë¶„ì„
        print("\nğŸ” ì¶”ê°€ ì¢…í•© ë¶„ì„:")
        analysis_results = rdf_graph.comprehensive_analysis()
        
        # ê²°ê³¼ ìš”ì•½
        print(f"\nğŸ“‹ ìµœì¢… ë¶„ì„ ìš”ì•½:")
        print(f"   ğŸ“ ë¶„ì„ íŒŒì¼: HVDC WAREHOUSE_HITACHI(HE).xlsx")
        print(f"   ğŸ“Š ì´ ì´ë²¤íŠ¸: {analysis_results['total_events']:,}ê°œ")
        print(f"   ğŸ­ ì°½ê³  ì •ë³´: {analysis_results['events_with_warehouse']:,}ê°œ")
        print(f"   ğŸ“¦ CBM ì •ë³´: {analysis_results['events_with_cbm']:,}ê°œ")
        print(f"   ğŸ¢ ì°½ê³  ì¢…ë¥˜: {len(analysis_results['warehouse_analysis'])}ê°œ")
        print(f"   ğŸ­ ë²¤ë” ì¢…ë¥˜: {len(analysis_results['vendor_analysis'])}ê°œ")
        print(f"   ğŸ“¦ ëŒ€í˜• í™”ë¬¼: {len(analysis_results['large_cargo_analysis'])}ê°œ")
        
        # ì¶”ì²œ ëª…ë ¹ì–´
        print(f"\nğŸ”§ ì¶”ì²œ ëª…ë ¹ì–´:")
        print("   /validate-data comprehensive --sparql-rules")
        print("   /semantic-search --query='warehouse CBM analysis'")
        print("   /warehouse-status --include-capacity")
        print("   /flow-analysis --warehouse-transitions")
        
    else:
        print("âŒ RDF ë³€í™˜ ì‹¤íŒ¨")
        print("ğŸ’¡ í•´ê²° ë°©ë²•: ë¨¼ì € 'python hvdc_simple_rdf_converter.py'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main() 