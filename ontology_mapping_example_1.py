#!/usr/bin/env python3
"""
HVDC ì˜¨í†¨ë¡œì§€ ë§¤í•‘ ì‹¤í–‰ ì˜ˆì œ
Excel ë°ì´í„°ë¥¼ RDFë¡œ ë³€í™˜í•˜ëŠ” ì™„ì „í•œ ê°€ì´ë“œ
"""

import pandas as pd
import json
from datetime import datetime
from pathlib import Path

def step1_load_mapping_rules():
    """1ë‹¨ê³„: ë§¤í•‘ ê·œì¹™ ë¡œë“œ"""
    print("ğŸ“‹ 1ë‹¨ê³„: ë§¤í•‘ ê·œì¹™ ë¡œë“œ")
    
    try:
        with open('mapping_rules_v2.6.json', 'r', encoding='utf-8') as f:
            rules = json.load(f)
        print("âœ… ë§¤í•‘ ê·œì¹™ ë¡œë“œ ì„±ê³µ")
        return rules
    except FileNotFoundError:
        print("âŒ mapping_rules_v2.6.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

def step2_prepare_sample_data():
    """2ë‹¨ê³„: ìƒ˜í”Œ ë°ì´í„° ì¤€ë¹„"""
    print("\nğŸ“Š 2ë‹¨ê³„: ìƒ˜í”Œ ë°ì´í„° ì¤€ë¹„")
    
    # ìƒ˜í”Œ Excel ë°ì´í„° ìƒì„±
    sample_data = {
        'Case_No': ['HVDC-HE-001', 'HVDC-SIM-002', 'HVDC-HE-003'],
        'Date': ['2024-01-01', '2024-01-02', '2024-01-03'],
        'Qty': [100, 200, 150],
        'Location': ['DSV Indoor', 'DSV Outdoor', 'MOSB'],
        'Vendor': ['HITACHI', 'SIM', 'HITACHI'],
        'Amount': [1000.0, 2000.0, 1500.0],
        'Handling Fee': [50.0, 100.0, 75.0]
    }
    
    df = pd.DataFrame(sample_data)
    print(f"âœ… ìƒ˜í”Œ ë°ì´í„° ìƒì„±: {len(df)}í–‰")
    print(df.head())
    return df

def step3_apply_mapping(df, rules):
    """3ë‹¨ê³„: ë§¤í•‘ ê·œì¹™ ì ìš©"""
    print("\nğŸ”„ 3ë‹¨ê³„: ë§¤í•‘ ê·œì¹™ ì ìš©")
    
    if not rules:
        print("âŒ ë§¤í•‘ ê·œì¹™ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # í•„ë“œ ë§¤í•‘ ì ìš©
    field_map = rules.get('field_map', {})
    mapped_data = []
    
    for idx, row in df.iterrows():
        event = {}
        for excel_col, rdf_prop in field_map.items():
            if excel_col in row and pd.notna(row[excel_col]):
                event[rdf_prop] = row[excel_col]
        
        # ì°½ê³  ë¶„ë¥˜ ì¶”ê°€
        location = row.get('Location', '')
        warehouse_class = get_warehouse_class(location, rules)
        event['warehouse_class'] = warehouse_class
        
        mapped_data.append(event)
    
    print(f"âœ… ë§¤í•‘ ì™„ë£Œ: {len(mapped_data)}ê°œ ì´ë²¤íŠ¸")
    return mapped_data

def get_warehouse_class(location, rules):
    """ì°½ê³  ë¶„ë¥˜ ê²°ì •"""
    warehouse_classification = rules.get('warehouse_classification', {})
    
    for storage_type, warehouses in warehouse_classification.items():
        if location in warehouses:
            if storage_type == 'Indoor':
                return 'IndoorWarehouse'
            elif storage_type == 'Outdoor':
                return 'OutdoorWarehouse'
            elif storage_type == 'Site':
                return 'Site'
            elif storage_type == 'dangerous_cargo':
                return 'DangerousCargoWarehouse'
    
    return 'Warehouse'  # ê¸°ë³¸ê°’

def step4_generate_rdf(mapped_data, rules):
    """4ë‹¨ê³„: RDF/TTL ìƒì„±"""
    print("\nğŸ”— 4ë‹¨ê³„: RDF/TTL ìƒì„±")
    
    if not mapped_data or not rules:
        print("âŒ ë§¤í•‘ëœ ë°ì´í„° ë˜ëŠ” ê·œì¹™ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    namespace = rules.get('namespace', 'http://samsung.com/project-logistics#')
    
    # TTL í—¤ë”
    ttl_content = f"""# HVDC Warehouse Ontology RDF
# Generated: {datetime.now().isoformat()}

@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .
@prefix ex: <{namespace}> .

"""
    
    # ì´ë²¤íŠ¸ ë°ì´í„° ë³€í™˜
    for idx, event in enumerate(mapped_data, 1):
        event_id = f"TransportEvent_{idx:05d}"
        ttl_content += f"ex:{event_id} a ex:TransportEvent ;\n"
        
        for prop, value in event.items():
            if prop == 'warehouse_class':
                continue
                
            # ë°ì´í„° íƒ€ì… ê²°ì •
            if prop in ['hasQuantity']:
                ttl_content += f'    ex:{prop} "{value}"^^xsd:integer ;\n'
            elif prop in ['hasAmount', 'hasHandlingFee']:
                ttl_content += f'    ex:{prop} "{value}"^^xsd:decimal ;\n'
            elif prop in ['hasDate']:
                ttl_content += f'    ex:{prop} "{value}"^^xsd:date ;\n'
            else:
                ttl_content += f'    ex:{prop} "{value}" ;\n'
        
        ttl_content = ttl_content.rstrip(';\n') + ' .\n\n'
    
    # ì°½ê³  ì¸ìŠ¤í„´ìŠ¤ ì¶”ê°€
    warehouse_classification = rules.get('warehouse_classification', {})
    for storage_type, warehouses in warehouse_classification.items():
        for warehouse in warehouses:
            warehouse_id = warehouse.replace(' ', '_')
            
            if storage_type == 'Indoor':
                class_type = 'IndoorWarehouse'
            elif storage_type == 'Outdoor':
                class_type = 'OutdoorWarehouse'
            elif storage_type == 'Site':
                class_type = 'Site'
            elif storage_type == 'dangerous_cargo':
                class_type = 'DangerousCargoWarehouse'
            else:
                class_type = 'Warehouse'
            
            ttl_content += f"""ex:{warehouse_id} a ex:{class_type} ;
    rdfs:label "{warehouse}" ;
    ex:hasStorageType "{storage_type}" .

"""
    
    return ttl_content

def step5_generate_sparql_queries(rules):
    """5ë‹¨ê³„: SPARQL ì¿¼ë¦¬ ìƒì„±"""
    print("\nğŸ” 5ë‹¨ê³„: SPARQL ì¿¼ë¦¬ ìƒì„±")
    
    if not rules:
        print("âŒ ë§¤í•‘ ê·œì¹™ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    namespace = rules.get('namespace', 'http://samsung.com/project-logistics#')
    
    queries = f"""# HVDC ì˜¨í†¨ë¡œì§€ SPARQL ì¿¼ë¦¬ ëª¨ìŒ
# Generated: {datetime.now().isoformat()}

# 1. ì›”ë³„ ì°½ê³ ë³„ ì§‘ê³„
PREFIX ex: <{namespace}>
SELECT ?month ?warehouse (SUM(?amount) AS ?totalAmount) (SUM(?qty) AS ?totalQty)
WHERE {{
    ?event rdf:type ex:TransportEvent ;
           ex:hasLocation ?warehouse ;
           ex:hasDate ?date ;
           ex:hasAmount ?amount ;
           ex:hasQuantity ?qty .
    BIND(SUBSTR(STR(?date), 1, 7) AS ?month)
}}
GROUP BY ?month ?warehouse
ORDER BY ?month ?warehouse

# 2. ë²¤ë”ë³„ ë¶„ì„
PREFIX ex: <{namespace}>
SELECT ?vendor (SUM(?amount) AS ?totalAmount) (COUNT(?event) AS ?eventCount)
WHERE {{
    ?event rdf:type ex:TransportEvent ;
           ex:hasVendor ?vendor ;
           ex:hasAmount ?amount .
}}
GROUP BY ?vendor
ORDER BY DESC(?totalAmount)

# 3. ì°½ê³  íƒ€ì…ë³„ ì¬ê³  í˜„í™©
PREFIX ex: <{namespace}>
SELECT ?storageType ?warehouse (SUM(?qty) AS ?totalQty)
WHERE {{
    ?event rdf:type ex:TransportEvent ;
           ex:hasLocation ?warehouse ;
           ex:hasQuantity ?qty .
    ?warehouse ex:hasStorageType ?storageType .
}}
GROUP BY ?storageType ?warehouse
ORDER BY ?storageType ?warehouse

# 4. Handling Fee ë¶„ì„
PREFIX ex: <{namespace}>
SELECT ?warehouse (AVG(?handlingFee) AS ?avgHandlingFee) (SUM(?handlingFee) AS ?totalHandlingFee)
WHERE {{
    ?event rdf:type ex:TransportEvent ;
           ex:hasLocation ?warehouse ;
           ex:hasHandlingFee ?handlingFee .
}}
GROUP BY ?warehouse
ORDER BY DESC(?totalHandlingFee)
"""
    
    return queries

def step6_save_outputs(ttl_content, sparql_queries):
    """6ë‹¨ê³„: ê²°ê³¼ íŒŒì¼ ì €ì¥"""
    print("\nğŸ’¾ 6ë‹¨ê³„: ê²°ê³¼ íŒŒì¼ ì €ì¥")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = Path('rdf_output')
    output_dir.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # TTL íŒŒì¼ ì €ì¥
    if ttl_content:
        ttl_file = output_dir / f'hvdc_ontology_{timestamp}.ttl'
        with open(ttl_file, 'w', encoding='utf-8') as f:
            f.write(ttl_content)
        print(f"âœ… RDF/TTL ì €ì¥: {ttl_file}")
    
    # SPARQL ì¿¼ë¦¬ ì €ì¥
    if sparql_queries:
        sparql_file = output_dir / f'hvdc_queries_{timestamp}.sparql'
        with open(sparql_file, 'w', encoding='utf-8') as f:
            f.write(sparql_queries)
        print(f"âœ… SPARQL ì¿¼ë¦¬ ì €ì¥: {sparql_file}")
    
    return ttl_file, sparql_file

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ HVDC ì˜¨í†¨ë¡œì§€ ë§¤í•‘ ì‹¤í–‰ ì˜ˆì œ")
    print("=" * 50)
    
    # ë‹¨ê³„ë³„ ì‹¤í–‰
    rules = step1_load_mapping_rules()
    df = step2_prepare_sample_data()
    mapped_data = step3_apply_mapping(df, rules)
    ttl_content = step4_generate_rdf(mapped_data, rules)
    sparql_queries = step5_generate_sparql_queries(rules)
    
    if ttl_content and sparql_queries:
        ttl_file, sparql_file = step6_save_outputs(ttl_content, sparql_queries)
        
        print("\nğŸ‰ ì˜¨í†¨ë¡œì§€ ë§¤í•‘ ì™„ë£Œ!")
        print("=" * 50)
        print("ğŸ“ ìƒì„±ëœ íŒŒì¼:")
        print(f"   â€¢ RDF/TTL: {ttl_file}")
        print(f"   â€¢ SPARQL: {sparql_file}")
        print("\nğŸ”§ ì¶”ì²œ ëª…ë ¹ì–´:")
        print("   /cmd_ontology_query [ì˜¨í†¨ë¡œì§€ ì¿¼ë¦¬ ì‹¤í–‰]")
        print("   /cmd_rdf_validate [RDF ê²€ì¦]")
        print("   /cmd_sparql_test [SPARQL í…ŒìŠ¤íŠ¸]")
    else:
        print("\nâŒ ì˜¨í†¨ë¡œì§€ ë§¤í•‘ ì‹¤íŒ¨")

if __name__ == "__main__":
    main() 