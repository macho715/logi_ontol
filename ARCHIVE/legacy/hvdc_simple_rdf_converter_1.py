#!/usr/bin/env python3
"""
HVDC Simple RDF Converter (No rdflib dependency)
Excel íŒŒì¼ì„ RDF/TTL í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê°„ë‹¨í•œ ìŠ¤í¬ë¦½íŠ¸
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import re
import warnings
warnings.filterwarnings('ignore')

# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì •ì˜
PREFIXES = """@prefix ex: <http://samsung.com/project-logistics#> .
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix owl: <http://www.w3.org/2002/07/owl#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

"""

# í•„ë“œ ë§¤í•‘ ê·œì¹™
FIELD_MAPPINGS = {
    "Case No.": "hasCase",
    "no.": "hasSequenceNumber",
    "Shipment Invoice No.": "hasShipmentInvoiceNumber",
    "HVDC CODE": "hasHVDCCode",
    "HVDC CODE 1": "hasHVDCCode1",
    "HVDC CODE 2": "hasHVDCCode2",
    "HVDC CODE 3": "hasHVDCCode3",
    "HVDC CODE 4": "hasHVDCCode4",
    "HVDC CODE 5": "hasHVDCCode5",
    "EQ No": "hasEquipmentNumber",
    "Pkg": "hasPackageCount",
    "Storage": "hasStorageType",
    "Description": "hasDescription",
    "L(CM)": "hasLength",
    "W(CM)": "hasWidth", 
    "H(CM)": "hasHeight",
    "CBM": "hasCubicMeter",
    "N.W(kgs)": "hasNetWeight",
    "G.W(kgs)": "hasGrossWeight",
    "Stack": "hasStackInfo",
    "ETA": "hasETA",
    "ETD": "hasETD",
    "Date": "hasDate",
    "Operation Month": "hasOperationMonth",
    "DHL Warehouse": "hasDHLWarehouse",
    "DSV Indoor": "hasDSVIndoor",
    "DSV Al Markaz": "hasDSVAlMarkaz",
    "DSV Outdoor": "hasDSVOutdoor",
    "AAA  Storage": "hasAAAStorage",
    "Hauler Indoor": "hasHaulerIndoor",
    "DSV MZP": "hasDSVMZP",
    "MOSB": "hasMOSB",
    "Shifting": "hasShifting",
    "DAS": "hasDAS",
    "AGI": "hasAGI",
    "SHU": "hasSHU",
    "MIR": "hasMIR",
    "Logistics Flow Code": "hasLogisticsFlowCode",
    "Status": "hasStatus",
    "wh handling": "hasWHHandling"
}

def sanitize_uri(text):
    """URIì— ì•ˆì „í•œ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    if pd.isna(text):
        return "unknown"
    
    # ë¬¸ìì—´ë¡œ ë³€í™˜
    text = str(text)
    
    # íŠ¹ìˆ˜ ë¬¸ì ì œê±° ë° ë³€í™˜
    text = re.sub(r'[^\w\-_.]', '_', text)
    text = re.sub(r'_+', '_', text)
    text = text.strip('_')
    
    return text or "unknown"

def format_literal(value):
    """ê°’ì„ RDF ë¦¬í„°ëŸ´ë¡œ í¬ë§·íŒ…"""
    if pd.isna(value):
        return None
    
    if isinstance(value, (int, np.integer)):
        return f'"{int(value)}"^^xsd:integer'
    elif isinstance(value, (float, np.floating)):
        if np.isnan(value):
            return None
        return f'"{float(value)}"^^xsd:decimal'
    elif isinstance(value, datetime):
        return f'"{value.strftime("%Y-%m-%d")}"^^xsd:date'
    elif isinstance(value, pd.Timestamp):
        return f'"{value.strftime("%Y-%m-%d")}"^^xsd:date'
    else:
        # ë¬¸ìì—´ ì²˜ë¦¬
        text = str(value).replace('"', '\\"').replace('\n', '\\n').replace('\r', '\\r')
        return f'"{text}"'

def is_valid_hvdc_vendor(code, valid_codes=['HE', 'SIM']):
    """ìœ íš¨í•œ HVDC ë²¤ë” ì½”ë“œì¸ì§€ í™•ì¸"""
    if pd.isna(code):
        return False
    return str(code).strip().upper() in valid_codes

def preprocess_dataframe(df, source_file):
    """ë°ì´í„°í”„ë ˆì„ ì „ì²˜ë¦¬"""
    print(f"ğŸ“Š ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘: {source_file}")
    
    original_count = len(df)
    
    # 1. ì—´ ì´ë¦„ ì •ê·œí™”
    df.columns = df.columns.str.strip()
    
    # 2. ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
    date_columns = [col for col in df.columns if 'Date' in col or 'ETA' in col or 'ETD' in col]
    for col in date_columns:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col], errors='coerce')
    
    # 3. ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ë³€í™˜
    numeric_columns = ['CBM', 'N.W(kgs)', 'G.W(kgs)', 'L(CM)', 'W(CM)', 'H(CM)', 'Pkg']
    for col in numeric_columns:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # 4. CBM ì–‘ìˆ˜ ë³´ì •
    if 'CBM' in df.columns:
        cbm_violations = (df['CBM'] <= 0).sum()
        if cbm_violations > 0:
            mean_cbm = df[df['CBM'] > 0]['CBM'].mean()
            df.loc[df['CBM'] <= 0, 'CBM'] = mean_cbm
            print(f"  âœ… CBM ìœ„ë°˜ {cbm_violations}ê±´ â†’ í‰ê· ê°’ {mean_cbm:.2f}ë¡œ ë³´ì •")
    
    # 5. íŒ¨í‚¤ì§€ ìˆ˜ ë³´ì •
    if 'Pkg' in df.columns:
        df['Pkg'] = df['Pkg'].fillna(1)
        df.loc[df['Pkg'] <= 0, 'Pkg'] = 1
    
    # 6. HVDC CODE 3 í•„í„°ë§
    if 'HVDC CODE 3' in df.columns:
        valid_vendor_mask = df['HVDC CODE 3'].apply(is_valid_hvdc_vendor)
        df = df[valid_vendor_mask]
        filtered_count = len(df)
        print(f"  âœ… ë²¤ë” í•„í„°ë§: {original_count} â†’ {filtered_count}")
    
    # 7. ì¤‘ë³µ ì œê±°
    if 'Case No.' in df.columns:
        df = df.drop_duplicates(subset=['Case No.'])
        final_count = len(df)
        print(f"  âœ… ì¤‘ë³µ ì œê±°: {filtered_count if 'HVDC CODE 3' in df.columns else original_count} â†’ {final_count}")
    
    # 8. ë°ì´í„° ì†ŒìŠ¤ ì¶”ê°€
    df['data_source'] = source_file.replace('.xlsx', '')
    
    print(f"ğŸ“Š ì „ì²˜ë¦¬ ì™„ë£Œ: {original_count} â†’ {len(df)} ({len(df)/original_count*100:.1f}%)")
    
    return df

def create_rdf_content(df, source_file):
    """DataFrameì„ RDF TTL ë‚´ìš©ìœ¼ë¡œ ë³€í™˜"""
    print(f"ğŸ”— RDF ë‚´ìš© ìƒì„± ì‹œì‘: {source_file}")
    
    rdf_content = [PREFIXES]
    
    # ì˜¨í†¨ë¡œì§€ í´ë˜ìŠ¤ ì •ì˜
    rdf_content.append("# ì˜¨í†¨ë¡œì§€ í´ë˜ìŠ¤ ì •ì˜\n")
    rdf_content.append("ex:TransportEvent rdf:type owl:Class ;\n")
    rdf_content.append('    rdfs:label "ìš´ì†¡ ì´ë²¤íŠ¸"@ko .\n\n')
    
    rdf_content.append("ex:HitachiCargo rdf:type owl:Class ;\n")
    rdf_content.append('    rdfs:label "íˆíƒ€ì¹˜ í™”ë¬¼"@ko ;\n')
    rdf_content.append("    rdfs:subClassOf ex:TransportEvent .\n\n")
    
    rdf_content.append("ex:SiemensCargo rdf:type owl:Class ;\n")
    rdf_content.append('    rdfs:label "ì§€ë©˜ìŠ¤ í™”ë¬¼"@ko ;\n')
    rdf_content.append("    rdfs:subClassOf ex:TransportEvent .\n\n")
    
    # ì†ì„± ì •ì˜
    rdf_content.append("# ì†ì„± ì •ì˜\n")
    for field, prop in FIELD_MAPPINGS.items():
        rdf_content.append(f"ex:{prop} rdf:type owl:DatatypeProperty ;\n")
        rdf_content.append(f'    rdfs:label "{field}"@ko .\n\n')
    
    # ì¸ìŠ¤í„´ìŠ¤ ë°ì´í„°
    rdf_content.append("# ì¸ìŠ¤í„´ìŠ¤ ë°ì´í„°\n")
    
    for idx, row in df.iterrows():
        case_no = sanitize_uri(row.get('Case No.', f"case_{idx+1}"))
        event_uri = f"ex:TransportEvent_{case_no}"
        
        rdf_content.append(f"{event_uri} rdf:type ex:TransportEvent")
        
        # ë²¤ë”ë³„ í´ë˜ìŠ¤ ì¶”ê°€
        if 'HVDC CODE 3' in row and pd.notna(row['HVDC CODE 3']):
            vendor = str(row['HVDC CODE 3']).strip().upper()
            if vendor == 'HE':
                rdf_content.append(f" , ex:HitachiCargo")
            elif vendor == 'SIM':
                rdf_content.append(f" , ex:SiemensCargo")
        
        rdf_content.append(" ;\n")
        
        # ë°ì´í„° ì†ŒìŠ¤ ì¶”ê°€
        rdf_content.append(f'    ex:hasDataSource "{source_file}" ;\n')
        
        # ê° í•„ë“œ ì²˜ë¦¬
        properties = []
        for col, value in row.items():
            if col not in FIELD_MAPPINGS:
                continue
            
            formatted_value = format_literal(value)
            if formatted_value:
                prop = FIELD_MAPPINGS[col]
                properties.append(f"    ex:{prop} {formatted_value}")
        
        if properties:
            rdf_content.append(" ;\n".join(properties))
        
        rdf_content.append(" .\n\n")
    
    print(f"ğŸ”— RDF ë‚´ìš© ìƒì„± ì™„ë£Œ: {len(df)} ë ˆì½”ë“œ")
    
    return "".join(rdf_content)

def save_rdf_file(content, output_file):
    """RDF ë‚´ìš©ì„ TTL íŒŒì¼ë¡œ ì €ì¥"""
    print(f"ğŸ’¾ RDF íŒŒì¼ ì €ì¥: {output_file}")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = Path(output_file).parent
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # TTL íŒŒì¼ë¡œ ì €ì¥
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(content)
    
    file_size = Path(output_file).stat().st_size
    print(f"âœ… RDF íŒŒì¼ ì €ì¥ ì™„ë£Œ: {file_size:,} bytes")

def create_summary_report(df_list, output_dir):
    """ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
    total_records = sum(len(df) for df in df_list)
    
    report_content = f"""# HVDC RDF ë³€í™˜ ë³´ê³ ì„œ

ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ì´ ì²˜ë¦¬ ë ˆì½”ë“œ: {total_records:,}

## íŒŒì¼ë³„ í†µê³„
"""
    
    for i, df in enumerate(df_list):
        if i == 0:
            filename = "HVDC WAREHOUSE_HITACHI(HE)"
        else:
            filename = "HVDC WAREHOUSE_SIMENSE(SIM)"
        
        report_content += f"### {filename}\n"
        report_content += f"- ë ˆì½”ë“œ ìˆ˜: {len(df):,}\n"
        
        # ë²¤ë”ë³„ í†µê³„
        if 'HVDC CODE 3' in df.columns:
            vendor_stats = df['HVDC CODE 3'].value_counts()
            for vendor, count in vendor_stats.items():
                report_content += f"- {vendor}: {count:,}ê°œ\n"
        
        # CBM í†µê³„
        if 'CBM' in df.columns:
            cbm_stats = df['CBM'].describe()
            report_content += f"- CBM í‰ê· : {cbm_stats['mean']:.2f}\n"
            report_content += f"- CBM ìµœëŒ€: {cbm_stats['max']:.2f}\n"
        
        report_content += "\n"
    
    report_content += f"""## ìƒì„±ëœ íŒŒì¼
- HVDC WAREHOUSE_HITACHI(HE).ttl
- HVDC WAREHOUSE_SIMENSE(SIM).ttl
- HVDC_COMBINED.ttl

## ì¶”ì²œ ëª…ë ¹ì–´
- `/validate-data comprehensive --sparql-rules`
- `/semantic-search --query="RDF conversion"`
- `/warehouse-status --include-capacity`
"""
    
    # ë³´ê³ ì„œ ì €ì¥
    report_file = output_dir / "conversion_report.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"ğŸ“‹ ë³´ê³ ì„œ ìƒì„±: {report_file}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ HVDC Excel to RDF ë³€í™˜ ì‹œì‘ (Simple Version)")
    print("=" * 50)
    
    # ì…ë ¥ íŒŒì¼ ì •ì˜
    input_files = [
        "data/HVDC WAREHOUSE_HITACHI(HE).xlsx",
        "data/HVDC WAREHOUSE_SIMENSE(SIM).xlsx"
    ]
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = Path("rdf_output")
    output_dir.mkdir(exist_ok=True)
    
    # í†µí•© ë‚´ìš© ì €ì¥ìš©
    combined_content = [PREFIXES]
    processed_dfs = []
    
    # ê° íŒŒì¼ ì²˜ë¦¬
    for input_file in input_files:
        if not Path(input_file).exists():
            print(f"âŒ íŒŒì¼ ì—†ìŒ: {input_file}")
            continue
        
        print(f"\nğŸ“ íŒŒì¼ ì²˜ë¦¬: {input_file}")
        
        # Excel íŒŒì¼ ì½ê¸°
        try:
            df = pd.read_excel(input_file, sheet_name='Case List')
            print(f"ğŸ“Š ë°ì´í„° ë¡œë“œ: {len(df)} ë ˆì½”ë“œ")
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            continue
        
        # ë°ì´í„° ì „ì²˜ë¦¬
        df = preprocess_dataframe(df, Path(input_file).stem)
        processed_dfs.append(df)
        
        # RDF ë‚´ìš© ìƒì„±
        rdf_content = create_rdf_content(df, Path(input_file).stem)
        
        # ê°œë³„ íŒŒì¼ ì €ì¥
        output_file = output_dir / f"{Path(input_file).stem}.ttl"
        save_rdf_file(rdf_content, str(output_file))
        
        # í†µí•© ë‚´ìš©ì— ì¶”ê°€ (ì ‘ë‘ì‚¬ ì œì™¸)
        content_without_prefix = rdf_content.replace(PREFIXES, "")
        combined_content.append(content_without_prefix)
        
        print(f"âœ… {input_file} ì²˜ë¦¬ ì™„ë£Œ")
    
    # í†µí•© íŒŒì¼ ì €ì¥
    if len(combined_content) > 1:
        combined_output = output_dir / "HVDC_COMBINED.ttl"
        save_rdf_file("".join(combined_content), str(combined_output))
        print(f"âœ… í†µí•© íŒŒì¼ ì €ì¥: {combined_output}")
    
    # ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
    if processed_dfs:
        create_summary_report(processed_dfs, output_dir)
    
    print(f"\nğŸ‰ ë³€í™˜ ì™„ë£Œ!")
    print(f"ğŸ“Š ì´ ì²˜ë¦¬ ë ˆì½”ë“œ: {sum(len(df) for df in processed_dfs):,}")
    print(f"ğŸ’¾ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    
    print(f"\nğŸ”§ ì¶”ì²œ ëª…ë ¹ì–´:")
    print(f"  /validate-data comprehensive --sparql-rules")
    print(f"  /semantic-search --query='RDF conversion'")
    print(f"  /warehouse-status --include-capacity")

if __name__ == "__main__":
    main() 