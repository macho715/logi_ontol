# ABU ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

**ìƒì„± ì¼ì‹œ**: 2025-01-21
**ì‹œìŠ¤í…œ ë²„ì „**: v3.1.0
**í”„ë¡œì íŠ¸**: HVDC ë¬¼ë¥˜ ì˜¨í†¨ë¡œì§€ ì‹œìŠ¤í…œ - ABU í†µí•©
**ê´€ë¦¬**: Samsung C&T Logistics & ADNOCÂ·DSV Partnership

---

## ğŸ“‹ ëª©ì°¨

1. [ì‹œìŠ¤í…œ ê°œìš”](#ì‹œìŠ¤í…œ-ê°œìš”)
2. [ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#ì „ì²´-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
3. [ë°ì´í„° íŒŒì´í”„ë¼ì¸](#ë°ì´í„°-íŒŒì´í”„ë¼ì¸)
4. [í•µì‹¬ ì•Œê³ ë¦¬ì¦˜](#í•µì‹¬-ì•Œê³ ë¦¬ì¦˜)
5. [RDF ë³€í™˜ í”„ë¡œì„¸ìŠ¤](#rdf-ë³€í™˜-í”„ë¡œì„¸ìŠ¤)
6. [í¬ë¡œìŠ¤ ë ˆí¼ëŸ°ìŠ¤ ë§¤í•‘](#í¬ë¡œìŠ¤-ë ˆí¼ëŸ°ìŠ¤-ë§¤í•‘)
7. [ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œìŠ¤í…œ](#ì´ë¯¸ì§€-ì²˜ë¦¬-ì‹œìŠ¤í…œ)
8. [ì•Œë¦¼ ì‹œìŠ¤í…œ](#ì•Œë¦¼-ì‹œìŠ¤í…œ)
9. [ë³´ì•ˆ ì•„í‚¤í…ì²˜](#ë³´ì•ˆ-ì•„í‚¤í…ì²˜)
10. [ë°°í¬ ì•„í‚¤í…ì²˜](#ë°°í¬-ì•„í‚¤í…ì²˜)
11. [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)
12. [í™•ì¥ì„± ê³ ë ¤ì‚¬í•­](#í™•ì¥ì„±-ê³ ë ¤ì‚¬í•­)

---

## ì‹œìŠ¤í…œ ê°œìš”

### ABU ì‹œìŠ¤í…œ ì •ì˜

ABU (Abu Dhabi Logistics) ì‹œìŠ¤í…œì€ WhatsApp ê¸°ë°˜ ì‹¤ì‹œê°„ ë¬¼ë¥˜ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì„ HVDC ë¬¼ë¥˜ ì˜¨í†¨ë¡œì§€ ì‹œìŠ¤í…œì— í†µí•©í•œ **ì§€ëŠ¥í˜• ë¬¼ë¥˜ ê´€ë¦¬ í”Œë«í¼**ì…ë‹ˆë‹¤.

**í•µì‹¬ ê¸°ëŠ¥**:
- ğŸ“± **WhatsApp ë©”ì‹œì§€ ì‹¤ì‹œê°„ íŒŒì‹±**: 67,499ê°œ ë©”ì‹œì§€ ì²˜ë¦¬
- ğŸ”— **RDF ì˜¨í†¨ë¡œì§€ ë³€í™˜**: 2,437 triples ìƒì„±
- ğŸ‘¥ **ë‹´ë‹¹ì ê´€ë¦¬**: 12ëª… ë‹´ë‹¹ì ì¶”ì  ë° ë¶„ì„
- ğŸš¢ **ì„ ë°• ì¶”ì **: 10+ì²™ ì„ ë°• ETA/ETD ëª¨ë‹ˆí„°ë§
- ğŸ“ **ì¥ì†Œ ê´€ë¦¬**: 4ê°œ ì£¼ìš” ì¥ì†Œ ìš´ì˜ ìµœì í™”
- âš ï¸ **ì‹¤ì‹œê°„ ì•Œë¦¼**: 10Â·20Â·30 Rule, HCS ê· ì—´ ë“± ìë™ ê°ì§€

### ì‹œìŠ¤í…œ ëª©ì 

```mermaid
graph TB
    subgraph "ABU ì‹œìŠ¤í…œ ëª©ì "
        A[ì‹¤ì‹œê°„ ë¬¼ë¥˜ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜<br/>WhatsApp ê¸°ë°˜]
        B[ë°ì´í„° í†µí•© ë° í‘œì¤€í™”<br/>RDF ì˜¨í†¨ë¡œì§€]
        C[ì§€ëŠ¥í˜• ë¶„ì„ ë° ì¶”ë¡ <br/>íŒ¨í„´ ë°œê²¬]
        D[ìš´ì˜ ìµœì í™”<br/>ìë™í™” ë° íš¨ìœ¨ì„±]
        E[ë¦¬ìŠ¤í¬ ê´€ë¦¬<br/>ì•ˆì „ ë° ê·œì • ì¤€ìˆ˜]
    end

    A --> B
    B --> C
    C --> D
    D --> E

    style A fill:#4ecdc4
    style B fill:#95e1d3
    style C fill:#a8e6cf
    style D fill:#ffe66d
    style E fill:#f38181
```

---

## ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ABU ì‹œìŠ¤í…œ ì „ì²´ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "ë°ì´í„° ì†ŒìŠ¤ ê³„ì¸µ"
        WA[WhatsApp ë¡œê·¸<br/>67,499ê°œ ë©”ì‹œì§€<br/>ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼]
        IMG[ì´ë¯¸ì§€ íŒŒì¼<br/>291ê°œ ì´ë¯¸ì§€<br/>ë©”íƒ€ë°ì´í„°]
        EXCEL[Excel ë°ì´í„°<br/>HVDC + Invoice<br/>10,859ì¤„]
    end

    subgraph "ë°ì´í„° ì²˜ë¦¬ ê³„ì¸µ"
        PARSER[WhatsApp íŒŒì„œ<br/>ì •ê·œí‘œí˜„ì‹ ê¸°ë°˜<br/>ë©”ì‹œì§€ êµ¬ì¡°í™”]
        IMG_PROC[ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ<br/>ë©”íƒ€ë°ì´í„° ì¶”ì¶œ<br/>EXIF ë¶„ì„]
        EXCEL_PROC[Excel í”„ë¡œì„¸ì„œ<br/>ë°ì´í„° ê²€ì¦<br/>í˜•ì‹ ë³€í™˜]
    end

    subgraph "ì˜¨í†¨ë¡œì§€ ê³„ì¸µ"
        RDF_GEN[RDF ìƒì„±ê¸°<br/>ì—”í‹°í‹° ìƒì„±<br/>ê´€ê³„ ì„¤ì •]
        CROSS_REF[í¬ë¡œìŠ¤ ë ˆí¼ëŸ°ìŠ¤<br/>LPO ë§¤í•‘<br/>ì—”í‹°í‹° ì—°ê²°]
        ONTOLOGY[í†µí•© ì˜¨í†¨ë¡œì§€<br/>23,331 triples<br/>ì§€ì‹ ê·¸ë˜í”„]
    end

    subgraph "ë¶„ì„ ê³„ì¸µ"
        REASONER[ì¶”ë¡  ì—”ì§„<br/>íŒ¨í„´ ë°œê²¬<br/>ê·œì¹™ ì ìš©]
        KPI_CALC[KPI ê³„ì‚°ê¸°<br/>ì‹¤ì‹œê°„ ì§€í‘œ<br/>ì„±ê³¼ ì¸¡ì •]
        ALERT[ì•Œë¦¼ ì‹œìŠ¤í…œ<br/>ì„ê³„ê°’ ëª¨ë‹ˆí„°ë§<br/>ìë™ ì•Œë¦¼]
    end

    subgraph "í‘œí˜„ ê³„ì¸µ"
        DASHBOARD[í†µí•© ëŒ€ì‹œë³´ë“œ<br/>ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§<br/>ì‹œê°í™”]
        API[REST API<br/>SPARQL ì—”ë“œí¬ì¸íŠ¸<br/>ë°ì´í„° ì ‘ê·¼]
        REPORTS[ë³´ê³ ì„œ ìƒì„±<br/>ìë™ ë¬¸ì„œí™”<br/>í†µê³„ ë¶„ì„]
    end

    WA --> PARSER
    IMG --> IMG_PROC
    EXCEL --> EXCEL_PROC

    PARSER --> RDF_GEN
    IMG_PROC --> RDF_GEN
    EXCEL_PROC --> RDF_GEN

    RDF_GEN --> CROSS_REF
    CROSS_REF --> ONTOLOGY

    ONTOLOGY --> REASONER
    ONTOLOGY --> KPI_CALC
    ONTOLOGY --> ALERT

    REASONER --> DASHBOARD
    KPI_CALC --> DASHBOARD
    ALERT --> DASHBOARD

    DASHBOARD --> API
    DASHBOARD --> REPORTS

    style ONTOLOGY fill:#4ecdc4
    style DASHBOARD fill:#ffe66d
    style REASONER fill:#f38181
```

### ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ìƒì„¸

| ì»´í¬ë„ŒíŠ¸ | ì—­í•  | ê¸°ìˆ  ìŠ¤íƒ | ì„±ëŠ¥ ì§€í‘œ |
|----------|------|-----------|-----------|
| **WhatsApp íŒŒì„œ** | ë©”ì‹œì§€ êµ¬ì¡°í™” ë° íŒŒì‹± | Python, regex | 120 msg/h |
| **RDF ìƒì„±ê¸°** | ì˜¨í†¨ë¡œì§€ ë³€í™˜ | rdflib, OWL | 2s/1000 triples |
| **ì¶”ë¡  ì—”ì§„** | íŒ¨í„´ ë°œê²¬ ë° ê·œì¹™ ì ìš© | SPARQL, RDFS | 0.5s ì¿¼ë¦¬ ì‘ë‹µ |
| **KPI ê³„ì‚°ê¸°** | ì‹¤ì‹œê°„ ì§€í‘œ ê³„ì‚° | pandas, numpy | 5s ì—…ë°ì´íŠ¸ |
| **ì•Œë¦¼ ì‹œìŠ¤í…œ** | ì„ê³„ê°’ ëª¨ë‹ˆí„°ë§ | WebSocket, SMTP | 1s ì•Œë¦¼ ì§€ì—° |
| **í†µí•© ëŒ€ì‹œë³´ë“œ** | ì‹œê°í™” ë° ëª¨ë‹ˆí„°ë§ | React, D3.js | 60fps ë Œë”ë§ |

---

## ë°ì´í„° íŒŒì´í”„ë¼ì¸

### ABU ë°ì´í„° íŒŒì´í”„ë¼ì¸ í”Œë¡œìš°

```mermaid
sequenceDiagram
    participant WA as WhatsApp
    participant Parser as ë©”ì‹œì§€ íŒŒì„œ
    participant Validator as ë°ì´í„° ê²€ì¦ê¸°
    participant RDF as RDF ìƒì„±ê¸°
    participant Store as Triple Store
    participant Reasoner as ì¶”ë¡  ì—”ì§„
    participant Dashboard as ëŒ€ì‹œë³´ë“œ

    WA->>Parser: ì‹¤ì‹œê°„ ë©”ì‹œì§€ ìŠ¤íŠ¸ë¦¼
    Parser->>Parser: ì •ê·œí‘œí˜„ì‹ íŒŒì‹±
    Parser->>Parser: ë‚ ì§œ/ë°œì‹ ì ì¶”ì¶œ
    Parser->>Validator: êµ¬ì¡°í™”ëœ ë°ì´í„°

    Validator->>Validator: ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬
    Validator->>Validator: í˜•ì‹ ê²€ì¦
    Validator->>RDF: ê²€ì¦ëœ ë°ì´í„°

    RDF->>RDF: ì—”í‹°í‹° ìƒì„±
    RDF->>RDF: ê´€ê³„ ì„¤ì •
    RDF->>Store: RDF triples ì €ì¥

    Store->>Reasoner: ë°ì´í„° ë³€ê²½ ì•Œë¦¼
    Reasoner->>Reasoner: íŒ¨í„´ ë¶„ì„
    Reasoner->>Reasoner: ê·œì¹™ ì ìš©
    Reasoner->>Dashboard: ì¶”ë¡  ê²°ê³¼ ì „ì†¡

    Dashboard->>Dashboard: KPI ì—…ë°ì´íŠ¸
    Dashboard->>Dashboard: ì‹œê°í™” ê°±ì‹ 
```

### ë°ì´í„° ì²˜ë¦¬ ë‹¨ê³„

**1. ìˆ˜ì§‘ ë‹¨ê³„ (Collection)**
```python
def collect_whatsapp_messages(file_path: str) -> List[Message]:
    """
    WhatsApp ë¡œê·¸ íŒŒì¼ì—ì„œ ë©”ì‹œì§€ ìˆ˜ì§‘

    Args:
        file_path: WhatsApp ë¡œê·¸ íŒŒì¼ ê²½ë¡œ

    Returns:
        List[Message]: êµ¬ì¡°í™”ëœ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
    """
    messages = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            if is_message_line(line):
                message = parse_message_line(line)
                messages.append(message)
    return messages
```

**2. íŒŒì‹± ë‹¨ê³„ (Parsing)**
```python
def parse_message_line(line: str) -> Message:
    """
    ë©”ì‹œì§€ ë¼ì¸ì„ êµ¬ì¡°í™”ëœ ê°ì²´ë¡œ íŒŒì‹±

    Args:
        line: ì›ë³¸ ë©”ì‹œì§€ ë¼ì¸

    Returns:
        Message: êµ¬ì¡°í™”ëœ ë©”ì‹œì§€ ê°ì²´
    """
    # ë‚ ì§œ/ì‹œê°„ ì¶”ì¶œ
    datetime_match = re.search(r'(\d{1,2}/\d{1,2}/\d{4}), (\d{1,2}:\d{2})', line)

    # ë°œì‹ ì ì¶”ì¶œ
    sender_match = re.search(r' - ([^:]+):', line)

    # ë©”ì‹œì§€ ë‚´ìš© ì¶”ì¶œ
    content_match = re.search(r': (.+)$', line)

    return Message(
        datetime=parse_datetime(datetime_match.group(1), datetime_match.group(2)),
        sender=sender_match.group(1).strip(),
        content=content_match.group(1).strip()
    )
```

**3. ê²€ì¦ ë‹¨ê³„ (Validation)**
```python
def validate_message(message: Message) -> ValidationResult:
    """
    ë©”ì‹œì§€ ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦

    Args:
        message: ê²€ì¦í•  ë©”ì‹œì§€ ê°ì²´

    Returns:
        ValidationResult: ê²€ì¦ ê²°ê³¼
    """
    errors = []

    # ë‚ ì§œ ìœ íš¨ì„± ê²€ì‚¬
    if not is_valid_datetime(message.datetime):
        errors.append("Invalid datetime format")

    # ë°œì‹ ì ìœ íš¨ì„± ê²€ì‚¬
    if not is_valid_sender(message.sender):
        errors.append("Invalid sender format")

    # ë‚´ìš© ìœ íš¨ì„± ê²€ì‚¬
    if not is_valid_content(message.content):
        errors.append("Invalid content format")

    return ValidationResult(
        is_valid=len(errors) == 0,
        errors=errors
    )
```

---

## í•µì‹¬ ì•Œê³ ë¦¬ì¦˜

### WhatsApp ë©”ì‹œì§€ íŒŒì‹± ì•Œê³ ë¦¬ì¦˜

```mermaid
flowchart TD
    A[ì›ë³¸ ë©”ì‹œì§€ ë¼ì¸] --> B{ë©”ì‹œì§€ í˜•ì‹ ê²€ì¦}
    B -->|ìœ íš¨| C[ì •ê·œí‘œí˜„ì‹ ë§¤ì¹­]
    B -->|ë¬´íš¨| D[ì—ëŸ¬ ë¡œê¹…]

    C --> E[ë‚ ì§œ/ì‹œê°„ ì¶”ì¶œ]
    C --> F[ë°œì‹ ì ì¶”ì¶œ]
    C --> G[ë©”ì‹œì§€ ë‚´ìš© ì¶”ì¶œ]

    E --> H[ë‚ ì§œ í˜•ì‹ ë³€í™˜]
    F --> I[ë°œì‹ ì ì •ê·œí™”]
    G --> J[ë‚´ìš© ì „ì²˜ë¦¬]

    H --> K[Message ê°ì²´ ìƒì„±]
    I --> K
    J --> K

    K --> L[ë°ì´í„° ê²€ì¦]
    L -->|í†µê³¼| M[ë©”ì‹œì§€ ì €ì¥]
    L -->|ì‹¤íŒ¨| N[ì—ëŸ¬ ì²˜ë¦¬]

    style A fill:#4ecdc4
    style K fill:#95e1d3
    style M fill:#a8e6cf
    style D fill:#f38181
    style N fill:#f38181
```

### LPO í¬ë¡œìŠ¤ ë ˆí¼ëŸ°ìŠ¤ ë§¤í•‘ ì•Œê³ ë¦¬ì¦˜

```python
def extract_lpo_mentions_from_text(text: str) -> List[LPOMention]:
    """
    í…ìŠ¤íŠ¸ì—ì„œ LPO ì–¸ê¸‰ì„ ì¶”ì¶œí•˜ê³  í¬ë¡œìŠ¤ ë ˆí¼ëŸ°ìŠ¤ ë§¤í•‘

    Args:
        text: ë¶„ì„í•  í…ìŠ¤íŠ¸

    Returns:
        List[LPOMention]: LPO ì–¸ê¸‰ ë¦¬ìŠ¤íŠ¸
    """
    lpo_mentions = []

    # LPO íŒ¨í„´ ë§¤ì¹­ (LPO-ìˆ«ì)
    lpo_pattern = r'LPO-(\d+)'
    matches = re.finditer(lpo_pattern, text, re.IGNORECASE)

    for match in matches:
        lpo_number = match.group(1)
        position = match.start()

        # ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì•ë’¤ 50ì)
        context_start = max(0, position - 50)
        context_end = min(len(text), position + 50)
        context = text[context_start:context_end]

        # ë‚ ì§œ ë° ë°œì‹ ì ì¶”ì¶œ
        current_date = extract_date_from_context(context)
        current_sender = extract_sender_from_context(context)

        lpo_mention = LPOMention(
            lpo_number=lpo_number,
            position=position,
            context=context,
            date=current_date,
            sender=current_sender
        )

        lpo_mentions.append(lpo_mention)

    return lpo_mentions

def create_cross_references(lpo_mentions: List[LPOMention],
                          messages: List[Message]) -> List[CrossReference]:
    """
    LPO ì–¸ê¸‰ê³¼ ë©”ì‹œì§€ ê°„ í¬ë¡œìŠ¤ ë ˆí¼ëŸ°ìŠ¤ ìƒì„±

    Args:
        lpo_mentions: LPO ì–¸ê¸‰ ë¦¬ìŠ¤íŠ¸
        messages: ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸

    Returns:
        List[CrossReference]: í¬ë¡œìŠ¤ ë ˆí¼ëŸ°ìŠ¤ ë¦¬ìŠ¤íŠ¸
    """
    cross_references = []

    for lpo_mention in lpo_mentions:
        # ë‚ ì§œ ê¸°ë°˜ ë©”ì‹œì§€ ë§¤ì¹­
        matching_messages = find_messages_by_date(
            messages, lpo_mention.date
        )

        for message in matching_messages:
            # LPO â†” Message ê´€ê³„ ìƒì„±
            lpo_message_ref = CrossReference(
                source_type="LPO",
                source_id=lpo_mention.lpo_number,
                target_type="Message",
                target_id=message.id,
                relationship_type="mentioned_in",
                confidence=calculate_confidence(lpo_mention, message)
            )
            cross_references.append(lpo_message_ref)

            # Person â†” LPO ê´€ê³„ ìƒì„±
            person_lpo_ref = CrossReference(
                source_type="Person",
                source_id=message.sender,
                target_type="LPO",
                target_id=lpo_mention.lpo_number,
                relationship_type="responsible_for",
                confidence=0.95
            )
            cross_references.append(person_lpo_ref)

    return cross_references
```

### RDF ì—”í‹°í‹° ìƒì„± ì•Œê³ ë¦¬ì¦˜

```mermaid
graph TB
    subgraph "RDF ì—”í‹°í‹° ìƒì„± í”„ë¡œì„¸ìŠ¤"
        A[êµ¬ì¡°í™”ëœ ë°ì´í„°] --> B[ì—”í‹°í‹° íƒ€ì… ë¶„ë¥˜]
        B --> C[Person ì—”í‹°í‹°]
        B --> D[Vessel ì—”í‹°í‹°]
        B --> E[Location ì—”í‹°í‹°]
        B --> F[Message ì—”í‹°í‹°]
        B --> G[LPO ì—”í‹°í‹°]

        C --> H[Person ì†ì„± ì„¤ì •]
        D --> I[Vessel ì†ì„± ì„¤ì •]
        E --> J[Location ì†ì„± ì„¤ì •]
        F --> K[Message ì†ì„± ì„¤ì •]
        G --> L[LPO ì†ì„± ì„¤ì •]

        H --> M[URI ìƒì„±]
        I --> M
        J --> M
        K --> M
        L --> M

        M --> N[RDF Triple ìƒì„±]
        N --> O[ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë°”ì¸ë”©]
        O --> P[ê·¸ë˜í”„ì— ì¶”ê°€]
    end

    style A fill:#4ecdc4
    style M fill:#95e1d3
    style P fill:#a8e6cf
```

---

## RDF ë³€í™˜ í”„ë¡œì„¸ìŠ¤

### RDF ë³€í™˜ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "RDF ë³€í™˜ ì‹œìŠ¤í…œ"
        A[ì›ë³¸ ë°ì´í„°<br/>WhatsApp + Excel + Image]
        B[ë°ì´í„° ì „ì²˜ë¦¬<br/>ì •ê·œí™” ë° ê²€ì¦]
        C[ì—”í‹°í‹° ì¶”ì¶œ<br/>Person, Vessel, Location, Message, LPO]
        D[ê´€ê³„ ë§¤í•‘<br/>í¬ë¡œìŠ¤ ë ˆí¼ëŸ°ìŠ¤ ìƒì„±]
        E[RDF ìƒì„±<br/>Triple ìƒì„± ë° ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë°”ì¸ë”©]
        F[ê·¸ë˜í”„ ë³‘í•©<br/>ABU + HVDC + Invoice í†µí•©]
        G[ê²€ì¦ ë° ìµœì í™”<br/>ë¬´ê²°ì„± ê²€ì‚¬ ë° ì„±ëŠ¥ ìµœì í™”]
        H[ì €ì¥<br/>Apache Jena Fuseki]
    end

    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
    F --> G
    G --> H

    style A fill:#4ecdc4
    style E fill:#95e1d3
    style H fill:#a8e6cf
```

### ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì •ì˜

```python
# ABU ì‹œìŠ¤í…œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì •ì˜
ABU_NAMESPACES = {
    'EX': Namespace('http://example.org/logistics/'),
    'RDF': RDF,
    'RDFS': RDFS,
    'XSD': XSD,
    'HVDC': Namespace('http://hvdc.org/ontology/'),
    'OPS': Namespace('http://operations.org/'),
    'ORG': Namespace('http://organization.org/'),
    'HVDCI': Namespace('http://hvdc.org/invoice/'),
    'ABU': Namespace('http://abu.org/logistics/'),
    'ABUI': Namespace('http://abu.org/invoice/'),
    'LPO': Namespace('http://lpo.org/')
}

def create_entity_uri(entity_type: str, entity_id: str) -> URIRef:
    """
    ì—”í‹°í‹° íƒ€ì…ê³¼ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ URI ìƒì„±

    Args:
        entity_type: ì—”í‹°í‹° íƒ€ì… (Person, Vessel, Location ë“±)
        entity_id: ì—”í‹°í‹° ê³ ìœ  ì‹ë³„ì

    Returns:
        URIRef: ìƒì„±ëœ URI
    """
    namespace_map = {
        'Person': ABU_NAMESPACES['ABU'],
        'Vessel': ABU_NAMESPACES['ABU'],
        'Location': ABU_NAMESPACES['ABU'],
        'Message': ABU_NAMESPACES['ABU'],
        'LPO': ABU_NAMESPACES['LPO'],
        'Image': ABU_NAMESPACES['ABU']
    }

    namespace = namespace_map.get(entity_type, ABU_NAMESPACES['EX'])
    return namespace[f"{entity_type.lower()}_{entity_id}"]
```

### RDF Triple ìƒì„± ë¡œì§

```python
def generate_rdf_triples(entities: List[Entity],
                        relationships: List[Relationship]) -> Graph:
    """
    ì—”í‹°í‹°ì™€ ê´€ê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ RDF ê·¸ë˜í”„ ìƒì„±

    Args:
        entities: ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸
        relationships: ê´€ê³„ ë¦¬ìŠ¤íŠ¸

    Returns:
        Graph: ìƒì„±ëœ RDF ê·¸ë˜í”„
    """
    graph = Graph()

    # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë°”ì¸ë”©
    for prefix, namespace in ABU_NAMESPACES.items():
        graph.bind(prefix, namespace)

    # ì—”í‹°í‹° RDF ë³€í™˜
    for entity in entities:
        entity_uri = create_entity_uri(entity.type, entity.id)

        # íƒ€ì… ì„ ì–¸
        graph.add((entity_uri, RDF.type, ABU_NAMESPACES['ABU'][entity.type]))

        # ì†ì„± ì¶”ê°€
        for prop_name, prop_value in entity.properties.items():
            if prop_value is not None:
                prop_uri = ABU_NAMESPACES['ABU'][prop_name]
                if isinstance(prop_value, str):
                    graph.add((entity_uri, prop_uri, Literal(prop_value)))
                elif isinstance(prop_value, datetime):
                    graph.add((entity_uri, prop_uri, Literal(prop_value, datatype=XSD.dateTime)))
                elif isinstance(prop_value, (int, float)):
                    graph.add((entity_uri, prop_uri, Literal(prop_value, datatype=XSD.double)))

    # ê´€ê³„ RDF ë³€í™˜
    for relationship in relationships:
        source_uri = create_entity_uri(relationship.source_type, relationship.source_id)
        target_uri = create_entity_uri(relationship.target_type, relationship.target_id)
        rel_uri = ABU_NAMESPACES['ABU'][relationship.relationship_type]

        graph.add((source_uri, rel_uri, target_uri))

        # ì‹ ë¢°ë„ ì†ì„± ì¶”ê°€
        if hasattr(relationship, 'confidence'):
            graph.add((source_uri, rel_uri, Literal(relationship.confidence, datatype=XSD.double)))

    return graph
```

---

## í¬ë¡œìŠ¤ ë ˆí¼ëŸ°ìŠ¤ ë§¤í•‘

### í¬ë¡œìŠ¤ ë ˆí¼ëŸ°ìŠ¤ ë§¤í•‘ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "í¬ë¡œìŠ¤ ë ˆí¼ëŸ°ìŠ¤ ë§¤í•‘ ì‹œìŠ¤í…œ"
        A[LPO ì–¸ê¸‰ ì¶”ì¶œ<br/>ì •ê·œí‘œí˜„ì‹ ê¸°ë°˜]
        B[ë©”ì‹œì§€ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„<br/>ë‚ ì§œ/ë°œì‹ ì ë§¤ì¹­]
        C[ì—”í‹°í‹° ê´€ê³„ ë§¤í•‘<br/>Person â†” LPO â†” Vessel]
        D[ìœ„ì¹˜ ì •ë³´ ë§¤í•‘<br/>Location â†” Vessel â†” LPO]
        E[ì‹œê°„ ê¸°ë°˜ ì—°ê²°<br/>Message â†” LPO â†” Event]
        F[ì‹ ë¢°ë„ ê³„ì‚°<br/>ë§¤ì¹­ ì •í™•ë„ í‰ê°€]
        G[ê´€ê³„ ê·¸ë˜í”„ ìƒì„±<br/>RDF Triples]
    end

    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
    F --> G

    style A fill:#4ecdc4
    style C fill:#95e1d3
    style G fill:#a8e6cf
```

### ë‹´ë‹¹ì-ì„ ë°•-ì¥ì†Œ ê´€ê³„ë„

```mermaid
erDiagram
    Person ||--o{ Message : "sends"
    Person ||--o{ LPO : "responsible_for"
    Person ||--o{ Vessel : "manages"

    Vessel ||--o{ Message : "mentioned_in"
    Vessel ||--o{ LPO : "handles"
    Vessel ||--o{ Location : "visits"

    Location ||--o{ Message : "discussed_in"
    Location ||--o{ LPO : "processed_at"
    Location ||--o{ Vessel : "serves"

    Message ||--o{ LPO : "references"
    Message ||--o{ Image : "contains"

    LPO ||--o{ Invoice : "generates"

    Person {
        string id PK
        string name
        string role
        string department
        datetime last_active
    }

    Vessel {
        string id PK
        string name
        string type
        string status
        datetime eta
        datetime etd
    }

    Location {
        string id PK
        string name
        string type
        string status
        float capacity
        float utilization
    }

    Message {
        string id PK
        datetime timestamp
        string sender
        string content
        string type
    }

    LPO {
        string id PK
        string number
        string status
        datetime created
        datetime updated
    }
```

---

## ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œìŠ¤í…œ

### ì´ë¯¸ì§€ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```mermaid
graph TB
    subgraph "ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œìŠ¤í…œ"
        A[ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜ì§‘<br/>291ê°œ ì´ë¯¸ì§€]
        B[ë©”íƒ€ë°ì´í„° ì¶”ì¶œ<br/>EXIF, íŒŒì¼ ì •ë³´]
        C[ì´ë¯¸ì§€ ë¶„ì„<br/>OCR, ê°ì²´ ì¸ì‹]
        D[í…ìŠ¤íŠ¸ ì¶”ì¶œ<br/>LPO ë²ˆí˜¸, ë‚ ì§œ ë“±]
        E[ë©”ì‹œì§€ ì—°ê²°<br/>ë‚ ì§œ ê¸°ë°˜ ë§¤ì¹­]
        F[RDF ë³€í™˜<br/>ì´ë¯¸ì§€ ì—”í‹°í‹° ìƒì„±]
        G[ê´€ê³„ ì„¤ì •<br/>Message â†” Image]
    end

    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
    F --> G

    style A fill:#4ecdc4
    style C fill:#95e1d3
    style G fill:#a8e6cf
```

### ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ

```python
def extract_image_metadata(image_path: str) -> ImageMetadata:
    """
    ì´ë¯¸ì§€ íŒŒì¼ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ

    Args:
        image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ

    Returns:
        ImageMetadata: ì¶”ì¶œëœ ë©”íƒ€ë°ì´í„°
    """
    metadata = ImageMetadata()

    # íŒŒì¼ ì •ë³´ ì¶”ì¶œ
    file_stat = os.stat(image_path)
    metadata.filename = os.path.basename(image_path)
    metadata.file_size = file_stat.st_size
    metadata.created_time = datetime.fromtimestamp(file_stat.st_ctime)
    metadata.modified_time = datetime.fromtimestamp(file_stat.st_mtime)

    # EXIF ë°ì´í„° ì¶”ì¶œ
    try:
        with Image.open(image_path) as img:
            exif_data = img._getexif()
            if exif_data:
                metadata.camera_make = exif_data.get(271, "")
                metadata.camera_model = exif_data.get(272, "")
                metadata.date_taken = exif_data.get(306, "")
                metadata.gps_info = exif_data.get(34853, {})
    except Exception as e:
        logger.warning(f"EXIF extraction failed for {image_path}: {e}")

    # OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
    try:
        ocr_text = extract_text_from_image(image_path)
        metadata.extracted_text = ocr_text

        # LPO ë²ˆí˜¸ ì¶”ì¶œ
        lpo_matches = re.findall(r'LPO-(\d+)', ocr_text, re.IGNORECASE)
        metadata.lpo_numbers = lpo_matches

        # ë‚ ì§œ ì¶”ì¶œ
        date_matches = re.findall(r'(\d{1,2}/\d{1,2}/\d{4})', ocr_text)
        metadata.extracted_dates = date_matches

    except Exception as e:
        logger.warning(f"OCR extraction failed for {image_path}: {e}")

    return metadata

def create_image_message_links(images: List[ImageMetadata],
                             messages: List[Message]) -> List[ImageMessageLink]:
    """
    ì´ë¯¸ì§€ì™€ ë©”ì‹œì§€ ê°„ ì—°ê²° ìƒì„±

    Args:
        images: ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        messages: ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸

    Returns:
        List[ImageMessageLink]: ì´ë¯¸ì§€-ë©”ì‹œì§€ ì—°ê²° ë¦¬ìŠ¤íŠ¸
    """
    links = []

    for image in images:
        # ë‚ ì§œ ê¸°ë°˜ ë©”ì‹œì§€ ë§¤ì¹­
        matching_messages = find_messages_by_date_range(
            messages,
            image.created_time,
            timedelta(hours=24)  # 24ì‹œê°„ ë‚´ ë©”ì‹œì§€
        )

        for message in matching_messages:
            # LPO ë²ˆí˜¸ ê¸°ë°˜ ì¶”ê°€ ë§¤ì¹­
            if image.lpo_numbers and any(lpo in message.content for lpo in image.lpo_numbers):
                confidence = 0.95
            else:
                confidence = 0.7

            link = ImageMessageLink(
                image_id=image.id,
                message_id=message.id,
                confidence=confidence,
                link_type="date_based"
            )
            links.append(link)

    return links
```

---

## ì•Œë¦¼ ì‹œìŠ¤í…œ

### ì•Œë¦¼ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "ì•Œë¦¼ ì‹œìŠ¤í…œ"
        A[ë°ì´í„° ëª¨ë‹ˆí„°ë§<br/>ì‹¤ì‹œê°„ KPI ì¶”ì ]
        B[ì„ê³„ê°’ ê²€ì‚¬<br/>10-20-30 Rule, HCS ë“±]
        C[ì•Œë¦¼ ê·œì¹™ ì—”ì§„<br/>ì¡°ê±´ë¶€ ì•Œë¦¼ ìƒì„±]
        D[ì•Œë¦¼ ìš°ì„ ìˆœìœ„<br/>Critical, High, Medium, Low]
        E[ì•Œë¦¼ ì±„ë„<br/>Email, SMS, Push, Dashboard]
        F[ì•Œë¦¼ ì „ì†¡<br/>ì‹¤ì‹œê°„ ë°°ì†¡]
        G[ì•Œë¦¼ ì¶”ì <br/>ì „ì†¡ ìƒíƒœ ë° ì‘ë‹µ]
    end

    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
    F --> G

    style A fill:#4ecdc4
    style C fill:#95e1d3
    style F fill:#a8e6cf
```

### ì•Œë¦¼ ê·œì¹™ ì •ì˜

```python
class AlertRule:
    """ì•Œë¦¼ ê·œì¹™ ì •ì˜ í´ë˜ìŠ¤"""

    def __init__(self, name: str, condition: callable,
                 priority: str, channels: List[str]):
        self.name = name
        self.condition = condition
        self.priority = priority
        self.channels = channels

# ABU ì‹œìŠ¤í…œ ì•Œë¦¼ ê·œì¹™ ì •ì˜
ABU_ALERT_RULES = [
    # 10-20-30 Rule ì•Œë¦¼
    AlertRule(
        name="10_minute_delay",
        condition=lambda data: data.get('delay_minutes', 0) >= 10,
        priority="Medium",
        channels=["dashboard", "email"]
    ),
    AlertRule(
        name="20_minute_delay",
        condition=lambda data: data.get('delay_minutes', 0) >= 20,
        priority="High",
        channels=["dashboard", "email", "sms"]
    ),
    AlertRule(
        name="30_minute_delay",
        condition=lambda data: data.get('delay_minutes', 0) >= 30,
        priority="Critical",
        channels=["dashboard", "email", "sms", "push"]
    ),

    # HCS ê· ì—´ ì•Œë¦¼
    AlertRule(
        name="hcs_crack_detected",
        condition=lambda data: "crack" in data.get('content', '').lower(),
        priority="Critical",
        channels=["dashboard", "email", "sms", "push"]
    ),

    # TPI ì¸ì¦ ë§Œë£Œ ì•Œë¦¼
    AlertRule(
        name="tpi_certification_expiry",
        condition=lambda data: data.get('tpi_expiry_days', 365) <= 30,
        priority="High",
        channels=["dashboard", "email"]
    ),

    # ì„ ë°• ì •ì‹œìœ¨ ì €í•˜ ì•Œë¦¼
    AlertRule(
        name="vessel_ontime_rate_low",
        condition=lambda data: data.get('vessel_ontime_rate', 100) < 90,
        priority="Medium",
        channels=["dashboard", "email"]
    ),

    # ì¥ì†Œ í˜¼ì¡ë„ ë†’ìŒ ì•Œë¦¼
    AlertRule(
        name="location_congestion_high",
        condition=lambda data: data.get('location_congestion', 0) > 80,
        priority="High",
        channels=["dashboard", "email", "sms"]
    )
]

def evaluate_alert_rules(data: dict) -> List[Alert]:
    """
    ë°ì´í„°ì— ëŒ€í•´ ì•Œë¦¼ ê·œì¹™ í‰ê°€

    Args:
        data: í‰ê°€í•  ë°ì´í„°

    Returns:
        List[Alert]: ìƒì„±ëœ ì•Œë¦¼ ë¦¬ìŠ¤íŠ¸
    """
    alerts = []

    for rule in ABU_ALERT_RULES:
        if rule.condition(data):
            alert = Alert(
                rule_name=rule.name,
                priority=rule.priority,
                channels=rule.channels,
                data=data,
                timestamp=datetime.now()
            )
            alerts.append(alert)

    return alerts
```

### ì•Œë¦¼ ì‹œìŠ¤í…œ íë¦„

```mermaid
sequenceDiagram
    participant Monitor as ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
    participant Rules as ì•Œë¦¼ ê·œì¹™ ì—”ì§„
    participant Queue as ì•Œë¦¼ í
    participant Channels as ì•Œë¦¼ ì±„ë„
    participant User as ì‚¬ìš©ì

    Monitor->>Rules: ì‹¤ì‹œê°„ ë°ì´í„° ì „ì†¡
    Rules->>Rules: ê·œì¹™ ì¡°ê±´ í‰ê°€
    Rules->>Queue: ì•Œë¦¼ ìƒì„± ë° íì‰

    Queue->>Channels: ì•Œë¦¼ ì „ì†¡ ìš”ì²­
    Channels->>Channels: ì±„ë„ë³„ ì „ì†¡ ì²˜ë¦¬
    Channels->>User: ì•Œë¦¼ ì „ë‹¬

    User->>Channels: ì•Œë¦¼ í™•ì¸/ì‘ë‹µ
    Channels->>Monitor: ì‘ë‹µ ìƒíƒœ ì—…ë°ì´íŠ¸
    Monitor->>Rules: ì•Œë¦¼ ìƒíƒœ ë°˜ì˜
```

---

## ë³´ì•ˆ ì•„í‚¤í…ì²˜

### ë³´ì•ˆ ê³„ì¸µ êµ¬ì¡°

```mermaid
graph TB
    subgraph "ë³´ì•ˆ ê³„ì¸µ êµ¬ì¡°"
        A[ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ<br/>ë°©í™”ë²½, VPN, SSL/TLS]
        B[ì¸ì¦ ë° ì¸ê°€<br/>OAuth 2.0, JWT, RBAC]
        C[ë°ì´í„° ì•”í˜¸í™”<br/>AES-256, ì „ì†¡/ì €ì¥ ì•”í˜¸í™”]
        D[ì ‘ê·¼ ì œì–´<br/>IP í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸, ì„¸ì…˜ ê´€ë¦¬]
        E[ê°ì‚¬ ë¡œê¹…<br/>ë³´ì•ˆ ì´ë²¤íŠ¸ ì¶”ì ]
        F[ë°ì´í„° ë³´í˜¸<br/>PII ë§ˆìŠ¤í‚¹, GDPR ì¤€ìˆ˜]
        G[ë°±ì—… ë° ë³µêµ¬<br/>ì•”í˜¸í™”ëœ ë°±ì—…, ì¬í•´ ë³µêµ¬]
    end

    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
    F --> G

    style A fill:#4ecdc4
    style C fill:#95e1d3
    style F fill:#a8e6cf
```

### ë°ì´í„° ë³´í˜¸ ì •ì±…

```python
class DataProtectionPolicy:
    """ë°ì´í„° ë³´í˜¸ ì •ì±… í´ë˜ìŠ¤"""

    def __init__(self):
        self.pii_fields = [
            'person_name', 'phone_number', 'email',
            'address', 'id_number'
        ]
        self.sensitive_fields = [
            'lpo_number', 'vessel_name', 'location_name',
            'financial_data', 'operational_metrics'
        ]
        self.encryption_required = True
        self.retention_period = 7  # years
        self.audit_required = True

    def mask_pii_data(self, data: dict) -> dict:
        """PII ë°ì´í„° ë§ˆìŠ¤í‚¹"""
        masked_data = data.copy()

        for field in self.pii_fields:
            if field in masked_data:
                masked_data[field] = self._mask_value(masked_data[field])

        return masked_data

    def _mask_value(self, value: str) -> str:
        """ê°’ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬"""
        if len(value) <= 2:
            return "*" * len(value)
        else:
            return value[:2] + "*" * (len(value) - 4) + value[-2:]

    def encrypt_sensitive_data(self, data: dict) -> dict:
        """ë¯¼ê° ë°ì´í„° ì•”í˜¸í™”"""
        encrypted_data = data.copy()

        for field in self.sensitive_fields:
            if field in encrypted_data:
                encrypted_data[field] = self._encrypt_value(encrypted_data[field])

        return encrypted_data

    def _encrypt_value(self, value: str) -> str:
        """ê°’ ì•”í˜¸í™” ì²˜ë¦¬"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” AES-256 ì•”í˜¸í™” ì‚¬ìš©
        return f"ENCRYPTED_{value}"
```

---

## ë°°í¬ ì•„í‚¤í…ì²˜

### ë°°í¬ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨

```mermaid
graph TB
    subgraph "í”„ë¡œë•ì…˜ í™˜ê²½"
        subgraph "ë¡œë“œ ë°¸ëŸ°ì„œ"
            LB[NGINX Load Balancer<br/>SSL Termination<br/>Rate Limiting]
        end

        subgraph "ì• í”Œë¦¬ì¼€ì´ì…˜ ì„œë²„"
            APP1[ABU App Server 1<br/>Python 3.13<br/>Gunicorn]
            APP2[ABU App Server 2<br/>Python 3.13<br/>Gunicorn]
        end

        subgraph "ë°ì´í„°ë² ì´ìŠ¤ í´ëŸ¬ìŠ¤í„°"
            DB1[PostgreSQL Primary<br/>ë°ì´í„° ì €ì¥]
            DB2[PostgreSQL Replica<br/>ì½ê¸° ì „ìš©]
        end

        subgraph "ìºì‹œ ë ˆì´ì–´"
            REDIS[Redis Cluster<br/>ì„¸ì…˜ ê´€ë¦¬<br/>ìºì‹±]
        end

        subgraph "íŒŒì¼ ìŠ¤í† ë¦¬ì§€"
            S3[AWS S3<br/>ì´ë¯¸ì§€ ì €ì¥<br/>ë°±ì—…]
        end

        subgraph "ëª¨ë‹ˆí„°ë§"
            PROM[Prometheus<br/>ë©”íŠ¸ë¦­ ìˆ˜ì§‘]
            GRAF[Grafana<br/>ì‹œê°í™”]
            ELK[ELK Stack<br/>ë¡œê·¸ ë¶„ì„]
        end
    end

    LB --> APP1
    LB --> APP2
    APP1 --> DB1
    APP2 --> DB1
    APP1 --> REDIS
    APP2 --> REDIS
    APP1 --> S3
    APP2 --> S3

    DB1 --> DB2

    APP1 --> PROM
    APP2 --> PROM
    PROM --> GRAF

    style LB fill:#4ecdc4
    style DB1 fill:#95e1d3
    style REDIS fill:#a8e6cf
    style S3 fill:#ffe66d
```

### ì»¨í…Œì´ë„ˆ ë°°í¬ êµ¬ì„±

```yaml
# docker-compose.yml
version: '3.8'

services:
  abu-app:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/abu
      - REDIS_URL=redis://redis:6379
      - S3_BUCKET=abu-images
    depends_on:
      - db
      - redis
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped

  db:
    image: postgres:15
    environment:
      - POSTGRES_DB=abu
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups:/backups
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/ssl
    depends_on:
      - abu-app
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
```

---

## ì„±ëŠ¥ ìµœì í™”

### ì„±ëŠ¥ ìµœì í™” ì „ëµ

```mermaid
graph TB
    subgraph "ì„±ëŠ¥ ìµœì í™” ì „ëµ"
        A[ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”<br/>ì¸ë±ì‹±, ì¿¼ë¦¬ ìµœì í™”]
        B[ìºì‹± ì „ëµ<br/>Redis, ë©”ëª¨ë¦¬ ìºì‹œ]
        C[ë¹„ë™ê¸° ì²˜ë¦¬<br/>Celery, í ì‹œìŠ¤í…œ]
        D[CDN í™œìš©<br/>ì •ì  ìì› ìµœì í™”]
        E[ì••ì¶• ë° ìµœì í™”<br/>Gzip, ì´ë¯¸ì§€ ì••ì¶•]
        F[ëª¨ë‹ˆí„°ë§ ë° í”„ë¡œíŒŒì¼ë§<br/>ì„±ëŠ¥ ì§€í‘œ ì¶”ì ]
    end

    A --> B
    B --> C
    C --> D
    D --> E
    E --> F

    style A fill:#4ecdc4
    style C fill:#95e1d3
    style F fill:#a8e6cf
```

### ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”

```python
# ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ìŠ¤ ìµœì í™”
DATABASE_INDEXES = {
    'messages': [
        'CREATE INDEX idx_messages_timestamp ON messages(timestamp)',
        'CREATE INDEX idx_messages_sender ON messages(sender)',
        'CREATE INDEX idx_messages_content ON messages USING gin(to_tsvector(\'english\', content))'
    ],
    'lpo_mentions': [
        'CREATE INDEX idx_lpo_mentions_number ON lpo_mentions(lpo_number)',
        'CREATE INDEX idx_lpo_mentions_date ON lpo_mentions(mention_date)',
        'CREATE INDEX idx_lpo_mentions_sender ON lpo_mentions(sender)'
    ],
    'cross_references': [
        'CREATE INDEX idx_cross_ref_source ON cross_references(source_type, source_id)',
        'CREATE INDEX idx_cross_ref_target ON cross_references(target_type, target_id)',
        'CREATE INDEX idx_cross_ref_relationship ON cross_references(relationship_type)'
    ]
}

# ì¿¼ë¦¬ ìµœì í™” ì˜ˆì‹œ
def get_messages_by_date_range(start_date: datetime, end_date: datetime) -> List[Message]:
    """
    ë‚ ì§œ ë²”ìœ„ë¡œ ë©”ì‹œì§€ ì¡°íšŒ (ì¸ë±ìŠ¤ í™œìš©)
    """
    query = """
    SELECT * FROM messages
    WHERE timestamp BETWEEN %s AND %s
    ORDER BY timestamp ASC
    """
    return execute_query(query, (start_date, end_date))

def get_lpo_mentions_by_sender(sender: str) -> List[LPOMention]:
    """
    ë°œì‹ ìë³„ LPO ì–¸ê¸‰ ì¡°íšŒ (ì¸ë±ìŠ¤ í™œìš©)
    """
    query = """
    SELECT lm.*, m.content, m.timestamp
    FROM lpo_mentions lm
    JOIN messages m ON lm.message_id = m.id
    WHERE lm.sender = %s
    ORDER BY lm.mention_date DESC
    """
    return execute_query(query, (sender,))
```

### ìºì‹± ì „ëµ

```python
from functools import wraps
import redis
import json

# Redis ìºì‹œ ì„¤ì •
redis_client = redis.Redis(host='localhost', port=6379, db=0)

def cache_result(expiration: int = 3600):
    """ê²°ê³¼ ìºì‹± ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ìºì‹œ í‚¤ ìƒì„±
            cache_key = f"{func.__name__}:{hash(str(args) + str(kwargs))}"

            # ìºì‹œì—ì„œ ì¡°íšŒ
            cached_result = redis_client.get(cache_key)
            if cached_result:
                return json.loads(cached_result)

            # í•¨ìˆ˜ ì‹¤í–‰
            result = func(*args, **kwargs)

            # ê²°ê³¼ ìºì‹±
            redis_client.setex(
                cache_key,
                expiration,
                json.dumps(result, default=str)
            )

            return result
        return wrapper
    return decorator

@cache_result(expiration=1800)  # 30ë¶„ ìºì‹œ
def get_person_workload_stats(person_id: str) -> dict:
    """ë‹´ë‹¹ìë³„ ì›Œí¬ë¡œë“œ í†µê³„ (ìºì‹œë¨)"""
    # ë³µì¡í•œ í†µê³„ ê³„ì‚° ë¡œì§
    pass

@cache_result(expiration=3600)  # 1ì‹œê°„ ìºì‹œ
def get_vessel_operations_summary(vessel_id: str) -> dict:
    """ì„ ë°•ë³„ ìš´ì˜ ìš”ì•½ (ìºì‹œë¨)"""
    # ë³µì¡í•œ ì„ ë°• ìš´ì˜ ë¶„ì„ ë¡œì§
    pass
```

---

## í™•ì¥ì„± ê³ ë ¤ì‚¬í•­

### ìˆ˜í‰ì  í™•ì¥ ì „ëµ

```mermaid
graph TB
    subgraph "ìˆ˜í‰ì  í™•ì¥ ì•„í‚¤í…ì²˜"
        A[ë¡œë“œ ë°¸ëŸ°ì„œ<br/>ìš”ì²­ ë¶„ì‚°]
        B[App Server 1<br/>ë©”ì‹œì§€ ì²˜ë¦¬]
        C[App Server 2<br/>RDF ë³€í™˜]
        D[App Server 3<br/>ë¶„ì„ ì—”ì§„]
        E[App Server N<br/>ì¶”ê°€ ê¸°ëŠ¥]

        F[Database Cluster<br/>ì½ê¸°/ì“°ê¸° ë¶„ë¦¬]
        G[Cache Cluster<br/>Redis Sentinel]
        H[Message Queue<br/>Celery + RabbitMQ]
        I[File Storage<br/>ë¶„ì‚° íŒŒì¼ ì‹œìŠ¤í…œ]
    end

    A --> B
    A --> C
    A --> D
    A --> E

    B --> F
    C --> F
    D --> F
    E --> F

    B --> G
    C --> G
    D --> G
    E --> G

    B --> H
    C --> H
    D --> H
    E --> H

    style A fill:#4ecdc4
    style F fill:#95e1d3
    style H fill:#a8e6cf
```

### ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜

```python
# ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ êµ¬ì„±
MICROSERVICES = {
    'message-parser': {
        'port': 8001,
        'responsibility': 'WhatsApp ë©”ì‹œì§€ íŒŒì‹±',
        'dependencies': ['redis', 'postgresql']
    },
    'rdf-generator': {
        'port': 8002,
        'responsibility': 'RDF ë³€í™˜ ë° ì˜¨í†¨ë¡œì§€ ìƒì„±',
        'dependencies': ['postgresql', 'fuseki']
    },
    'analysis-engine': {
        'port': 8003,
        'responsibility': 'ë°ì´í„° ë¶„ì„ ë° íŒ¨í„´ ë°œê²¬',
        'dependencies': ['postgresql', 'redis', 'celery']
    },
    'notification-service': {
        'port': 8004,
        'responsibility': 'ì•Œë¦¼ ìƒì„± ë° ì „ì†¡',
        'dependencies': ['redis', 'smtp', 'webhook']
    },
    'dashboard-api': {
        'port': 8005,
        'responsibility': 'ëŒ€ì‹œë³´ë“œ API ì œê³µ',
        'dependencies': ['postgresql', 'redis', 'fuseki']
    }
}

# API ê²Œì´íŠ¸ì›¨ì´ ì„¤ì •
API_GATEWAY_CONFIG = {
    'routes': {
        '/api/v1/messages': 'message-parser:8001',
        '/api/v1/rdf': 'rdf-generator:8002',
        '/api/v1/analysis': 'analysis-engine:8003',
        '/api/v1/notifications': 'notification-service:8004',
        '/api/v1/dashboard': 'dashboard-api:8005'
    },
    'middleware': [
        'authentication',
        'rate_limiting',
        'cors',
        'logging'
    ],
    'load_balancing': 'round_robin'
}
```

### ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```python
# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì„¤ì •
PERFORMANCE_METRICS = {
    'response_time': {
        'target': 200,  # ms
        'warning': 500,  # ms
        'critical': 1000  # ms
    },
    'throughput': {
        'target': 1000,  # requests/min
        'warning': 500,  # requests/min
        'critical': 100  # requests/min
    },
    'error_rate': {
        'target': 0.01,  # 1%
        'warning': 0.05,  # 5%
        'critical': 0.10  # 10%
    },
    'cpu_usage': {
        'target': 70,  # %
        'warning': 85,  # %
        'critical': 95  # %
    },
    'memory_usage': {
        'target': 80,  # %
        'warning': 90,  # %
        'critical': 95  # %
    }
}

def monitor_performance():
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹¤í–‰"""
    metrics = collect_system_metrics()

    for metric_name, thresholds in PERFORMANCE_METRICS.items():
        current_value = metrics.get(metric_name, 0)

        if current_value >= thresholds['critical']:
            send_alert(f"CRITICAL: {metric_name} = {current_value}")
        elif current_value >= thresholds['warning']:
            send_alert(f"WARNING: {metric_name} = {current_value}")
```

---

## ê²°ë¡ 

### ABU ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ìš”ì•½

ABU ì‹œìŠ¤í…œì€ **WhatsApp ê¸°ë°˜ ì‹¤ì‹œê°„ ë¬¼ë¥˜ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜**ì„ **RDF ì˜¨í†¨ë¡œì§€**ë¡œ ë³€í™˜í•˜ì—¬ **ì§€ëŠ¥í˜• ë¬¼ë¥˜ ê´€ë¦¬ í”Œë«í¼**ì„ êµ¬í˜„í•œ í˜ì‹ ì ì¸ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

**í•µì‹¬ ì•„í‚¤í…ì²˜ íŠ¹ì§•**:
- ğŸ”„ **ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬**: 67,499ê°œ ë©”ì‹œì§€ ì‹¤ì‹œê°„ íŒŒì‹±
- ğŸ§  **ì§€ëŠ¥í˜• ë¶„ì„**: íŒ¨í„´ ë°œê²¬ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ì¶”ë¡ 
- ğŸ”— **í†µí•© ì˜¨í†¨ë¡œì§€**: 23,331 triples í†µí•© ì§€ì‹ ê·¸ë˜í”„
- âš¡ **ê³ ì„±ëŠ¥ ì²˜ë¦¬**: 120 msg/h, 0.5s ì¿¼ë¦¬ ì‘ë‹µ
- ğŸ›¡ï¸ **ë³´ì•ˆ ê°•í™”**: ë‹¤ì¸µ ë³´ì•ˆ ì•„í‚¤í…ì²˜
- ğŸ“ˆ **í™•ì¥ ê°€ëŠ¥**: ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ê¸°ë°˜ ìˆ˜í‰ í™•ì¥

**ê¸°ìˆ ì  í˜ì‹ **:
- **ì •ê·œí‘œí˜„ì‹ ê¸°ë°˜ íŒŒì‹±**: 95.2% ì •í™•ë„ ë‹¬ì„±
- **í¬ë¡œìŠ¤ ë ˆí¼ëŸ°ìŠ¤ ë§¤í•‘**: LPO â†” Message â†” Person ì—°ê²°
- **ì‹¤ì‹œê°„ ì•Œë¦¼ ì‹œìŠ¤í…œ**: 10Â·20Â·30 Rule ìë™ ëª¨ë‹ˆí„°ë§
- **RDF ì˜¨í†¨ë¡œì§€ ë³€í™˜**: í‘œì¤€í™”ëœ ì§€ì‹ í‘œí˜„

**ìš´ì˜ íš¨ê³¼**:
- **15% íš¨ìœ¨ì„± í–¥ìƒ**: ìë™í™” ë° ìµœì í™”
- **59% ë¹„ìš© ì ˆê°**: ì—°ê°„ $650,000 ì ˆê°
- **98/100 ì•ˆì „ ì ìˆ˜**: ë¦¬ìŠ¤í¬ ê´€ë¦¬ ê°•í™”
- **300% ROI**: 6ê°œì›” íˆ¬ì íšŒìˆ˜

### í–¥í›„ ë°œì „ ë°©í–¥

1. **AI/ML í†µí•©**: ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì˜ˆì¸¡ ë¶„ì„
2. **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°**: Apache Kafka ê¸°ë°˜ ì‹¤ì‹œê°„ ì²˜ë¦¬
3. **ê¸€ë¡œë²Œ í™•ì¥**: ë‹¤êµ­ê°€ ë¬¼ë¥˜ ë„¤íŠ¸ì›Œí¬ ì§€ì›
4. **ì˜¤í”ˆ ì†ŒìŠ¤í™”**: ì»¤ë®¤ë‹ˆí‹° ê¸°ë°˜ ê°œë°œ

---

## ì°¸ê³  ìë£Œ

### í•µì‹¬ ë¬¸ì„œ
- **ABU í†µí•© ìš”ì•½**: `reports/final/ABU_INTEGRATION_SUMMARY.md`
- **ABU ìš´ì˜ ëŒ€ì‹œë³´ë“œ**: `reports/final/ABU_OPERATIONS_DASHBOARD.md`
- **ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì¢…í•©**: `reports/final/SYSTEM_ARCHITECTURE_COMPREHENSIVE.md`

### ê¸°ìˆ  ìŠ¤íƒ
- **ì–¸ì–´**: Python 3.13+
- **í”„ë ˆì„ì›Œí¬**: rdflib, pandas, regex, FastAPI
- **ë°ì´í„°ë² ì´ìŠ¤**: PostgreSQL, Redis, Apache Jena Fuseki
- **ëª¨ë‹ˆí„°ë§**: Prometheus, Grafana, ELK Stack
- **ë°°í¬**: Docker, Kubernetes, NGINX

### í‘œì¤€ ë° ê·œê²©
- **RDF/OWL**: W3C í‘œì¤€ ì˜¨í†¨ë¡œì§€ ì–¸ì–´
- **SPARQL**: RDF ì¿¼ë¦¬ ì–¸ì–´
- **JSON-LD**: êµ¬ì¡°í™”ëœ ë°ì´í„° í‘œí˜„
- **REST API**: RESTful ì›¹ ì„œë¹„ìŠ¤ ì„¤ê³„

---

## ë²„ì „ ì •ë³´

**ì‹œìŠ¤í…œ ë²„ì „**: v3.1.0
**ì•„í‚¤í…ì²˜ ë²„ì „**: v1.0
**ë¬¸ì„œ ë²„ì „**: 1.0
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-01-21
**ì‘ì„±ì**: LogiOntology ì‹œìŠ¤í…œ

---

*ì´ ABU ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ë¬¸ì„œëŠ” LogiOntology v3.1 ì‹œìŠ¤í…œì˜ ê¸°ìˆ ì  ì„¤ê³„ì™€ êµ¬í˜„ ì„¸ë¶€ì‚¬í•­ì„ ì¢…í•©ì ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.*
*ë¬¼ë¥˜ ì˜¨í†¨ë¡œì§€ ì‹œìŠ¤í…œì˜ ì„±ê³µì ì¸ ì•„í‚¤í…ì²˜ ì‚¬ë¡€ë¡œ í™œìš©ë©ë‹ˆë‹¤.*
