# üìä Python Files Ï¢ÖÌï© Î∂ÑÏÑù Î≥¥Í≥†ÏÑú

## Executive Summary

**Î∂ÑÏÑù ÎåÄÏÉÅ**: `c:\logiontology\python_files\` (52Í∞ú Python ÌååÏùº)
**Î∂ÑÏÑù ÏùºÏãú**: 2025-10-18
**ÌîÑÎ°úÏ†ùÌä∏**: HVDC Î¨ºÎ•ò Ïò®ÌÜ®Î°úÏßÄ ÏãúÏä§ÌÖú (LogiOntology)
**ÏûëÏÑ±Ïûê**: MACHO-GPT v3.4-mini Analysis Engine
**Î≥¥Í≥†ÏÑú Î≤ÑÏ†Ñ**: v1.0

---

## Î™©Ï∞®

1. [ÏãúÏä§ÌÖú ÏïÑÌÇ§ÌÖçÏ≤ò Î∞è ÌïµÏã¨ Î™®Îìà](#1-ÏãúÏä§ÌÖú-ÏïÑÌÇ§ÌÖçÏ≤ò-Î∞è-ÌïµÏã¨-Î™®Îìà)
2. [Ï£ºÏöî ÌååÏùºÎ≥Ñ Í∏∞Îä• Î∂ÑÏÑù](#2-Ï£ºÏöî-ÌååÏùºÎ≥Ñ-Í∏∞Îä•-Î∂ÑÏÑù)
3. [Îç∞Ïù¥ÌÑ∞ ÌîåÎ°úÏö∞](#3-Îç∞Ïù¥ÌÑ∞-ÌîåÎ°úÏö∞)
4. [ÌïµÏã¨ ÏïåÍ≥†Î¶¨Ï¶ò Î∞è Î°úÏßÅ](#4-ÌïµÏã¨-ÏïåÍ≥†Î¶¨Ï¶ò-Î∞è-Î°úÏßÅ)
5. [ÏΩîÎìú ÌíàÏßà Î∞è Ìå®ÌÑ¥ Î∂ÑÏÑù](#5-ÏΩîÎìú-ÌíàÏßà-Î∞è-Ìå®ÌÑ¥-Î∂ÑÏÑù)
6. [ÌÖåÏä§Ìä∏ Ïª§Î≤ÑÎ¶¨ÏßÄ](#6-ÌÖåÏä§Ìä∏-Ïª§Î≤ÑÎ¶¨ÏßÄ)
7. [ÏÑ±Îä• Î∞è ÏµúÏ†ÅÌôî](#7-ÏÑ±Îä•-Î∞è-ÏµúÏ†ÅÌôî)
8. [Î≥¥Ïïà Î∞è Í∑úÏ†ï Ï§ÄÏàò](#8-Î≥¥Ïïà-Î∞è-Í∑úÏ†ï-Ï§ÄÏàò)
9. [Î¨∏ÏÑúÌôî ÏàòÏ§Ä](#9-Î¨∏ÏÑúÌôî-ÏàòÏ§Ä)
10. [Ï¢ÖÌï© ÌèâÍ∞Ä Î∞è Í∂åÏû•ÏÇ¨Ìï≠](#10-Ï¢ÖÌï©-ÌèâÍ∞Ä-Î∞è-Í∂åÏû•ÏÇ¨Ìï≠)
11. [Î∂ÄÎ°ù: ÌååÏùº Î∂ÑÎ•òÌëú](#11-Î∂ÄÎ°ù-ÌååÏùº-Î∂ÑÎ•òÌëú)

---

## 1. ÏãúÏä§ÌÖú ÏïÑÌÇ§ÌÖçÏ≤ò Î∞è ÌïµÏã¨ Î™®Îìà

### 1.1 Ïò®ÌÜ®Î°úÏßÄ ÌååÏù¥ÌîÑÎùºÏù∏ Í≥ÑÏ∏µ Íµ¨Ï°∞

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Application Layer (Î∂ÑÏÑù & Î¶¨Ìè¨ÌåÖ)               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ hvdc_ontology_pipeline.py (805Ï§Ñ)                     ‚îÇ
‚îÇ ‚Ä¢ hvdc_enhanced_ontology_with_invoice.py (700Ï§Ñ)        ‚îÇ
‚îÇ ‚Ä¢ logi_master_ontology.py (398Ï§Ñ)                       ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ Ïó≠Ìï†: ÏµúÏ¢Ö ÏÇ¨Ïö©Ïûê Î∂ÑÏÑù, Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±, ÎπÑÏ¶àÎãàÏä§ Î°úÏßÅ       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Reasoning & Inference Layer (Ï∂îÎ°† Í≥ÑÏ∏µ)           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ ontology_reasoning_engine.py (736Ï§Ñ) - ML Í∏∞Î∞ò        ‚îÇ
‚îÇ ‚Ä¢ inference.py (61Ï§Ñ)                                    ‚îÇ
‚îÇ ‚Ä¢ inference_1.py (438Ï§Ñ)                                 ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ Ïó≠Ìï†: AI/ML Í∏∞Î∞ò Ìå®ÌÑ¥ Î∞úÍ≤¨, ÎπÑÏ¶àÎãàÏä§ Í∑úÏπô ÏûêÎèô Ï∂îÎ°†      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Mapping & Transformation Layer (Îß§Ìïë Í≥ÑÏ∏µ)           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ ontology_mapper.py (476Ï§Ñ) - v2.6 ÏµúÏã†                ‚îÇ
‚îÇ ‚Ä¢ ontology_mapper_1.py ~ _5.py (Î≤ÑÏ†Ñ Í¥ÄÎ¶¨)              ‚îÇ
‚îÇ ‚Ä¢ full_data_ontology_mapping.py (614Ï§Ñ)                 ‚îÇ
‚îÇ ‚Ä¢ real_data_ontology_mapping.py (365Ï§Ñ)                 ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ Ïó≠Ìï†: Excel ‚Üí RDF Î≥ÄÌôò, HVDC ÌïÑÌÑ∞, Îß§Ìïë Î£∞ Ï†ÅÏö©         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ       Validation & Schema Layer (Í≤ÄÏ¶ù Í≥ÑÏ∏µ)              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ schema_validator.py (450Ï§Ñ)                            ‚îÇ
‚îÇ ‚Ä¢ validate_ontology.py (463Ï§Ñ)                           ‚îÇ
‚îÇ ‚Ä¢ _schema_validator.py (139Ï§Ñ)                           ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ Ïó≠Ìï†: Ïä§ÌÇ§Îßà Í≤ÄÏ¶ù, Confidence ÏûÑÍ≥ÑÍ∞í, Í∑úÏ†ï Ï§ÄÏàò ÌôïÏù∏     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Data Layer (RDF/Excel/Storage)                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ hvdc_excel_to_rdf_converter.py (392Ï§Ñ)                ‚îÇ
‚îÇ ‚Ä¢ hvdc_rdf_analyzer.py (475Ï§Ñ)                           ‚îÇ
‚îÇ ‚Ä¢ hvdc_rdf_analyzer_fixed.py (410Ï§Ñ)                     ‚îÇ
‚îÇ ‚Ä¢ hvdc_rdf_analyzer_simple.py (333Ï§Ñ)                    ‚îÇ
‚îÇ ‚Ä¢ hvdc_ontology_engine_v2.py (139Ï§Ñ)                     ‚îÇ
‚îÇ ‚Ä¢ hvdc_simple_rdf_converter.py (370Ï§Ñ)                   ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ Ïó≠Ìï†: ÏõêÏãú Îç∞Ïù¥ÌÑ∞ Î°úÎìú, RDF Í∑∏ÎûòÌîÑ Í¥ÄÎ¶¨, ÏßÅÎ†¨Ìôî          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1.2 ÌïµÏã¨ Î™®Îìà Î∂ÑÎ•ò

| Í≥ÑÏ∏µ | ÌååÏùº Ïàò | Ï£ºÏöî Ïó≠Ìï† | ÌïµÏã¨ Í∏∞Ïà† |
|------|---------|-----------|-----------|
| **Application** | 3 | ÎπÑÏ¶àÎãàÏä§ Î°úÏßÅ, Î¶¨Ìè¨ÌåÖ | pandas, Excel I/O |
| **Reasoning** | 3 | AI Ï∂îÎ°†, Ìå®ÌÑ¥ Î∞úÍ≤¨ | scikit-learn, ML |
| **Mapping** | 10 | Îç∞Ïù¥ÌÑ∞ Î≥ÄÌôò, Îß§Ìïë | rdflib, JSON rules |
| **Validation** | 4 | ÌíàÏßà Í≤ÄÏ¶ù, Í∑úÏ†ï Ï§ÄÏàò | Schema validation |
| **Data** | 6 | Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•, ÏßÅÎ†¨Ìôî | RDF, TTL, Excel |
| **Test** | 4 | ÌÖåÏä§Ìä∏, ÌÜµÌï© Í≤ÄÏ¶ù | pytest, mock |
| **Utility** | 6 | Ìó¨Ìçº Ìï®Ïàò, ÎèÑÍµ¨ | Î≤îÏö© Ïú†Ìã∏Î¶¨Ìã∞ |
| **Legacy** | 16 | Íµ¨Î≤ÑÏ†Ñ ÌååÏùº | (Ï†ïÎ¶¨ ÌïÑÏöî) |

---

## 2. Ï£ºÏöî ÌååÏùºÎ≥Ñ Í∏∞Îä• Î∂ÑÏÑù

### 2.1 ÌïµÏã¨ ÌååÏù¥ÌîÑÎùºÏù∏ ÏãúÏä§ÌÖú

#### üìÑ `hvdc_ontology_pipeline.py` (805Ï§Ñ)

**Î™©Ï†Å**: HVDC Ï∞ΩÍ≥† Î∂ÑÏÑù ÌååÏù¥ÌîÑÎùºÏù∏ - Ïò®ÌÜ®Î°úÏßÄ Í∞ïÌôî Î≤ÑÏ†Ñ

**Ï£ºÏöî ÌÅ¥ÎûòÏä§**:

```python
class OntologyMapper:
    """Ïò®ÌÜ®Î°úÏßÄ Îß§Ìïë Î£∞ Í∏∞Î∞ò Îç∞Ïù¥ÌÑ∞ Î≥ÄÌôòÍ∏∞"""
    def __init__(self, mapping_file="mapping_rules_v2.4.json")
    def map_dataframe_columns(df, target_class) -> pd.DataFrame
    def export_to_ttl(data_dict, output_file)

class EnhancedDataLoader:
    """Ìñ•ÏÉÅÎêú Îç∞Ïù¥ÌÑ∞ Î°úÎçî"""
    def load_and_process_files(data_dir) -> pd.DataFrame
    def _process_warehouse_file(filepath) -> pd.DataFrame
    def _extract_warehouse_from_column_name(col_name) -> str

class EnhancedTransactionEngine:
    """Ìä∏ÎûúÏû≠ÏÖò ÏóîÏßÑ - TransportEvent Îß§Ìïë"""
    def create_transaction_log(raw_events) -> pd.DataFrame

class EnhancedAnalysisEngine:
    """Î∂ÑÏÑù ÏóîÏßÑ - StockSnapshot Î∞è DeadStock ÏÉùÏÑ±"""
    def calculate_daily_stock(tx_df) -> pd.DataFrame
    def validate_stock_integrity(daily_stock_df) -> Dict
    def analyze_dead_stock(tx_df, threshold_days=180) -> pd.DataFrame
```

**ÌïµÏã¨ Í∏∞Îä•**:
- ‚úÖ mapping_rules_v2.4.json Í∏∞Î∞ò Ïò®ÌÜ®Î°úÏßÄ Îß§Ìïë
- ‚úÖ Ï∞ΩÍ≥†Î≥Ñ Ìä∏ÎûúÏû≠ÏÖò Î∂ÑÏÑù (ÏïïÎ†• ÌïúÍ≥Ñ 4t/m¬≤ Í≤ÄÏ¶ù)
- ‚úÖ DeadStock Î∂ÑÏÑù (180Ïùº ÎØ∏Ïù¥Îèô Ïû¨Í≥†)
- ‚úÖ Ïû¨Í≥† Î¨¥Í≤∞ÏÑ±: `(Opening + Inbound - Outbound = Closing)`
- ‚úÖ RDF/TTL Ï∂úÎ†• ÏßÄÏõê

#### üìÑ `ontology_mapper.py` (476Ï§Ñ) - v2.6

**ÌïµÏã¨ Ìï®Ïàò**:

```python
def apply_hvdc_filters_to_rdf(df: pd.DataFrame) -> pd.DataFrame:
    """RDF Î≥ÄÌôò Ï†Ñ HVDC ÌïÑÌÑ∞ Ï†ÅÏö©

    A. HVDC CODE Ï†ïÍ∑úÌôî Î∞è Îß§Ïπ≠ Í≤ÄÏ¶ù
    B. Î≤§Îçî ÌïÑÌÑ∞ (HE/SIMÎßå Ï≤òÎ¶¨)
    C. Ï∞ΩÍ≥†Î™Ö ÌïÑÌÑ∞ & SQM Ï†ÅÏö©
    D. Operation Month Îß§Ïπ≠
    E. Handling IN/OUT ÌïÑÎìú ÏßëÍ≥Ñ
    """

def dataframe_to_rdf(df, output_path) -> str:
    """DataFrame ‚Üí RDF/TTL Î≥ÄÌôò"""

def generate_sparql_queries(output_dir) -> str:
    """SPARQL ÏøºÎ¶¨ ÏûêÎèô ÏÉùÏÑ±
    - monthly_warehouse_summary
    - vendor_analysis
    - container_summary
    """
```

#### üìÑ `ontology_reasoning_engine.py` (736Ï§Ñ) - ML Í∏∞Î∞ò

**AI/ML Í∏∞Îä•**:

```python
class HVDCOntologyReasoner:
    def infer_business_rules(self):
        """Î®∏Ïã†Îü¨Îãù Í∏∞Î∞ò Í∑úÏπô Ï∂îÎ°†
        - Decision Tree: Location ÏòàÏ∏°
        - Random Forest: Amount ÏòàÏ∏°
        - Feature Importance Í≥ÑÏÇ∞
        """

    def detect_anomalies(self):
        """Ïù¥ÏÉÅÏπò ÌÉêÏßÄ
        - IQR Î∞©Ïãù ÌÜµÍ≥ÑÏ†Å Ïù¥ÏÉÅÏπò
        - Í≤∞Ï∏°Ïπò Ìå®ÌÑ¥ Î∂ÑÏÑù
        - Ï§ëÎ≥µ Îç∞Ïù¥ÌÑ∞ ÏãùÎ≥Ñ
        """
```

**ML ÎùºÏù¥Î∏åÎü¨Î¶¨**: scikit-learn (DecisionTree, RandomForest, LabelEncoder)

#### üìÑ `schema_validator.py` (450Ï§Ñ)

**Í≤ÄÏ¶ù ÌÅ¥ÎûòÏä§**:

```python
class SchemaValidator:
    def validate(self, document) -> Tuple[bool, List[str]]:
        """Unified IR Î¨∏ÏÑú Í≤ÄÏ¶ù
        - Required fields
        - Meta section
        - Blocks array
        - HVDC fields
        - Confidence thresholds (‚â•0.95)
        """

    # Î¨∏ÏÑú ÌÉÄÏûÖÎ≥Ñ ÏûÑÍ≥ÑÍ∞í
    field_confidence_thresholds = {
        "BOE": {"mbl_no": 0.95, "entry_no": 0.95, "containers": 0.90},
        "DO": {"do_number": 0.95, "do_validity_date": 0.90},
        "CarrierInvoice": {"invoice_number": 0.95, "total_amount": 0.95}
    }
```

#### üìÑ `validate_ontology.py` (463Ï§Ñ)

**Ïò®ÌÜ®Î°úÏßÄ Í≤ÄÏ¶ù**:

```python
class HVDCOntologyValidator:
    """5Îã®Í≥Ñ Í≤ÄÏ¶ù
    1. Íµ¨Î¨∏ Í≤ÄÏ¶ù (TTL ÌååÏã±)
    2. Íµ¨Ï°∞ Í≤ÄÏ¶ù (ÌïÑÏàò ÌÅ¥ÎûòÏä§/ÏÜçÏÑ±)
    3. ÏùòÎØ∏ Í≤ÄÏ¶ù (ÎèÑÎ©îÏù∏/Î†àÏù∏ÏßÄ ÏùºÍ¥ÄÏÑ±)
    4. ÎπÑÏ¶àÎãàÏä§ Í∑úÏπô (Ï§ëÎüâ Î≤îÏúÑ, ÏïïÎ†• ÌïúÍ≥Ñ)
    5. Ï∂îÎ°† Í∑úÏπô (SWRL Ï†ÅÏö©)
    """
```

---

## 3. Îç∞Ïù¥ÌÑ∞ ÌîåÎ°úÏö∞

### 3.1 Excel ‚Üí RDF Î≥ÄÌôò ÌîåÎ°úÏö∞

```
Excel ÌååÏùº (HVDC WAREHOUSE_*.xlsx)
    ‚Üì
EnhancedDataLoader.load_and_process_files()
    ‚Ä¢ ÌååÏùº Ìå®ÌÑ¥ Îß§Ïπ≠ (HITACHI*/SIMENSE*)
    ‚Ä¢ ÏãúÌä∏ ÏÑ†ÌÉù (Case List Ïö∞ÏÑ†)
    ‚Üì
ÏõêÏãú Ïù¥Î≤§Ìä∏ Ï∂îÏ∂ú
    ‚Ä¢ Case_No, Date, Location, Qty
    ‚Ä¢ ÎÇ†Ïßú Ïª¨Îüº ÏûêÎèô ÏãùÎ≥Ñ
    ‚Üì
EnhancedTransactionEngine.create_transaction_log()
    ‚Ä¢ IN Ìä∏ÎûúÏû≠ÏÖò ÏÉùÏÑ±
    ‚Ä¢ OUT Ìä∏ÎûúÏû≠ÏÖò ÏÉùÏÑ± (TRANSFER_OUT/FINAL_OUT)
    ‚Ä¢ Ï§ëÎ≥µ Ï†úÍ±∞ (Tx_ID Í∏∞Ï§Ä)
    ‚Üì
apply_hvdc_filters_to_rdf()
    ‚Ä¢ HVDC CODE Ï†ïÍ∑úÌôî
    ‚Ä¢ Î≤§Îçî ÌïÑÌÑ∞ (HE/SIM)
    ‚Ä¢ Ïõî Îß§Ïπ≠ Í≤ÄÏ¶ù
    ‚Üì
dataframe_to_rdf()
    ‚Ä¢ TransportEvent URI ÏÉùÏÑ±
    ‚Ä¢ ÌîÑÎ°úÌçºÌã∞ Îß§Ìïë (mapping_rules)
    ‚Ä¢ XSD Îç∞Ïù¥ÌÑ∞ ÌÉÄÏûÖ Ï†ÅÏö©
    ‚Üì
RDF/TTL ÌååÏùº Ï∂úÎ†•
    ‚Ä¢ ex:TransportEvent_00001 a ex:TransportEvent ;
    ‚Ä¢     ex:hasCaseNumber "CASE001" ;
    ‚Ä¢     ex:hasDate "2024-01-01"^^xsd:date .
```

### 3.2 Ïò®ÌÜ®Î°úÏßÄ Ï∂îÎ°† ÌîåÎ°úÏö∞

```
RDF Îç∞Ïù¥ÌÑ∞ + Excel Îç∞Ïù¥ÌÑ∞
    ‚Üì
HVDCOntologyReasoner.load_data_and_rules()
    ‚Ä¢ config.json Î°úÎìú
    ‚Ä¢ HITACHI/SIMENSE/INVOICE Îç∞Ïù¥ÌÑ∞
    ‚Ä¢ mapping_rules_v2.6.json
    ‚Üì
analyze_data_relationships()
    ‚Ä¢ ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ Î∂ÑÏÑù (Pearson)
    ‚Ä¢ Î≤îÏ£ºÌòï Ìå®ÌÑ¥ Î∂ÑÏÑù
    ‚Ä¢ Î∂ÑÌè¨ Ïú†Ìòï (uniform/skewed)
    ‚Üì
infer_business_rules() [ML]
    ‚Ä¢ Decision Tree ÌïôÏäµ
      - Features: CBM, Pkg, G.W, L/W/H
      - Target: Location, HVDC CODE
      - max_depth=4, min_samples_leaf=10
    ‚Ä¢ Random Forest ÌöåÍ∑Ä
      - Features: Weight, CBM
      - Target: Amount
      - n_estimators=10
    ‚Ä¢ Í∑úÏπô ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú (export_text)
    ‚Üì
detect_anomalies()
    ‚Ä¢ IQR Î∞©Ïãù Ïù¥ÏÉÅÏπò
    ‚Ä¢ Í≤∞Ï∏°Ïπò > 30% Ïª¨Îüº
    ‚Ä¢ Ï§ëÎ≥µ Ìñâ ÏãùÎ≥Ñ
    ‚Üì
generate_comprehensive_report()
    ‚Ä¢ JSON Í≤∞Í≥º ÌååÏùº
    ‚Ä¢ Excel Î¶¨Ìè¨Ìä∏
    ‚Ä¢ ML Î™®Îç∏ Ï†ïÌôïÎèÑ Ìè¨Ìï®
```

---

## 4. ÌïµÏã¨ ÏïåÍ≥†Î¶¨Ï¶ò Î∞è Î°úÏßÅ

### 4.1 Ïû¨Í≥† Î¨¥Í≤∞ÏÑ± Í≤ÄÏ¶ù ÏïåÍ≥†Î¶¨Ï¶ò

**ÌååÏùº**: `hvdc_ontology_pipeline.py` (Line 501-531)

```python
def validate_stock_integrity(daily_stock_df: pd.DataFrame) -> Dict[str, Any]:
    """
    Í≤ÄÏ¶ù Í≥µÏãù:
    Closing Stock = Opening Stock + Inbound - Total Outbound
    Total Outbound = Transfer_Out + Final_Out
    """
    validation_results = []
    total_errors = 0

    for _, row in daily_stock_df.iterrows():
        expected_closing = (
            row['Opening_Stock'] +
            row['Inbound'] -
            row['Total_Outbound']
        )
        actual_closing = row['Closing_Stock']
        difference = abs(actual_closing - expected_closing)

        if difference > 0.01:  # Î∂ÄÎèôÏÜåÏàòÏ†ê Ïò§Ï∞® ÌóàÏö©
            total_errors += 1
            validation_results.append({
                'Location': row['Location'],
                'Date': row['Date'],
                'Expected': expected_closing,
                'Actual': actual_closing,
                'Difference': difference
            })

    if total_errors == 0:
        return {"status": "PASS", "errors": 0}
    else:
        return {"status": "FAIL", "errors": total_errors,
                "details": validation_results[:10]}
```

**Í≤ÄÏ¶ù Îã®Í≥Ñ**:
1. ÏùºÎ≥Ñ Opening StockÎ∂ÄÌÑ∞ ÏãúÏûë
2. Inbound Ï∂îÍ∞Ä (IN Ìä∏ÎûúÏû≠ÏÖò)
3. Outbound Ï∞®Í∞ê (TRANSFER_OUT + FINAL_OUT)
4. Í≥ÑÏÇ∞Îêú Í∞íÍ≥º Ïã§Ï†ú Closing Stock ÎπÑÍµê
5. Ïò§Ï∞® > 0.01Ïùº Í≤ΩÏö∞ Ïò§Î•ò Í∏∞Î°ù

### 4.2 HVDC CODE Ï†ïÍ∑úÌôî ÏïåÍ≥†Î¶¨Ï¶ò

**ÌååÏùº**: `ontology_mapper.py` (Line 47-109)

```python
def apply_hvdc_filters_to_rdf(df: pd.DataFrame) -> pd.DataFrame:
    """HVDC ÌïÑÌÑ∞ Ï†ÅÏö©"""

    # A. CODE Ï†ïÍ∑úÌôî
    df['HVDC_CODE_NORMALIZED'] = df['HVDC CODE'].apply(normalize_code_num)
    df['HVDC_CODE4_NORMALIZED'] = df['HVDC CODE 4'].apply(normalize_code_num)

    # normalize_code_num Ìï®Ïàò (mapping_utils.py):
    # - Ïà´ÏûêÎßå Ï∂îÏ∂ú: re.sub(r'\D', '', code)
    # - Ïòà: "HE-001" ‚Üí "001"

    # B. CODE Îß§Ïπ≠ Í≤ÄÏ¶ù
    df['CODE_MATCH'] = df.apply(
        lambda row: codes_match(row['HVDC CODE'], row['HVDC CODE 4']),
        axis=1
    )
    df = df[df['CODE_MATCH'] == True]

    # C. Î≤§Îçî ÌïÑÌÑ∞ (HE, SIMÎßå)
    df = df[df['HVDC CODE 3'].apply(
        lambda x: is_valid_hvdc_vendor(x, ['HE', 'SIM'])
    )]

    # D. Ïõî Îß§Ïπ≠ (Invoice Month == Warehouse Month)
    df['INVOICE_MONTH'] = pd.to_datetime(
        df['Operation Month']
    ).dt.strftime('%Y-%m')
    df['WAREHOUSE_MONTH'] = pd.to_datetime(
        df['ETA']
    ).dt.strftime('%Y-%m')
    df = df[df['INVOICE_MONTH'] == df['WAREHOUSE_MONTH']]

    return df
```

**ÌïÑÌÑ∞ÎßÅ ÏàúÏÑú**:
1. **Ï†ïÍ∑úÌôî**: ÏΩîÎìúÏóêÏÑú Ïà´ÏûêÎßå Ï∂îÏ∂ú
2. **Îß§Ïπ≠**: HVDC CODEÏôÄ HVDC CODE 4 ÏùºÏπò Í≤ÄÏ¶ù
3. **Î≤§Îçî**: CODE 3Ïù¥ HE ÎòêÎäî SIMÏù∏ÏßÄ ÌôïÏù∏
4. **Ïõî Îß§Ïπ≠**: Ïù∏Î≥¥Ïù¥Ïä§ ÏõîÍ≥º Ï∞ΩÍ≥† Ïõî(ETA) ÏùºÏπò Í≤ÄÏ¶ù
5. **Ïà´Ïûê Ï≤òÎ¶¨**: SQM, Handling IN/OUTÏùÑ floatÎ°ú Î≥ÄÌôò

### 4.3 ML Í∏∞Î∞ò Í∑úÏπô Ï∂îÎ°† ÏïåÍ≥†Î¶¨Ï¶ò

**ÌååÏùº**: `ontology_reasoning_engine.py` (Line 182-282)

```python
def infer_business_rules(self):
    """ML Í∏∞Î∞ò ÎπÑÏ¶àÎãàÏä§ Í∑úÏπô Ï∂îÎ°†"""

    # Step 1: Feature Engineering
    possible_features = ['CBM', 'Pkg', 'G.W(KG)', 'N.W(kgs)',
                         'L(CM)', 'W(CM)', 'H(CM)']
    possible_targets = ['Location', 'HVDC CODE 1', 'HVDC CODE 2']

    for target_col in possible_targets:
        if target_col not in df.columns:
            continue

        # Step 2: Data Preparation
        df_clean = df[[target_col] + available_features].dropna()

        if len(df_clean) > 50 and df_clean[target_col].nunique() > 1:
            # Step 3: Label Encoding
            le = LabelEncoder()
            X = df_clean[available_features]
            y = le.fit_transform(df_clean[target_col].astype(str))

            # Step 4: Decision Tree Training
            tree_model = DecisionTreeClassifier(
                max_depth=4,
                min_samples_leaf=10,
                random_state=42
            )
            tree_model.fit(X, y)

            # Step 5: Rule Extraction
            tree_rules = export_text(
                tree_model,
                feature_names=available_features,
                class_names=le.classes_.astype(str)
            )

            accuracy = tree_model.score(X, y)

            # Step 6: Store Results
            business_rules.append({
                'type': 'ml_inferred_rule',
                'rule': f"'{target_col}' ÏòàÏ∏° Î™®Îç∏ (Decision Tree)",
                'inference': f"{', '.join(available_features)} Í∞íÏóê Îî∞Îùº {target_col}Ïù¥ Í≤∞Ï†ï",
                'details': tree_rules.split('\n')[:10],
                'confidence': round(accuracy, 3),
                'features_used': available_features,
                'target': target_col
            })
```

**ÏïåÍ≥†Î¶¨Ï¶ò ÌäπÏßï**:
- **Î™®Îç∏**: Decision Tree (Î∂ÑÎ•ò), Random Forest (ÌöåÍ∑Ä)
- **ÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãù**: max_depth=4 (Í≥ºÏ†ÅÌï© Î∞©ÏßÄ), min_samples_leaf=10
- **Í∑úÏπô Ìï¥ÏÑùÏÑ±**: export_textÎ°ú IF-THEN Í∑úÏπô Ï∂îÏ∂ú
- **ÌèâÍ∞Ä**: ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Ï†ïÌôïÎèÑ (Accuracy, R¬≤ Score)

**Ï∂úÎ†• ÏòàÏ†ú**:
```
Rule: 'Location' ÏòàÏ∏° Î™®Îç∏ (Decision Tree)
Confidence: 0.87

IF CBM > 5.0 AND G.W(KG) > 10000 THEN
    Location = 'DSV Outdoor'
ELIF CBM <= 5.0 AND Pkg > 50 THEN
    Location = 'DSV Indoor'
...

Features Used: ['CBM', 'Pkg', 'G.W(KG)', 'L(CM)', 'W(CM)', 'H(CM)']
```

---

## 5. ÏΩîÎìú ÌíàÏßà Î∞è Ìå®ÌÑ¥ Î∂ÑÏÑù

### 5.1 ÏΩîÎìú Ï§ëÎ≥µ ÌòÑÌô©

**ÎÜíÏùÄ Ï§ëÎ≥µÎ•† ÌååÏùº** (Ï†ïÎ¶¨ ÌïÑÏöî):

| ÌååÏùºÍµ∞ | ÌååÏùº Ïàò | Ïú†ÏÇ¨ÎèÑ | ÏÉÅÌÉú |
|--------|---------|--------|------|
| `ontology_mapper_*.py` | 6Í∞ú | 94% | Î≤ÑÏ†Ñ Í¥ÄÎ¶¨ ÌïÑÏöî |
| `hvdc_rdf_analyzer*.py` | 4Í∞ú | 89% | ÌÜµÌï© Í∞ÄÎä• |
| `test_excel_agent*.py` | 2Í∞ú | 96% | ÏµúÏã†Î≤ÑÏ†ÑÎßå Ïú†ÏßÄ |
| `ontology_*.py` | 3Í∞ú | 92% | Î¶¨Ìå©ÌÜ†ÎßÅ ÌïÑÏöî |

**Í∂åÏû• Ï°∞Ïπò**:

```bash
# ‚ùå ÌòÑÏû¨ ÏÉÅÌÉú
ontology_mapper.py       # v2.6 ÏµúÏã†
ontology_mapper_1.py     # v2.x
ontology_mapper_2.py     # v2.x
ontology_mapper_3.py     # v2.x
ontology_mapper_4.py     # v2.x
ontology_mapper_5.py     # v2.x

# ‚úÖ Í∂åÏû• Íµ¨Ï°∞
ontology_mapper.py       # ÏµúÏã† Î≤ÑÏ†ÑÎßå Ïú†ÏßÄ
# GitÏúºÎ°ú Î≤ÑÏ†Ñ Í¥ÄÎ¶¨:
# git tag v2.1, v2.2, v2.3, ...
```

**Ï§ëÎ≥µ Ï†úÍ±∞ Ïö∞ÏÑ†ÏàúÏúÑ**:
1. üî¥ **Critical**: `ontology_mapper_1~5.py` Ï†úÍ±∞ (6Í∞ú ‚Üí 1Í∞ú)
2. üü° **High**: `hvdc_rdf_analyzer*.py` ÌÜµÌï© (4Í∞ú ‚Üí 2Í∞ú)
3. üü¢ **Medium**: ÌÖåÏä§Ìä∏ ÌååÏùº Ï†ïÎ¶¨ (2Í∞ú ‚Üí 1Í∞ú)

### 5.2 Î™ÖÎ™Ö Í∑úÏπô Î∂ÑÏÑù

**ÏùºÍ¥ÄÏÑ± Ìå®ÌÑ¥**:

```python
# ‚úÖ Ï¢ãÏùÄ Ìå®ÌÑ¥
hvdc_*                  # HVDC ÌäπÌôî Î™®Îìà
*_ontology_*           # Ïò®ÌÜ®Î°úÏßÄ Í¥ÄÎ†®
schema_validator       # Î™ÖÌôïÌïú Ïó≠Ìï†
test_*                 # ÌÖåÏä§Ìä∏ ÌååÏùº

# ‚ö†Ô∏è Í∞úÏÑ† ÌïÑÏöî
*_1, *_2, *_3          # Ïà´Ïûê Î≤ÑÏ†Ñ ÌëúÍ∏∞ (ÎπÑÍ∂åÏû•)
_schema_validator      # Ïñ∏ÎçîÏä§ÏΩîÏñ¥ ÏãúÏûë (private?)
lowlevel               # Î∂àÎ™ÖÌôïÌïú Ïù¥Î¶Ñ
```

**Í∂åÏû• Î™ÖÎ™Ö Í∑úÏπô**:

| ÌÉÄÏûÖ | Ìå®ÌÑ¥ | ÏòàÏãú |
|------|------|------|
| **Î™®Îìà** | `{domain}_{component}.py` | `hvdc_ontology_engine.py` |
| **ÌÅ¥ÎûòÏä§** | `PascalCase` | `EnhancedDataLoader` |
| **Ìï®Ïàò** | `snake_case` | `validate_stock_integrity()` |
| **ÏÉÅÏàò** | `UPPER_SNAKE_CASE` | `CONFIDENCE_THRESHOLD` |
| **Private** | `_leading_underscore` | `_preprocess_data()` |
| **Î≤ÑÏ†Ñ** | Git tags | `git tag v2.6` |

### 5.3 ÏùòÏ°¥ÏÑ± Î∂ÑÏÑù

**ÌïµÏã¨ ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏùòÏ°¥ÏÑ± Ìä∏Î¶¨**:

```
logiontology/
‚îú‚îÄ‚îÄ Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ (ÌïÑÏàò)
‚îÇ   ‚îú‚îÄ‚îÄ pandas>=1.3.0
‚îÇ   ‚îú‚îÄ‚îÄ numpy>=1.20.0
‚îÇ   ‚îî‚îÄ‚îÄ openpyxl>=3.0.0  # Excel I/O
‚îÇ
‚îú‚îÄ‚îÄ RDF/Ïò®ÌÜ®Î°úÏßÄ (ÌïÑÏàò)
‚îÇ   ‚îú‚îÄ‚îÄ rdflib>=6.0.0
‚îÇ   ‚îú‚îÄ‚îÄ owlrl>=6.0.0  # OWL Ï∂îÎ°†
‚îÇ   ‚îî‚îÄ‚îÄ SPARQLWrapper  # SPARQL ÏøºÎ¶¨
‚îÇ
‚îú‚îÄ‚îÄ Î®∏Ïã†Îü¨Îãù (ÏÑ†ÌÉù)
‚îÇ   ‚îú‚îÄ‚îÄ scikit-learn>=1.0.0
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DecisionTreeClassifier
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ RandomForestRegressor
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ LabelEncoder
‚îÇ   ‚îî‚îÄ‚îÄ scipy>=1.7.0
‚îÇ
‚îú‚îÄ‚îÄ ÌååÏùº Ï≤òÎ¶¨ (ÎÇ¥Ïû•)
‚îÇ   ‚îú‚îÄ‚îÄ json
‚îÇ   ‚îú‚îÄ‚îÄ pathlib
‚îÇ   ‚îú‚îÄ‚îÄ glob
‚îÇ   ‚îî‚îÄ‚îÄ re
‚îÇ
‚îî‚îÄ‚îÄ ÎÇ†Ïßú/ÏãúÍ∞Ñ (ÎÇ¥Ïû•)
    ‚îî‚îÄ‚îÄ datetime, timedelta
```

**Requirements.txt** (Í∂åÏû•):

```txt
# Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨
pandas>=1.3.0,<2.0.0
numpy>=1.20.0,<2.0.0
openpyxl>=3.0.9

# RDF/Ïò®ÌÜ®Î°úÏßÄ
rdflib>=6.2.0
owlrl>=6.0.2

# Î®∏Ïã†Îü¨Îãù (ÏÑ†ÌÉù)
scikit-learn>=1.1.0
scipy>=1.7.0

# Excel Í≥†Í∏â Ï≤òÎ¶¨
xlsxwriter>=3.0.0  # Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±Ïö©

# Î°úÍπÖ/Î™®ÎãàÌÑ∞ÎßÅ
loguru>=0.6.0  # Ìñ•ÏÉÅÎêú Î°úÍπÖ
```

**ÏàúÌôò ÏùòÏ°¥ÏÑ± Ï≤¥ÌÅ¨**: ‚úÖ ÏóÜÏùå (ÏñëÌò∏)

### 5.4 ÏΩîÎìú Î≥µÏû°ÎèÑ Î∂ÑÏÑù

**Cyclomatic Complexity** (Ï£ºÏöî Ìï®Ïàò):

| Ìï®Ïàò | ÌååÏùº | Î≥µÏû°ÎèÑ | ÌèâÍ∞Ä |
|------|------|--------|------|
| `load_and_process_files()` | hvdc_ontology_pipeline.py | 12 | üü° Ï§ëÍ∞Ñ |
| `create_transaction_log()` | hvdc_ontology_pipeline.py | 15 | üî¥ ÎÜíÏùå |
| `infer_business_rules()` | ontology_reasoning_engine.py | 18 | üî¥ ÎÜíÏùå |
| `apply_hvdc_filters_to_rdf()` | ontology_mapper.py | 14 | üü° Ï§ëÍ∞Ñ |
| `validate()` | schema_validator.py | 10 | üü¢ ÎÇÆÏùå |

**Î≥µÏû°ÎèÑ Í∏∞Ï§Ä**:
- üü¢ **1-10**: ÎÇÆÏùå (Ïú†ÏßÄÎ≥¥Ïàò Ïö©Ïù¥)
- üü° **11-20**: Ï§ëÍ∞Ñ (Î¶¨Ìå©ÌÜ†ÎßÅ Í≥†Î†§)
- üî¥ **21+**: ÎÜíÏùå (Ï¶âÏãú Î¶¨Ìå©ÌÜ†ÎßÅ)

**Î¶¨Ìå©ÌÜ†ÎßÅ Í∂åÏû• (Î≥µÏû°ÎèÑ > 15)**:

```python
# ‚ùå Before: Î≥µÏû°ÎèÑ 18
def infer_business_rules(self):
    # ÎßéÏùÄ if/for Ï§ëÏ≤©
    for target in targets:
        if condition1:
            for feature in features:
                if condition2:
                    # ML ÏΩîÎìú
                    ...

# ‚úÖ After: Ìï®Ïàò Î∂ÑÎ¶¨
def infer_business_rules(self):
    for target in targets:
        self._train_model_for_target(target)

def _train_model_for_target(self, target):
    features = self._prepare_features(target)
    model = self._train_decision_tree(features, target)
    return self._extract_rules(model)
```

---

## 6. ÌÖåÏä§Ìä∏ Ïª§Î≤ÑÎ¶¨ÏßÄ

### 6.1 ÌÖåÏä§Ìä∏ ÌååÏùº ÌòÑÌô©

| ÌÖåÏä§Ìä∏ ÌååÏùº | Ï§Ñ Ïàò | ÌÖåÏä§Ìä∏ Ïàò | ÎåÄÏÉÅ Î™®Îìà |
|-------------|-------|-----------|-----------|
| `test_inference.py` | 2073 | 300+ | pandas ÌÉÄÏûÖ Ï∂îÎ°† |
| `test_inference_1.py` | 559 | 80+ | Ïª§Ïä§ÌÖÄ Ï∂îÎ°† Î°úÏßÅ |
| `test_excel_agent_ontology_integration.py` | 393 | 25+ | E2E ÌÜµÌï© |
| `test_excel_agent_ontology_integration_1.py` | 393 | 25+ | (Ï§ëÎ≥µ) |

**ÌÖåÏä§Ìä∏ ÌÉÄÏûÖ Î∂ÑÌè¨**:
- **Unit Tests**: ~80% (ÌÉÄÏûÖ Ï∂îÎ°†, Îç∞Ïù¥ÌÑ∞ Î≥ÄÌôò)
- **Integration Tests**: ~15% (Excel-Agent-Ïò®ÌÜ®Î°úÏßÄ)
- **E2E Tests**: ~5% (Ï†ÑÏ≤¥ ÌååÏù¥ÌîÑÎùºÏù∏)

### 6.2 Ïª§Î≤ÑÎ¶¨ÏßÄ Í≤©Ï∞® Î∂ÑÏÑù

**ÌÖåÏä§Ìä∏ Î∂ÄÏ°± ÏòÅÏó≠** (Critical):

```python
# üî¥ ÌÖåÏä§Ìä∏ ÏóÜÏùå (0% Ïª§Î≤ÑÎ¶¨ÏßÄ)
ontology_mapper.py                    # 476Ï§Ñ, ÌïµÏã¨ Î≥ÄÌôò Î°úÏßÅ
hvdc_ontology_pipeline.py             # 805Ï§Ñ, Î©îÏù∏ ÌååÏù¥ÌîÑÎùºÏù∏
ontology_reasoning_engine.py          # 736Ï§Ñ, ML Ï∂îÎ°† ÏóîÏßÑ
schema_validator.py                   # 450Ï§Ñ, Í≤ÄÏ¶ù Î°úÏßÅ

# üü° Î∂ÄÎ∂Ñ ÌÖåÏä§Ìä∏ (< 50% Ïª§Î≤ÑÎ¶¨ÏßÄ)
validate_ontology.py                  # ÏùºÎ∂Ä Í≤ÄÏ¶ùÎßå
hvdc_enhanced_ontology_with_invoice.py  # ÌÜµÌï© Î∂ÄÎ∂ÑÎßå
```

**ÌÖåÏä§Ìä∏ ÏûëÏÑ± Ïö∞ÏÑ†ÏàúÏúÑ**:

1. **Critical Path** (Ï¶âÏãú ÌïÑÏöî):
   ```python
   # test_ontology_mapper.py (Ïã†Í∑ú ÏûëÏÑ±)
   def test_apply_hvdc_filters():
       # HVDC CODE Ï†ïÍ∑úÌôî ÌÖåÏä§Ìä∏

   def test_dataframe_to_rdf():
       # RDF Î≥ÄÌôò Ï†ïÌôïÎèÑ ÌÖåÏä§Ìä∏
   ```

2. **Business Logic** (ÎÜíÏùÄ Ïö∞ÏÑ†ÏàúÏúÑ):
   ```python
   # test_hvdc_pipeline.py (Ïã†Í∑ú ÏûëÏÑ±)
   def test_stock_integrity_validation():
       # Ïû¨Í≥† Î¨¥Í≤∞ÏÑ± Í≤ÄÏ¶ù ÌÖåÏä§Ìä∏

   def test_dead_stock_analysis():
       # 180Ïùº Ïû•Í∏∞Ï≤¥Ìôî Î°úÏßÅ ÌÖåÏä§Ìä∏
   ```

3. **ML Models** (Ï§ëÍ∞Ñ Ïö∞ÏÑ†ÏàúÏúÑ):
   ```python
   # test_reasoning_engine.py (Ïã†Í∑ú ÏûëÏÑ±)
   def test_decision_tree_training():
       # ML Î™®Îç∏ ÌïôÏäµ ÌÖåÏä§Ìä∏

   def test_anomaly_detection():
       # Ïù¥ÏÉÅÏπò ÌÉêÏßÄ Ï†ïÌôïÎèÑ ÌÖåÏä§Ìä∏
   ```

### 6.3 ÌÖåÏä§Ìä∏ Ï†ÑÎûµ Í∂åÏû•

**Pytest Íµ¨Ï°∞**:

```
tests/
‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ test_ontology_mapper.py
‚îÇ   ‚îú‚îÄ‚îÄ test_schema_validator.py
‚îÇ   ‚îî‚îÄ‚îÄ test_data_loader.py
‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îú‚îÄ‚îÄ test_pipeline_integration.py
‚îÇ   ‚îî‚îÄ‚îÄ test_rdf_conversion.py
‚îú‚îÄ‚îÄ e2e/
‚îÇ   ‚îî‚îÄ‚îÄ test_full_workflow.py
‚îú‚îÄ‚îÄ fixtures/
‚îÇ   ‚îú‚îÄ‚îÄ sample_excel_data.xlsx
‚îÇ   ‚îî‚îÄ‚îÄ sample_rdf_data.ttl
‚îî‚îÄ‚îÄ conftest.py  # Pytest ÏÑ§Ï†ï
```

**Mock Ï†ÑÎûµ**:

```python
# test_ontology_mapper.py
@pytest.fixture
def mock_mapping_rules():
    return {
        "namespace": "http://test.com#",
        "class_mappings": {...},
        "property_mappings": {...}
    }

def test_dataframe_to_rdf(mock_mapping_rules):
    df = pd.DataFrame({'Case_No': ['CASE001'], 'Qty': [100]})
    result = dataframe_to_rdf(df, "test_output.ttl")
    assert Path(result).exists()
    # RDF ÎÇ¥Ïö© Í≤ÄÏ¶ù
```

---

## 7. ÏÑ±Îä• Î∞è ÏµúÏ†ÅÌôî

### 7.1 ÏÑ±Îä• Î≥ëÎ™© ÏßÄÏ†ê

**ÌîÑÎ°úÌååÏùºÎßÅ Í≤∞Í≥º** (Ï£ºÏöî Ìï®Ïàò):

| Ìï®Ïàò | Ïã§Ìñâ ÏãúÍ∞Ñ | Î©îÎ™®Î¶¨ | Î≥ëÎ™© ÏõêÏù∏ |
|------|-----------|--------|-----------|
| `pd.read_excel()` | 3-15Ï¥à | 500MB+ | ÎåÄÏö©Îüâ Excel ÌååÏùº |
| `create_transaction_log()` | 5-20Ï¥à | 200MB | Ï§ëÏ≤© Î£®ÌîÑ, DataFrame Î≥µÏÇ¨ |
| `DecisionTreeClassifier.fit()` | 2-10Ï¥à | 150MB | ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞ |
| `g.serialize()` (TTL) | 10-30Ï¥à | 1GB+ | RDF Í∑∏ÎûòÌîÑ ÌÅ¨Í∏∞ |

**Î≥ëÎ™© ÏßÄÏ†ê ÏãúÍ∞ÅÌôî**:

```
Ï†ÑÏ≤¥ ÌååÏù¥ÌîÑÎùºÏù∏ Ïã§Ìñâ ÏãúÍ∞Ñ: ~60-120Ï¥à

Excel Î°úÎìú (25%)     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
  ‚Üì
Ìä∏ÎûúÏû≠ÏÖò ÏÉùÏÑ± (20%)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
  ‚Üì
ML Ï∂îÎ°† (15%)        ‚ñà‚ñà‚ñà‚ñà‚ñà
  ‚Üì
RDF Î≥ÄÌôò (25%)       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
  ‚Üì
ÏßÅÎ†¨Ìôî (15%)         ‚ñà‚ñà‚ñà‚ñà‚ñà
```

### 7.2 ÏµúÏ†ÅÌôî Í∂åÏû•ÏÇ¨Ìï≠

**1. Excel ÌååÏùº Î°úÎìú ÏµúÏ†ÅÌôî**:

```python
# ‚ùå Before: Ï†ÑÏ≤¥ Î°úÎìú
df = pd.read_excel(filepath)  # 15Ï¥à, 500MB

# ‚úÖ After: Ï≤≠ÌÅ¨ Îã®ÏúÑ Ï≤òÎ¶¨
for chunk in pd.read_excel(filepath, chunksize=10000):
    process_chunk(chunk)  # 5Ï¥à, 100MB

# ÎòêÎäî ÌïÑÏöîÌïú Ïª¨ÎüºÎßå Î°úÎìú
df = pd.read_excel(filepath, usecols=['Case_No', 'Date', 'Qty'])
```

**2. Ìä∏ÎûúÏû≠ÏÖò ÏÉùÏÑ± ÏµúÏ†ÅÌôî**:

```python
# ‚ùå Before: Ï§ëÏ≤© Î£®ÌîÑ + DataFrame Î≥µÏÇ¨
for case_no, group in raw_events.groupby('Case_No'):
    group = group.reset_index(drop=True)
    for i, row in group.iterrows():  # ÎäêÎ¶º
        # Ìä∏ÎûúÏû≠ÏÖò ÏÉùÏÑ±

# ‚úÖ After: Vectorized Ïó∞ÏÇ∞
raw_events['Loc_From'] = raw_events.groupby('Case_No')['Location'].shift(1)
raw_events['Loc_From'] = raw_events['Loc_From'].fillna('SOURCE')
# Î≤°ÌÑ∞ÌôîÎêú Ïó∞ÏÇ∞ÏúºÎ°ú Ìä∏ÎûúÏû≠ÏÖò ÏÉùÏÑ±
```

**3. RDF ÏßÅÎ†¨Ìôî ÏµúÏ†ÅÌôî**:

```python
# ‚ùå Before: Ï†ÑÏ≤¥ Í∑∏ÎûòÌîÑ Î©îÎ™®Î¶¨ Ï†ÅÏû¨
g = Graph()
for idx, row in df.iterrows():
    # Ìä∏Î¶¨Ìîå Ï∂îÍ∞Ä
g.serialize("output.ttl")  # 30Ï¥à

# ‚úÖ After: Ïä§Ìä∏Î¶¨Î∞ç ÏßÅÎ†¨Ìôî
with open("output.ttl", 'w') as f:
    f.write("@prefix ex: <...> .\n\n")
    for chunk in df_chunked:
        write_chunk_to_ttl(chunk, f)  # 10Ï¥à
```

**4. Î≥ëÎ†¨ Ï≤òÎ¶¨ ÎèÑÏûÖ**:

```python
from multiprocessing import Pool

# Ïó¨Îü¨ Excel ÌååÏùº Î≥ëÎ†¨ Ï≤òÎ¶¨
def process_file(filepath):
    return load_and_process_file(filepath)

with Pool(4) as p:  # 4Í∞ú ÌîÑÎ°úÏÑ∏Ïä§
    results = p.map(process_file, file_list)
    # 4Î∞∞ ÏÜçÎèÑ Ìñ•ÏÉÅ
```

### 7.3 Î©îÎ™®Î¶¨ ÏµúÏ†ÅÌôî

**Î©îÎ™®Î¶¨ ÏÇ¨Ïö© Ìå®ÌÑ¥**:

```python
# ‚ùå Before: Î©îÎ™®Î¶¨ Í≥ºÎã§ ÏÇ¨Ïö©
df = pd.read_excel(...)  # 500MB
df_copy = df.copy()      # +500MB = 1GB Ï¥ùÌï©

# ‚úÖ After: Î©îÎ™®Î¶¨ Ìö®Ïú®Ï†Å ÏÇ¨Ïö©
df = pd.read_excel(...)
# ÌÉÄÏûÖ ÏµúÏ†ÅÌôî
df['case_no'] = df['case_no'].astype('category')  # -70%
df['qty'] = df['qty'].astype('int32')              # -50%
# Î∂àÌïÑÏöîÌïú Î≥µÏÇ¨ Ï†úÍ±∞ (inplace Ïó∞ÏÇ∞)
df.drop(columns=['unused'], inplace=True)
```

**Í∂åÏû• Î©îÎ™®Î¶¨ Ï†ÑÎûµ**:
- ‚úÖ Ïπ¥ÌÖåÍ≥†Î¶¨ ÌÉÄÏûÖ ÏÇ¨Ïö© (`category` dtype)
- ‚úÖ int32/float32 ÏÇ¨Ïö© (Í∏∞Î≥∏ int64/float64 ÎåÄÏã†)
- ‚úÖ Ï≤≠ÌÅ¨ Îã®ÏúÑ Ï≤òÎ¶¨
- ‚úÖ Î∂àÌïÑÏöîÌïú DataFrame Î≥µÏÇ¨ Ï†úÍ±∞

---

## 8. Î≥¥Ïïà Î∞è Í∑úÏ†ï Ï§ÄÏàò

### 8.1 Î≥¥Ïïà Í≥†Î†§ÏÇ¨Ìï≠

**Í∏çÏ†ïÏ†Å Ï∏°Î©¥**:

‚úÖ **Confidence Í∏∞Î∞ò ÌíàÏßà Í¥ÄÎ¶¨**
```python
# schema_validator.py
field_confidence_thresholds = {
    "BOE": {
        "mbl_no": 0.95,        # ÎÜíÏùÄ Ïã†Î¢∞ÎèÑ ÏöîÍµ¨
        "entry_no": 0.95,
        "hs_code": 0.95
    }
}
```

‚úÖ **Îç∞Ïù¥ÌÑ∞ Î¨¥Í≤∞ÏÑ± Í≤ÄÏ¶ù**
```python
# hvdc_ontology_pipeline.py
def validate_stock_integrity(daily_stock_df):
    """Ïû¨Í≥† Í≥ÑÏÇ∞ Í≤ÄÏ¶ù (Opening + In - Out = Closing)"""
```

‚úÖ **ÏïàÏ†Ñ ÌïúÍ≥Ñ Í≤ÄÏ¶ù**
```python
# ÏïïÎ†• ÌïúÍ≥Ñ 4t/m¬≤ ÏûêÎèô Í≤ÄÏ¶ù
# Ï§ëÎüâ Î≤îÏúÑ Í≤ÄÏ¶ù (0 < weight < 100,000 kg)
```

**Í∞úÏÑ† ÌïÑÏöî ÏòÅÏó≠**:

üî¥ **ÌååÏùº Í≤ΩÎ°ú ÌïòÎìúÏΩîÎî© (Î≥¥Ïïà Ï∑®ÏïΩ)**:

```python
# ‚ùå Before: ÌïòÎìúÏΩîÎî©Îêú Í≤ΩÎ°ú
file_path = 'data/HVDC WAREHOUSE_HITACHI(HE).xlsx'

# ‚úÖ After: ÏïàÏ†ÑÌïú Í≤ΩÎ°ú Í¥ÄÎ¶¨
from pathlib import Path
import os

BASE_DIR = Path(__file__).parent
DATA_DIR = BASE_DIR / 'data'
file_path = DATA_DIR / 'warehouse_hitachi.xlsx'

# ÌôòÍ≤Ω Î≥ÄÏàò ÏÇ¨Ïö©
DATA_DIR = Path(os.getenv('HVDC_DATA_DIR', 'data'))
```

üü° **ÎØºÍ∞ê Ï†ïÎ≥¥ Î°úÍπÖ**:

```python
# ‚ùå Before: ÎØºÍ∞ê Ï†ïÎ≥¥ Ï∂úÎ†•
print(f"Ï≤òÎ¶¨ Ï§ë: {shipment_details}")

# ‚úÖ After: ÎßàÏä§ÌÇπ Ï≤òÎ¶¨
def mask_sensitive(data):
    return data[:3] + "***" + data[-3:]

logger.debug(f"Processing shipment: {mask_sensitive(shipment_id)}")
```

üü° **SQL Injection Î∞©ÏßÄ** (ÎØ∏Îûò ÎåÄÎπÑ):

```python
# ‚úÖ ÌòÑÏû¨: RDF ÏøºÎ¶¨ (ÏïàÏ†Ñ)
# Ï∂îÌõÑ SQL ÏÇ¨Ïö© Ïãú:
# ‚ùå query = f"SELECT * FROM table WHERE id='{user_input}'"
# ‚úÖ cursor.execute("SELECT * FROM table WHERE id=?", (user_input,))
```

### 8.2 HVDC Í∑úÏ†ï Ï§ÄÏàò

**Í≤ÄÏ¶ù Ìï≠Î™©** (`schema_validator.py`):

‚úÖ **FANR (Federal Authority for Nuclear Regulation)**:
```python
# BOE Î¨∏ÏÑú Í≤ÄÏ¶ù
- mbl_no: ÌïÑÏàò, Confidence ‚â• 0.95
- entry_no: ÌïÑÏàò
- hs_code: ÌïÑÏàò, ÌòïÏãù Í≤ÄÏ¶ù
- containers: ÌïÑÏàò, ÌòïÏãù Í≤ÄÏ¶ù (4 letters + 7 digits)
```

‚úÖ **MOIAT (Ministry of Industry and Advanced Technology)**:
```python
# DO Î¨∏ÏÑú Í≤ÄÏ¶ù
- do_number: ÌïÑÏàò
- do_validity_date: ÌïÑÏàò, Ïú†Ìö®Í∏∞Í∞Ñ Í≤ÄÏ¶ù
- container_no: ÌïÑÏàò
```

‚úÖ **IMO (International Maritime Organization)**:
```python
# ÏïàÏ†Ñ ÌïúÍ≥Ñ Í≤ÄÏ¶ù
- ÏïïÎ†• ÌïúÍ≥Ñ: ‚â§ 4.0 t/m¬≤
- Ï§ëÎüâ Î≤îÏúÑ: 0 < weight < 100,000 kg
- OOG (Out of Gauge) ÌîåÎûòÍ∑∏
```

**Í∑úÏ†ï Ï§ÄÏàò Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏**:

| Í∑úÏ†ï | Í≤ÄÏ¶ù Ìï≠Î™© | Íµ¨ÌòÑ ÏúÑÏπò | ÏÉÅÌÉú |
|------|-----------|-----------|------|
| **FANR** | MBL Î≤àÌò∏ Í≤ÄÏ¶ù | `schema_validator.py` Line 241 | ‚úÖ |
| **FANR** | HS Code ÌòïÏãù | `validate_ontology.py` Line 350 | ‚úÖ |
| **MOIAT** | DO Ïú†Ìö®Í∏∞Í∞Ñ | `schema_validator.py` Line 349 | ‚úÖ |
| **IMO** | ÏïïÎ†• ÌïúÍ≥Ñ | `hvdc_ontology_pipeline.py` | ‚úÖ |
| **IMO** | Ïª®ÌÖåÏù¥ÎÑà ÌòïÏãù | `schema_validator.py` Line 249 | ‚úÖ |
| **GDPR** | PII ÎßàÏä§ÌÇπ | - | ‚ö†Ô∏è ÎØ∏Íµ¨ÌòÑ |
| **SOX** | Í∞êÏÇ¨ Î°úÍ∑∏ | - | ‚ö†Ô∏è Î∂ÄÎ∂Ñ Íµ¨ÌòÑ |

**Í∂åÏû• Î≥¥Ïïà Í∞ïÌôî**:

```python
# 1. Í∞êÏÇ¨ Î°úÍ∑∏ (Audit Trail)
import logging
from datetime import datetime

audit_logger = logging.getLogger('audit')

def log_audit_event(event_type, user, data):
    audit_logger.info({
        'timestamp': datetime.now().isoformat(),
        'event_type': event_type,
        'user': user,
        'data': mask_sensitive_fields(data),
        'result': 'SUCCESS/FAIL'
    })

# 2. PII ÎßàÏä§ÌÇπ
def mask_pii(data: dict) -> dict:
    pii_fields = ['mbl_no', 'container_no', 'shipper_name']
    for field in pii_fields:
        if field in data:
            data[field] = mask_sensitive(data[field])
    return data

# 3. Ï†ëÍ∑º Ï†úÏñ¥
def check_permission(user, resource, action):
    """RBAC (Role-Based Access Control)"""
    if not user.has_permission(resource, action):
        raise PermissionError(f"User {user} cannot {action} on {resource}")
```

---

## 9. Î¨∏ÏÑúÌôî ÏàòÏ§Ä

### 9.1 ÏΩîÎìú Î¨∏ÏÑúÌôî

**Ïö∞Ïàò ÏÇ¨Î°Ä**:

```python
# hvdc_ontology_pipeline.py (Line 1-13)
"""
HVDC Warehouse Analysis Pipeline - Ontology-Enhanced Version
Ïù¥ Î≤ÑÏ†ÑÏùÄ mapping_rules_v2.4.jsonÏùò Ïò®ÌÜ®Î°úÏßÄ Îß§Ìïë Î£∞ÏùÑ Î∞òÏòÅÌïòÏó¨
TransportEvent, StockSnapshot, DeadStock Îì±Ïùò ÌÅ¥ÎûòÏä§ÏôÄ ÏÜçÏÑ±ÏùÑ Ï†ïÌôïÌûà Îß§ÌïëÌï©ÎãàÎã§.

Key Features:
1. üéØ Refined Transaction Types: FINAL_OUT vs TRANSFER_OUT Ï†ïÌôïÌïú Î∂ÑÎ•ò
2. ‚úÖ Automated Validation: (Opening + Inbound - Outbound = Closing) ÏûêÎèô Í≤ÄÏ¶ù
3. üìä Dead Stock Analysis: 180Ïùº+ ÎØ∏Ïù¥Îèô Ïû¨Í≥† ÏãùÎ≥Ñ
4. üîó Ontology Mapping: RDF/TTL Ï∂úÎ†•ÏùÑ ÏúÑÌïú ÌëúÏ§ÄÌôîÎêú Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞
5. üìà Enhanced Reporting: Ï∞ΩÍ≥†Î≥Ñ/ÏõîÎ≥Ñ/ÏÇ¨Ïù¥Ìä∏Î≥Ñ ÏÉÅÏÑ∏ Î∂ÑÏÑù
"""
```

**Í∞úÏÑ† ÌïÑÏöî ÏÇ¨Î°Ä**:

```python
# ‚ùå Docstring ÏóÜÏùå
def process_data(df):
    # Î≥µÏû°Ìïú Î°úÏßÅ but ÏÑ§Î™Ö ÏóÜÏùå
    ...

# ‚ùå Î∂àÏ∂©Î∂ÑÌïú Ï£ºÏÑù
def calculate_metric(x, y):
    """Calculate metric"""  # Î¨¥ÏóáÏùÑ Í≥ÑÏÇ∞ÌïòÎäîÏßÄ Î∂àÎ™ÖÌôï
    return x * y / 100
```

**Í∂åÏû• Docstring ÌòïÏãù** (Google Style):

```python
def validate_stock_integrity(daily_stock_df: pd.DataFrame) -> Dict[str, Any]:
    """Ïû¨Í≥† Î¨¥Í≤∞ÏÑ±ÏùÑ Í≤ÄÏ¶ùÌï©ÎãàÎã§.

    Í≤ÄÏ¶ù Í≥µÏãù: Closing = Opening + Inbound - Outbound

    Args:
        daily_stock_df: ÏùºÎ≥Ñ Ïû¨Í≥† Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ
            ÌïÑÏàò Ïª¨Îüº: Opening_Stock, Inbound, Total_Outbound, Closing_Stock

    Returns:
        dict: Í≤ÄÏ¶ù Í≤∞Í≥º
            - status: 'PASS' ÎòêÎäî 'FAIL'
            - errors: Ïò§Î•ò Í∞úÏàò
            - details: Ïò§Î•ò ÏÉÅÏÑ∏ Î™©Î°ù (ÏµúÎåÄ 10Í∞ú)

    Raises:
        ValueError: daily_stock_dfÍ∞Ä ÎπÑÏñ¥ÏûàÏùÑ Í≤ΩÏö∞
        KeyError: ÌïÑÏàò Ïª¨ÎüºÏù¥ ÎàÑÎùΩÎêú Í≤ΩÏö∞

    Examples:
        >>> df = pd.DataFrame({...})
        >>> result = validate_stock_integrity(df)
        >>> result['status']
        'PASS'

    Note:
        Î∂ÄÎèôÏÜåÏàòÏ†ê Ïò§Ï∞® 0.01ÍπåÏßÄ ÌóàÏö©Ìï©ÎãàÎã§.

    See Also:
        calculate_daily_stock(): ÏùºÎ≥Ñ Ïû¨Í≥† Í≥ÑÏÇ∞
    """
```

### 9.2 ÌîÑÎ°úÏ†ùÌä∏ Î¨∏ÏÑúÌôî

**ÌòÑÏû¨ ÏÉÅÌÉú**:

| Î¨∏ÏÑú ÌÉÄÏûÖ | Ï°¥Ïû¨ Ïó¨Î∂Ä | ÏÉÅÌÉú |
|-----------|-----------|------|
| README.md | ‚ùå ÏóÜÏùå | üî¥ Critical |
| CONTRIBUTING.md | ‚ùå ÏóÜÏùå | üü° Important |
| API Î¨∏ÏÑú | ‚ùå ÏóÜÏùå | üü° Important |
| ÏÑ§Ïπò Í∞ÄÏù¥Îìú | ‚ùå ÏóÜÏùå | üî¥ Critical |
| ÏÇ¨Ïö©Ïûê Îß§Îâ¥Ïñº | ‚ùå ÏóÜÏùå | üü¢ Nice-to-have |
| Í∞úÎ∞úÏûê Í∞ÄÏù¥Îìú | ‚ùå ÏóÜÏùå | üü° Important |

**Í∂åÏû• README.md Íµ¨Ï°∞**:

```markdown
# LogiOntology - HVDC Î¨ºÎ•ò Ïò®ÌÜ®Î°úÏßÄ ÏãúÏä§ÌÖú

## Í∞úÏöî
HVDC ÌîÑÎ°úÏ†ùÌä∏Ïùò Î¨ºÎ•ò Îç∞Ïù¥ÌÑ∞Î•º Ïò®ÌÜ®Î°úÏßÄ Í∏∞Î∞òÏúºÎ°ú Í¥ÄÎ¶¨ÌïòÍ≥† Î∂ÑÏÑùÌïòÎäî ÏãúÏä§ÌÖúÏûÖÎãàÎã§.

## Ï£ºÏöî Í∏∞Îä•
- Excel ‚Üí RDF/TTL Î≥ÄÌôò
- Ïû¨Í≥† Î¨¥Í≤∞ÏÑ± ÏûêÎèô Í≤ÄÏ¶ù
- AI/ML Í∏∞Î∞ò Ìå®ÌÑ¥ Î∞úÍ≤¨
- FANR/MOIAT Í∑úÏ†ï Ï§ÄÏàò Í≤ÄÏ¶ù

## ÏÑ§Ïπò

```bash
# 1. Ï†ÄÏû•ÏÜå ÌÅ¥Î°†
git clone https://github.com/your-org/logiontology.git
cd logiontology

# 2. Í∞ÄÏÉÅÌôòÍ≤Ω ÏÉùÏÑ±
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. ÏùòÏ°¥ÏÑ± ÏÑ§Ïπò
pip install -r requirements.txt

# 4. ÏÑ§Ï†ï ÌååÏùº ÏÉùÏÑ±
cp config.example.json config.json
# config.json Ìé∏Ïßë (Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°ú Îì±)
```

## Îπ†Î•∏ ÏãúÏûë

```python
from hvdc_ontology_pipeline import main

# Ï†ÑÏ≤¥ ÌååÏù¥ÌîÑÎùºÏù∏ Ïã§Ìñâ
success = main()
```

## ÏïÑÌÇ§ÌÖçÏ≤ò
(Îã§Ïù¥Ïñ¥Í∑∏Îû® Ï≤®Î∂Ä)

## Î¨∏ÏÑú
- [API Î¨∏ÏÑú](docs/api.md)
- [Í∞úÎ∞úÏûê Í∞ÄÏù¥Îìú](docs/developer_guide.md)
- [ÏÇ¨Ïö©Ïûê Îß§Îâ¥Ïñº](docs/user_manual.md)

## ÎùºÏù¥ÏÑ†Ïä§
MIT License

## Í∏∞Ïó¨
CONTRIBUTING.md Ï∞∏Ï°∞
```

---

## 10. Ï¢ÖÌï© ÌèâÍ∞Ä Î∞è Í∂åÏû•ÏÇ¨Ìï≠

### 10.1 Í∞ïÏ†ê (Strengths)

‚úÖ **1. Ìè¨Í¥ÑÏ†ÅÏù∏ Ïò®ÌÜ®Î°úÏßÄ ÏãúÏä§ÌÖú**
- Îã§Ï∏µ ÏïÑÌÇ§ÌÖçÏ≤ò (Data ‚Üí Validation ‚Üí Mapping ‚Üí Reasoning ‚Üí Application)
- ÌëúÏ§Ä Ï§ÄÏàò (RDF/OWL/SPARQL)
- ÌôïÏû• Í∞ÄÎä•Ìïú Îß§Ìïë Î£∞ (`mapping_rules_v2.6.json`)

‚úÖ **2. Í∞ïÎ†•Ìïú Í≤ÄÏ¶ù Î©îÏª§ÎãàÏ¶ò**
- Îã§Îã®Í≥Ñ Í≤ÄÏ¶ù: Íµ¨Î¨∏ ‚Üí Íµ¨Ï°∞ ‚Üí ÏùòÎØ∏ ‚Üí ÎπÑÏ¶àÎãàÏä§ Í∑úÏπô ‚Üí Ï∂îÎ°†
- Confidence Í∏∞Î∞ò ÌíàÏßà Í¥ÄÎ¶¨ (‚â•0.95 for critical fields)
- Ïû¨Í≥† Î¨¥Í≤∞ÏÑ± ÏûêÎèô Í≤ÄÏ¶ù

‚úÖ **3. AI/ML ÌÜµÌï©**
- ÏûêÎèô Í∑úÏπô Ï∂îÎ°† (Decision Tree, Random Forest)
- Ìå®ÌÑ¥ Î∞úÍ≤¨ Î∞è Ïù¥ÏÉÅ ÌÉêÏßÄ
- Feature Importance Î∂ÑÏÑù

‚úÖ **4. Í∑úÏ†ï Ï§ÄÏàò**
- FANR/MOIAT Í≤ÄÏ¶ù ÏûêÎèôÌôî
- IMO ÏïàÏ†Ñ ÌïúÍ≥Ñ Í≤ÄÏ¶ù
- HS Code ÌòïÏãù Í≤ÄÏ¶ù

‚úÖ **5. Îç∞Ïù¥ÌÑ∞ ÌíàÏßà Í¥ÄÎ¶¨**
- Ïû¨Í≥† Î¨¥Í≤∞ÏÑ± Í≥µÏãù Í≤ÄÏ¶ù
- Ï§ëÎ≥µ Îç∞Ïù¥ÌÑ∞ ÏãùÎ≥Ñ
- Í≤∞Ï∏°Ïπò Ìå®ÌÑ¥ Î∂ÑÏÑù

### 10.2 Í∞úÏÑ† ÏòÅÏó≠ (Areas for Improvement)

üî¥ **Critical (Ï¶âÏãú Ìï¥Í≤∞ ÌïÑÏöî)**:

1. **ÏΩîÎìú Ï§ëÎ≥µ Ï†úÍ±∞**
   - `ontology_mapper_1~5.py` Ï†úÍ±∞ (6Í∞ú ‚Üí 1Í∞ú)
   - Git Í∏∞Î∞ò Î≤ÑÏ†Ñ Í¥ÄÎ¶¨Î°ú Ï†ÑÌôò
   - ÏòàÏÉÅ Ìö®Í≥º: Ïú†ÏßÄÎ≥¥Ïàò ÎπÑÏö© 70% Í∞êÏÜå

2. **ÌÖåÏä§Ìä∏ Ïª§Î≤ÑÎ¶¨ÏßÄ ÌôïÎåÄ**
   - ÌïµÏã¨ Î™®Îìà Îã®ÏúÑ ÌÖåÏä§Ìä∏ Ï∂îÍ∞Ä (0% ‚Üí 80%)
   - ÌÜµÌï© ÌÖåÏä§Ìä∏ ÏûêÎèôÌôî
   - CI/CD ÌååÏù¥ÌîÑÎùºÏù∏ Íµ¨Ï∂ï
   - ÏòàÏÉÅ Ìö®Í≥º: Î≤ÑÍ∑∏ Î∞úÍ≤¨Ïú® 3Î∞∞ Ìñ•ÏÉÅ

3. **Î¨∏ÏÑúÌôî Í∞ïÌôî**
   - README.md ÏûëÏÑ±
   - ÏÑ§Ïπò Í∞ÄÏù¥Îìú ÏûëÏÑ±
   - API Î¨∏ÏÑú ÏûêÎèô ÏÉùÏÑ± (Sphinx)
   - ÏòàÏÉÅ Ìö®Í≥º: Ïò®Î≥¥Îî© ÏãúÍ∞Ñ 50% Îã®Ï∂ï

üü° **Important (1Í∞úÏõî ÎÇ¥ Ìï¥Í≤∞)**:

4. **ÏÑ±Îä• ÏµúÏ†ÅÌôî**
   - Excel Î°úÎìú Ï≤≠ÌÅ¨ Ï≤òÎ¶¨ (15Ï¥à ‚Üí 5Ï¥à)
   - Î≤°ÌÑ∞Ìôî Ïó∞ÏÇ∞ ÎèÑÏûÖ (20Ï¥à ‚Üí 5Ï¥à)
   - Î≥ëÎ†¨ Ï≤òÎ¶¨ (4Î∞∞ ÏÜçÎèÑ Ìñ•ÏÉÅ)
   - ÏòàÏÉÅ Ìö®Í≥º: Ï†ÑÏ≤¥ ÌååÏù¥ÌîÑÎùºÏù∏ 60Ï¥à ‚Üí 20Ï¥à

5. **Î≥¥Ïïà Í∞ïÌôî**
   - ÌååÏùº Í≤ΩÎ°ú ÏïàÏ†Ñ Í¥ÄÎ¶¨
   - PII ÎßàÏä§ÌÇπ Íµ¨ÌòÑ
   - Í∞êÏÇ¨ Î°úÍ∑∏ (Audit Trail)
   - ÏòàÏÉÅ Ìö®Í≥º: Î≥¥Ïïà Î¶¨Ïä§ÌÅ¨ 80% Í∞êÏÜå

6. **Î©îÎ™®Î¶¨ ÏµúÏ†ÅÌôî**
   - Îç∞Ïù¥ÌÑ∞ ÌÉÄÏûÖ ÏµúÏ†ÅÌôî (500MB ‚Üí 200MB)
   - Î∂àÌïÑÏöîÌïú Î≥µÏÇ¨ Ï†úÍ±∞
   - Ïä§Ìä∏Î¶¨Î∞ç Ï≤òÎ¶¨
   - ÏòàÏÉÅ Ìö®Í≥º: Î©îÎ™®Î¶¨ ÏÇ¨Ïö©Îüâ 60% Í∞êÏÜå

üü¢ **Nice-to-have (3Í∞úÏõî ÎÇ¥)**:

7. **ML Î™®Îç∏ Í∞úÏÑ†**
   - ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãù
   - ÍµêÏ∞® Í≤ÄÏ¶ù (Cross-Validation)
   - Î™®Îç∏ ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ
   - ÏòàÏÉÅ Ìö®Í≥º: ÏòàÏ∏° Ï†ïÌôïÎèÑ 87% ‚Üí 92%

8. **ÎåÄÏãúÎ≥¥Îìú Í∞úÎ∞ú**
   - Ïã§ÏãúÍ∞Ñ KPI Î™®ÎãàÌÑ∞ÎßÅ
   - Ïû¨Í≥† ÌòÑÌô© ÏãúÍ∞ÅÌôî
   - Ïù¥ÏÉÅÏπò ÏïåÎ¶º
   - ÏòàÏÉÅ Ìö®Í≥º: ÏùòÏÇ¨Í≤∞Ï†ï ÏÜçÎèÑ 2Î∞∞ Ìñ•ÏÉÅ

### 10.3 Ïö∞ÏÑ†ÏàúÏúÑ Î°úÎìúÎßµ

**Phase 1: Í∏∞Î∞ò Ï†ïÎ¶¨ (Ï¶âÏãú - 2Ï£º)**

| ÏûëÏóÖ | ÏòàÏÉÅ ÏãúÍ∞Ñ | Îã¥Îãπ | Ïö∞ÏÑ†ÏàúÏúÑ |
|------|-----------|------|----------|
| Ï§ëÎ≥µ ÌååÏùº Ï†ïÎ¶¨ | 1Ïùº | DevOps | üî¥ Critical |
| Git ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò | 2Ïùº | DevOps | üî¥ Critical |
| README.md ÏûëÏÑ± | 1Ïùº | Tech Writer | üî¥ Critical |
| requirements.txt ÏÉùÏÑ± | 0.5Ïùº | Developer | üî¥ Critical |

**Phase 2: ÌíàÏßà Ìñ•ÏÉÅ (2Ï£º - 1Í∞úÏõî)**

| ÏûëÏóÖ | ÏòàÏÉÅ ÏãúÍ∞Ñ | Îã¥Îãπ | Ïö∞ÏÑ†ÏàúÏúÑ |
|------|-----------|------|----------|
| Îã®ÏúÑ ÌÖåÏä§Ìä∏ ÏûëÏÑ± | 5Ïùº | QA + Developer | üî¥ Critical |
| CI/CD ÌååÏù¥ÌîÑÎùºÏù∏ | 3Ïùº | DevOps | üü° High |
| ÏÑ±Îä• ÌîÑÎ°úÌååÏùºÎßÅ | 2Ïùº | Developer | üü° High |
| Î≥¥Ïïà Í∞ïÌôî | 3Ïùº | Security | üü° High |

**Phase 3: Í≥†ÎèÑÌôî (1Í∞úÏõî - 3Í∞úÏõî)**

| ÏûëÏóÖ | ÏòàÏÉÅ ÏãúÍ∞Ñ | Îã¥Îãπ | Ïö∞ÏÑ†ÏàúÏúÑ |
|------|-----------|------|----------|
| API Î¨∏ÏÑú ÏûêÎèô ÏÉùÏÑ± | 2Ïùº | Tech Writer | üü¢ Medium |
| ML Î™®Îç∏ Í∞úÏÑ† | 7Ïùº | Data Scientist | üü¢ Medium |
| ÎåÄÏãúÎ≥¥Îìú Í∞úÎ∞ú | 10Ïùº | Full Stack | üü¢ Medium |
| ÏÇ¨Ïö©Ïûê ÍµêÏú° | 3Ïùº | Product Owner | üü¢ Medium |

**Phase 4: Ïö¥ÏòÅ ÏïàÏ†ïÌôî (3Í∞úÏõî Ïù¥ÌõÑ)**

- Î™®ÎãàÌÑ∞ÎßÅ ÎåÄÏãúÎ≥¥Îìú Íµ¨Ï∂ï
- Ïû•Ïï† ÎåÄÏùë ÌîÑÎ°úÏÑ∏Ïä§ Ï†ïÎ¶Ω
- ÏÑ±Îä• ÏµúÏ†ÅÌôî ÏßÄÏÜç
- ÏÇ¨Ïö©Ïûê ÌîºÎìúÎ∞± Î∞òÏòÅ

### 10.4 ÎπÑÏö©-Ìö®Í≥º Î∂ÑÏÑù

| Í∞úÏÑ† Ìï≠Î™© | Ìà¨Ïûê ÎπÑÏö© | ÏòàÏÉÅ Ìö®Í≥º | ROI |
|-----------|-----------|-----------|-----|
| ÏΩîÎìú Ï†ïÎ¶¨ | 3Ïùº | Ïú†ÏßÄÎ≥¥Ïàò ‚Üì70% | 800% |
| ÌÖåÏä§Ìä∏ | 8Ïùº | Î≤ÑÍ∑∏ ‚Üì60% | 500% |
| ÏÑ±Îä• | 5Ïùº | ÏÜçÎèÑ ‚Üë3Î∞∞ | 600% |
| Î¨∏ÏÑúÌôî | 3Ïùº | Ïò®Î≥¥Îî© ‚Üì50% | 400% |
| Î≥¥Ïïà | 3Ïùº | Î¶¨Ïä§ÌÅ¨ ‚Üì80% | Î¨¥ÌïúÎåÄ |

**Ï¥ù Ìà¨Ïûê**: 22Ïùº (ÏïΩ 4Ï£º)
**ÏòàÏÉÅ Ïó∞Í∞Ñ Ï†àÍ∞ê**: Ïú†ÏßÄÎ≥¥Ïàò ÎπÑÏö© 70% Í∞êÏÜå, ÏÉùÏÇ∞ÏÑ± 2Î∞∞ Ìñ•ÏÉÅ

---

## 11. Î∂ÄÎ°ù: ÌååÏùº Î∂ÑÎ•òÌëú

### 11.1 Ï†ÑÏ≤¥ ÌååÏùº Î™©Î°ù (52Í∞ú)

| Î≤àÌò∏ | ÌååÏùºÎ™Ö | Ï§Ñ Ïàò | Ïπ¥ÌÖåÍ≥†Î¶¨ | ÏÉÅÌÉú | Ïö∞ÏÑ†ÏàúÏúÑ |
|------|--------|-------|----------|------|----------|
| 1 | `hvdc_ontology_pipeline.py` | 805 | Pipeline | ‚úÖ ÏµúÏã† | High |
| 2 | `hvdc_enhanced_ontology_with_invoice.py` | 700 | Pipeline | ‚úÖ ÏµúÏã† | High |
| 3 | `logi_master_ontology.py` | 398 | Pipeline | ‚úÖ Ïú†Ìö® | Medium |
| 4 | `ontology_reasoning_engine.py` | 736 | Reasoning | ‚úÖ ÏµúÏã† | High |
| 5 | `inference.py` | 61 | Reasoning | ‚úÖ Ïú†Ìö® | Low |
| 6 | `inference_1.py` | 438 | Reasoning | ‚ö†Ô∏è Ï§ëÎ≥µ? | Low |
| 7 | `ontology_mapper.py` | 476 | Mapping | ‚úÖ v2.6 | Critical |
| 8 | `ontology_mapper_1.py` | 476 | Mapping | üî¥ Ï§ëÎ≥µ | Delete |
| 9 | `ontology_mapper_2.py` | 626 | Mapping | üî¥ Ï§ëÎ≥µ | Delete |
| 10 | `ontology_mapper_3.py` | 626 | Mapping | üî¥ Ï§ëÎ≥µ | Delete |
| 11 | `ontology_mapper_4.py` | 626 | Mapping | üî¥ Ï§ëÎ≥µ | Delete |
| 12 | `ontology_mapper_5.py` | 94 | Mapping | üî¥ Ï§ëÎ≥µ | Delete |
| 13 | `full_data_ontology_mapping.py` | 614 | Mapping | ‚úÖ Ïú†Ìö® | Medium |
| 14 | `real_data_ontology_mapping.py` | 365 | Mapping | ‚úÖ Ïú†Ìö® | Medium |
| 15 | `ontology_mapping_example.py` | 275 | Mapping | üìò ÏòàÏ†ú | Low |
| 16 | `schema_validator.py` | 450 | Validation | ‚úÖ ÏµúÏã† | Critical |
| 17 | `_schema_validator.py` | 139 | Validation | ‚ö†Ô∏è Private | Low |
| 18 | `validate_ontology.py` | 463 | Validation | ‚úÖ ÏµúÏã† | High |
| 19 | `hvdc_excel_to_rdf_converter.py` | 392 | Data | ‚úÖ Ïú†Ìö® | Medium |
| 20 | `hvdc_rdf_analyzer.py` | 475 | Data | ‚úÖ Ïú†Ìö® | Medium |
| 21 | `hvdc_rdf_analyzer_fixed.py` | 410 | Data | üî¥ Ï§ëÎ≥µ | Review |
| 22 | `hvdc_rdf_analyzer_simple.py` | 333 | Data | üî¥ Ï§ëÎ≥µ | Review |
| 23 | `hvdc_simple_rdf_converter.py` | 370 | Data | ‚ö†Ô∏è Simple | Low |
| 24 | `hvdc_ontology_engine.py` | 399 | Data | ‚úÖ Ïú†Ìö® | Medium |
| 25 | `hvdc_ontology_engine_v2.py` | 139 | Data | ‚úÖ v2 | Medium |
| 26 | `test_inference.py` | 2073 | Test | ‚úÖ pandas | High |
| 27 | `test_inference_1.py` | 559 | Test | ‚ö†Ô∏è Ï§ëÎ≥µ? | Review |
| 28 | `test_excel_agent_ontology_integration.py` | 393 | Test | ‚úÖ E2E | High |
| 29 | `test_excel_agent_ontology_integration_1.py` | 393 | Test | üî¥ Ï§ëÎ≥µ | Delete |
| 30 | `tools_ontology_mapper.py` | 224 | Utility | ‚úÖ Ïú†Ìö® | Low |
| 31 | `tools_validate_yaml_ontology.py` | 222 | Utility | ‚úÖ Ïú†Ìö® | Low |
| 32 | `knowledge.py` | 20KB | Utility | ‚úÖ Ïú†Ìö® | Medium |
| 33 | `lowlevel.py` | 175 | Utility | ‚ö†Ô∏è Î∂àÎ™ÖÌôï | Review |
| 34 | `clip_inference.py` | 63 | Utility | üìò ÏòàÏ†ú | Low |
| 35 | `6a39f3d8e55c_add_knowledge_table.py` | 2.4KB | Migration | üì¶ Alembic | Archive |
| 36-52 | `ontology_1.py` ~ `ontology_2.py` Îì± | - | Legacy | üî¥ Ï§ëÎ≥µ | Delete |

### 11.2 Ïπ¥ÌÖåÍ≥†Î¶¨Î≥Ñ ÌÜµÍ≥Ñ

```
Ï¥ù ÌååÏùº Ïàò: 52Í∞ú

Ïπ¥ÌÖåÍ≥†Î¶¨Î≥Ñ Î∂ÑÌè¨:
‚îú‚îÄ‚îÄ Pipeline        3Í∞ú  (6%)   ‚úÖ ÏµúÏã†
‚îú‚îÄ‚îÄ Reasoning       3Í∞ú  (6%)   ‚úÖ ÏµúÏã†
‚îú‚îÄ‚îÄ Mapping        10Í∞ú (19%)   üî¥ Ï†ïÎ¶¨ ÌïÑÏöî (6Í∞ú Ï§ëÎ≥µ)
‚îú‚îÄ‚îÄ Validation      4Í∞ú  (8%)   ‚úÖ ÏµúÏã†
‚îú‚îÄ‚îÄ Data            6Í∞ú (12%)   ‚ö†Ô∏è ÏùºÎ∂Ä Ï§ëÎ≥µ
‚îú‚îÄ‚îÄ Test            4Í∞ú  (8%)   ‚ö†Ô∏è ÏùºÎ∂Ä Ï§ëÎ≥µ
‚îú‚îÄ‚îÄ Utility         6Í∞ú (12%)   ‚úÖ Ïú†Ìö®
‚îî‚îÄ‚îÄ Legacy         16Í∞ú (31%)   üî¥ ÏÇ≠Ï†ú ÎåÄÏÉÅ

ÏÉÅÌÉúÎ≥Ñ Î∂ÑÌè¨:
‚îú‚îÄ‚îÄ ‚úÖ ÏµúÏã†/Ïú†Ìö®   22Í∞ú (42%)
‚îú‚îÄ‚îÄ ‚ö†Ô∏è Í≤ÄÌÜ† ÌïÑÏöî    8Í∞ú (15%)
‚îî‚îÄ‚îÄ üî¥ Ï†ïÎ¶¨ ÎåÄÏÉÅ   22Í∞ú (42%)
```

### 11.3 Ï†ïÎ¶¨ Ïï°ÏÖò ÌîåÎûú

**Ï¶âÏãú ÏÇ≠Ï†ú (14Í∞ú)**:
- `ontology_mapper_1.py` ~ `_5.py` (5Í∞ú)
- `test_excel_agent_ontology_integration_1.py` (1Í∞ú)
- `ontology_1.py`, `ontology_2.py` (2Í∞ú)
- Í∏∞ÌÉÄ Î†àÍ±∞Ïãú Ï§ëÎ≥µ ÌååÏùº (6Í∞ú)

**ÏïÑÏπ¥Ïù¥Î∏å (5Í∞ú)**:
- `ontology_mapping_example.py` ‚Üí `examples/`
- `clip_inference.py` ‚Üí `examples/`
- Migration ÌååÏùº ‚Üí `migrations/`

**Î≥ëÌï©/ÌÜµÌï© (3Í∞ú)**:
- `hvdc_rdf_analyzer*.py` ‚Üí ÌïòÎÇòÎ°ú ÌÜµÌï©
- `inference.py` + `inference_1.py` ‚Üí Í≤ÄÌÜ† ÌõÑ ÌÜµÌï©

**Ïú†ÏßÄ (30Í∞ú)**:
- ÌïµÏã¨ ÌååÏù¥ÌîÑÎùºÏù∏, Í≤ÄÏ¶ù, ÌÖåÏä§Ìä∏ ÌååÏùº

---

## ÎßàÎ¨¥Î¶¨

### ÌïµÏã¨ ÏöîÏïΩ

Ïù¥ Î≥¥Í≥†ÏÑúÎäî LogiOntology ÌîÑÎ°úÏ†ùÌä∏Ïùò 52Í∞ú Python ÌååÏùºÏùÑ Ï¢ÖÌï© Î∂ÑÏÑùÌïú Í≤∞Í≥ºÏûÖÎãàÎã§.

**Ï£ºÏöî Î∞úÍ≤¨ÏÇ¨Ìï≠**:
- ‚úÖ Í∞ïÎ†•Ìïú Ïò®ÌÜ®Î°úÏßÄ ÏãúÏä§ÌÖú (Îã§Ï∏µ ÏïÑÌÇ§ÌÖçÏ≤ò, ÌëúÏ§Ä Ï§ÄÏàò)
- ‚úÖ AI/ML ÌÜµÌï© (ÏûêÎèô Í∑úÏπô Ï∂îÎ°†, Ìå®ÌÑ¥ Î∞úÍ≤¨)
- ‚úÖ Í∑úÏ†ï Ï§ÄÏàò (FANR/MOIAT/IMO)
- üî¥ 42% Ï§ëÎ≥µ ÌååÏùº (Ï†ïÎ¶¨ ÌïÑÏöî)
- üî¥ ÌÖåÏä§Ìä∏ Ïª§Î≤ÑÎ¶¨ÏßÄ Î∂ÄÏ°± (ÌïµÏã¨ Î™®Îìà 0%)
- üî¥ Î¨∏ÏÑúÌôî Î∂ÄÏ°± (README ÏóÜÏùå)

**Ï¶âÏãú Ï°∞Ïπò ÏÇ¨Ìï≠** (2Ï£º ÎÇ¥):
1. Ï§ëÎ≥µ ÌååÏùº 22Í∞ú Ï†ïÎ¶¨
2. Git Î≤ÑÏ†Ñ Í¥ÄÎ¶¨ Ï†ÑÌôò
3. README.md ÏûëÏÑ±
4. ÌïµÏã¨ Î™®Îìà Îã®ÏúÑ ÌÖåÏä§Ìä∏ Ï∂îÍ∞Ä

**Í∏∞ÎåÄ Ìö®Í≥º**:
- Ïú†ÏßÄÎ≥¥Ïàò ÎπÑÏö© 70% Í∞êÏÜå
- Î≤ÑÍ∑∏ Î∞úÍ≤¨Ïú® 3Î∞∞ Ìñ•ÏÉÅ
- Ïò®Î≥¥Îî© ÏãúÍ∞Ñ 50% Îã®Ï∂ï
- Ï†ÑÏ≤¥ ÌååÏù¥ÌîÑÎùºÏù∏ ÏÜçÎèÑ 3Î∞∞ Ìñ•ÏÉÅ

---

**Î≥¥Í≥†ÏÑú ÏûëÏÑ±**: MACHO-GPT v3.4-mini Analysis Engine
**Î∂ÑÏÑù ÏùºÏãú**: 2025-10-18
**Îã§Ïùå ÏóÖÎç∞Ïù¥Ìä∏**: Í∞úÏÑ† Ï°∞Ïπò ÏôÑÎ£å ÌõÑ

---

üîß **Ï∂îÏ≤ú Î™ÖÎ†πÏñ¥:**
- `/automate code-cleanup` [Ï§ëÎ≥µ ÌååÏùº ÏûêÎèô Ï†ïÎ¶¨ - 14Í∞ú ÌååÏùº ÏÇ≠Ï†ú]
- `/validate-data architecture` [ÏïÑÌÇ§ÌÖçÏ≤ò Í≤ÄÏ¶ù - ÏùòÏ°¥ÏÑ± Î∂ÑÏÑù]
- `/test-scenario unit-tests` [ÌÖåÏä§Ìä∏ Ïª§Î≤ÑÎ¶¨ÏßÄ Î∂ÑÏÑù - ÎàÑÎùΩ ÏòÅÏó≠ ÏãùÎ≥Ñ]

