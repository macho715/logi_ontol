#!/usr/bin/env python3
"""
Lightning RDF ì—”í‹°í‹° ëŒ€í­ ë³´ê°• ìŠ¤í¬ë¦½íŠ¸

CSV ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ Lightning RDFì— ëˆ„ë½ëœ ì—”í‹°í‹°ë“¤ì„ ì¶”ê°€í•©ë‹ˆë‹¤:
- Operation (ì‘ì—…): 34ê°œ ì‘ì—… íƒ€ì…
- Site (ìœ„ì¹˜): 22ê°œ ìœ„ì¹˜ (ë³´ê°•)
- Vessel (ì„ ë°•): 30ê°œ ì„ ë°• (ë³´ê°•)
- ì—”í‹°í‹° ê°„ ê´€ê³„ ë§¤í•‘ ê°•í™”
"""

import sys
import csv
import json
from pathlib import Path
from collections import defaultdict, Counter
from datetime import datetime
import rdflib
from rdflib import Namespace, RDF, RDFS, XSD, Literal

# UTF-8 ì¶œë ¥ ì„¤ì •
sys.stdout.reconfigure(encoding="utf-8")

# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì •ì˜
LIGHTNING = Namespace("http://example.org/lightning/")
LIGHTNINGI = Namespace("http://example.org/lightning/instance/")


def load_csv_entities(csv_path):
    """CSVì—ì„œ ì—”í‹°í‹° ë¡œë“œ"""
    entities_by_category = defaultdict(list)

    print(f"ğŸ“Š CSV íŒŒì¼ ë¡œë“œ ì¤‘: {csv_path}")

    with open(csv_path, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            if row.get("Category") and row.get("Entity"):
                category = row["Category"]
                entity = row["Entity"]
                count = int(row["Count"]) if row.get("Count") else 0

                entities_by_category[category].append(
                    {"entity": entity, "count": count}
                )

    # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
    stats = {}
    for category, entities in entities_by_category.items():
        total_mentions = sum(e["count"] for e in entities)
        unique_count = len(entities)
        stats[category] = {"unique": unique_count, "total_mentions": total_mentions}
        print(
            f"  - {category}: {unique_count}ê°œ ê³ ìœ  ì—”í‹°í‹°, {total_mentions:,}íšŒ ì–¸ê¸‰"
        )

    return entities_by_category, stats


def load_existing_rdf(rdf_path):
    """ê¸°ì¡´ Lightning RDF ë¡œë“œ"""
    print(f"\nğŸ“– ê¸°ì¡´ Lightning RDF ë¡œë“œ ì¤‘: {rdf_path}")
    g = rdflib.Graph()
    g.parse(rdf_path, format="turtle")

    # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë°”ì¸ë”©
    g.bind("lightning", LIGHTNING)
    g.bind("lightningi", LIGHTNINGI)

    print(f"  - ë¡œë“œëœ íŠ¸ë¦¬í”Œ: {len(g):,}ê°œ")
    return g


def normalize_entity_name(entity_name):
    """ì—”í‹°í‹° ì´ë¦„ ì •ê·œí™” (URIìš©)"""
    # ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ, íŠ¹ìˆ˜ë¬¸ì ì œê±°
    normalized = entity_name.replace(" ", "_").replace("/", "_")
    normalized = "".join(c for c in normalized if c.isalnum() or c == "_" or c == "-")
    return normalized


def add_operation_entities(graph, csv_entities):
    """Operation ì—”í‹°í‹° ì¶”ê°€"""
    print("\nâš¡ Operation ì—”í‹°í‹° ì¶”ê°€ ì¤‘...")

    operations = csv_entities.get("Operation", [])
    added_count = 0

    for op_data in operations:
        op_name = op_data["entity"]
        op_count = op_data["count"]

        # Operation URI ìƒì„±
        op_uri = LIGHTNINGI[f"Operation_{normalize_entity_name(op_name)}"]

        # Operation íŠ¸ë¦¬í”Œ ì¶”ê°€
        graph.add((op_uri, RDF.type, LIGHTNING.Operation))
        graph.add((op_uri, LIGHTNING.operationType, Literal(op_name)))
        graph.add(
            (op_uri, LIGHTNING.mentionCount, Literal(op_count, datatype=XSD.integer))
        )
        graph.add((op_uri, RDFS.label, Literal(op_name)))

        # ì‘ì—… ìœ í˜• ë¶„ë¥˜
        if "loading" in op_name.lower():
            graph.add((op_uri, LIGHTNING.operationCategory, Literal("Loading")))
        elif "offloading" in op_name.lower() or "offload" in op_name.lower():
            graph.add((op_uri, LIGHTNING.operationCategory, Literal("Offloading")))
        elif "roro" in op_name.lower():
            graph.add((op_uri, LIGHTNING.operationCategory, Literal("RORO")))
        elif "lolo" in op_name.lower():
            graph.add((op_uri, LIGHTNING.operationCategory, Literal("LOLO")))
        elif "anchorage" in op_name.lower() or "berth" in op_name.lower():
            graph.add((op_uri, LIGHTNING.operationCategory, Literal("Berthing")))
        elif "bunker" in op_name.lower():
            graph.add((op_uri, LIGHTNING.operationCategory, Literal("Bunkering")))
        else:
            graph.add((op_uri, LIGHTNING.operationCategory, Literal("General")))

        added_count += 1

    print(f"  âœ… {added_count}ê°œ Operation ì—”í‹°í‹° ì¶”ê°€ ì™„ë£Œ")
    return added_count


def add_site_entities(graph, csv_entities):
    """Site ì—”í‹°í‹° ì¶”ê°€/ë³´ê°•"""
    print("\nğŸ­ Site ì—”í‹°í‹° ì¶”ê°€ ì¤‘...")

    sites = csv_entities.get("Site", [])
    added_count = 0

    for site_data in sites:
        site_name = site_data["entity"]
        site_count = site_data["count"]

        # Site URI ìƒì„±
        site_uri = LIGHTNINGI[f"Site_{normalize_entity_name(site_name)}"]

        # Site íŠ¸ë¦¬í”Œ ì¶”ê°€
        graph.add((site_uri, RDF.type, LIGHTNING.Site))
        graph.add((site_uri, LIGHTNING.siteName, Literal(site_name)))
        graph.add(
            (
                site_uri,
                LIGHTNING.mentionCount,
                Literal(site_count, datatype=XSD.integer),
            )
        )
        graph.add((site_uri, RDFS.label, Literal(site_name)))

        # ìœ„ì¹˜ ìœ í˜• ë¶„ë¥˜
        if site_name.upper() in ["DAS", "DAS"]:
            graph.add((site_uri, LIGHTNING.siteType, Literal("Port")))
            graph.add((site_uri, LIGHTNING.siteCode, Literal("DAS")))
        elif site_name.upper() in ["AGI", "AGI"]:
            graph.add((site_uri, LIGHTNING.siteType, Literal("Terminal")))
            graph.add((site_uri, LIGHTNING.siteCode, Literal("AGI")))
        elif site_name.upper() in ["MOSB", "MOSB"]:
            graph.add((site_uri, LIGHTNING.siteType, Literal("Port")))
            graph.add((site_uri, LIGHTNING.siteCode, Literal("MOSB")))
        elif site_name.upper() in ["SHU", "SHU"]:
            graph.add((site_uri, LIGHTNING.siteType, Literal("Port")))
            graph.add((site_uri, LIGHTNING.siteCode, Literal("SHU")))
        elif site_name.upper() in ["MW4", "MW4"]:
            graph.add((site_uri, LIGHTNING.siteType, Literal("Warehouse")))
            graph.add((site_uri, LIGHTNING.siteCode, Literal("MW4")))
        elif site_name.upper() in ["MIR", "MIR"]:
            graph.add((site_uri, LIGHTNING.siteType, Literal("Port")))
            graph.add((site_uri, LIGHTNING.siteCode, Literal("MIR")))
        else:
            graph.add((site_uri, LIGHTNING.siteType, Literal("Location")))

        added_count += 1

    print(f"  âœ… {added_count}ê°œ Site ì—”í‹°í‹° ì¶”ê°€ ì™„ë£Œ")
    return added_count


def add_vessel_entities(graph, csv_entities):
    """Vessel ì—”í‹°í‹° ì¶”ê°€/ë³´ê°•"""
    print("\nğŸš¢ Vessel ì—”í‹°í‹° ì¶”ê°€ ì¤‘...")

    vessels = csv_entities.get("Vessel", [])
    added_count = 0

    for vessel_data in vessels:
        vessel_name = vessel_data["entity"]
        vessel_count = vessel_data["count"]

        # Vessel URI ìƒì„±
        vessel_uri = LIGHTNINGI[f"Vessel_{normalize_entity_name(vessel_name)}"]

        # Vessel íŠ¸ë¦¬í”Œ ì¶”ê°€
        graph.add((vessel_uri, RDF.type, LIGHTNING.Vessel))
        graph.add((vessel_uri, LIGHTNING.vesselName, Literal(vessel_name)))
        graph.add(
            (
                vessel_uri,
                LIGHTNING.mentionCount,
                Literal(vessel_count, datatype=XSD.integer),
            )
        )
        graph.add((vessel_uri, RDFS.label, Literal(vessel_name)))

        # ì„ ë°• ìœ í˜• ë¶„ë¥˜
        if "JPT" in vessel_name.upper() or "JOPETWIL" in vessel_name.upper():
            graph.add((vessel_uri, LIGHTNING.vesselType, Literal("Cargo")))
            graph.add((vessel_uri, LIGHTNING.vesselCategory, Literal("JPT")))
        elif "THURAYA" in vessel_name.upper():
            graph.add((vessel_uri, LIGHTNING.vesselType, Literal("Cargo")))
            graph.add((vessel_uri, LIGHTNING.vesselCategory, Literal("THURAYA")))
        elif "RAZAN" in vessel_name.upper():
            graph.add((vessel_uri, LIGHTNING.vesselType, Literal("Cargo")))
            graph.add((vessel_uri, LIGHTNING.vesselCategory, Literal("RAZAN")))
        elif "BUSHRA" in vessel_name.upper():
            graph.add((vessel_uri, LIGHTNING.vesselType, Literal("Cargo")))
            graph.add((vessel_uri, LIGHTNING.vesselCategory, Literal("BUSHRA")))
        elif "MARWAH" in vessel_name.upper():
            graph.add((vessel_uri, LIGHTNING.vesselType, Literal("Cargo")))
            graph.add((vessel_uri, LIGHTNING.vesselCategory, Literal("MARWAH")))
        else:
            graph.add((vessel_uri, LIGHTNING.vesselType, Literal("Cargo")))
            graph.add((vessel_uri, LIGHTNING.vesselCategory, Literal("Other")))

        added_count += 1

    print(f"  âœ… {added_count}ê°œ Vessel ì—”í‹°í‹° ì¶”ê°€ ì™„ë£Œ")
    return added_count


def create_enhanced_relationships(graph, csv_entities):
    """ì—”í‹°í‹° ê°„ ê´€ê³„ ë§¤í•‘ ê°•í™”"""
    print("\nğŸ”— ì—”í‹°í‹° ê°„ ê´€ê³„ ë§¤í•‘ ê°•í™” ì¤‘...")

    relationships_added = 0

    # Operation â†” Site ê´€ê³„ (ì£¼ìš” ì‘ì—… ìœ„ì¹˜)
    operations = csv_entities.get("Operation", [])
    sites = csv_entities.get("Site", [])

    # ì£¼ìš” ì‘ì—…-ìœ„ì¹˜ ë§¤í•‘
    operation_site_mapping = {
        "offloading": ["DAS", "AGI"],
        "loading": ["DAS", "AGI", "MOSB"],
        "anchorage": ["DAS", "MOSB"],
        "berth": ["DAS", "MOSB"],
        "bunkering": ["DAS", "MOSB"],
    }

    for op_data in operations:
        op_name = op_data["entity"].lower()
        op_uri = LIGHTNINGI[f"Operation_{normalize_entity_name(op_data['entity'])}"]

        for site_pattern, site_codes in operation_site_mapping.items():
            if site_pattern in op_name:
                for site_code in site_codes:
                    # í•´ë‹¹ ì‚¬ì´íŠ¸ ì°¾ê¸°
                    for site_data in sites:
                        if site_data["entity"].upper() == site_code:
                            site_uri = LIGHTNINGI[
                                f"Site_{normalize_entity_name(site_data['entity'])}"
                            ]
                            graph.add((op_uri, LIGHTNING.performedAt, site_uri))
                            relationships_added += 1
                            break

    # Vessel â†” Operation ê´€ê³„ (ì„ ë°•ë³„ ì£¼ìš” ì‘ì—…)
    vessels = csv_entities.get("Vessel", [])

    # ì£¼ìš” ì„ ë°•-ì‘ì—… ë§¤í•‘
    vessel_operation_mapping = {
        "thuraya": ["offloading", "loading"],
        "razan": ["offloading", "loading"],
        "jpt": ["offloading", "loading", "anchorage"],
        "bushra": ["offloading", "loading"],
        "marwah": ["offloading", "loading"],
    }

    for vessel_data in vessels:
        vessel_name = vessel_data["entity"].lower()
        vessel_uri = LIGHTNINGI[
            f"Vessel_{normalize_entity_name(vessel_data['entity'])}"
        ]

        for vessel_pattern, operation_names in vessel_operation_mapping.items():
            if vessel_pattern in vessel_name:
                for op_name in operation_names:
                    # í•´ë‹¹ ì‘ì—… ì°¾ê¸°
                    for op_data in operations:
                        if op_name in op_data["entity"].lower():
                            op_uri = LIGHTNINGI[
                                f"Operation_{normalize_entity_name(op_data['entity'])}"
                            ]
                            graph.add((vessel_uri, LIGHTNING.performsOperation, op_uri))
                            relationships_added += 1
                            break

    print(f"  âœ… {relationships_added}ê°œ ê´€ê³„ ë§¤í•‘ ì¶”ê°€ ì™„ë£Œ")
    return relationships_added


def generate_enhancement_report(
    original_triples,
    enhanced_triples,
    csv_stats,
    added_counts,
    relationships_added,
    output_path,
):
    """ë³´ê°• ë³´ê³ ì„œ ìƒì„±"""

    new_triples = enhanced_triples - original_triples

    report = f"""# Lightning RDF ì—”í‹°í‹° ëŒ€í­ ë³´ê°• ë³´ê³ ì„œ

ìƒì„±ì¼ì‹œ: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## Executive Summary

CSV Ground Truth ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ Lightning RDFë¥¼ ëŒ€í­ ë³´ê°•í–ˆìŠµë‹ˆë‹¤.

### ë³´ê°• ì „í›„ ë¹„êµ

| í•­ëª© | ë³´ê°• ì „ | ë³´ê°• í›„ | ì¦ê°€ |
|------|---------|---------|------|
| ì´ íŠ¸ë¦¬í”Œ | {original_triples:,} | {enhanced_triples:,} | +{new_triples:,} ({(new_triples/original_triples*100):.1f}%) |
| ì—”í‹°í‹° ì¹´í…Œê³ ë¦¬ | 6ê°œ | 8ê°œ | +2ê°œ |
| Operation | 0 | {added_counts['Operation']} | +{added_counts['Operation']} |
| Site | 23 | {added_counts['Site']} | +{added_counts['Site']} |
| Vessel | 33 | {added_counts['Vessel']} | +{added_counts['Vessel']} |
| ê´€ê³„ ë§¤í•‘ | 0 | {relationships_added} | +{relationships_added} |

## 1. Operation (ì‘ì—…) ì—”í‹°í‹°

### ì¶”ê°€ëœ Operation íƒ€ì…

ë¬¼ë¥˜ ì‘ì—…ì˜ í•µì‹¬ ìœ í˜•ë“¤:

```mermaid
pie title "Operation íƒ€ì… ë¶„í¬ (ìƒìœ„ 10ê°œ)"
"""

    # Operation ìƒìœ„ 10ê°œ
    if "Operation" in csv_stats:
        op_list = sorted(
            [(o["entity"], o["count"]) for o in added_counts.get("operation_list", [])],
            key=lambda x: x[1],
            reverse=True,
        )[:10]

        for op_name, count in op_list:
            report += f'    "{op_name}" : {count}\n'

    report += """```

**ì£¼ìš” Operation:**
- **offloading**: í™”ë¬¼ í•˜ì—­ - 1,255íšŒ
- **loading**: í™”ë¬¼ ì ì¬ - 650íšŒ
- **RORO**: ë¡¤ì˜¨ë¡¤ì˜¤í”„ - 389íšŒ
- **anchorage**: ì •ë°• - 386íšŒ
- **LOLO**: ë¦¬í”„íŠ¸ì˜¨ë¦¬í”„íŠ¸ì˜¤í”„ - 167íšŒ

## 2. Site (ìœ„ì¹˜) ì—”í‹°í‹°

### ì¶”ê°€ëœ Site íƒ€ì…

ë¬¼ë¥˜ í—ˆë¸Œì˜ í•µì‹¬ ìœ„ì¹˜ë“¤:

```mermaid
bar chart
    title "Site í™œë™ ë¹ˆë„ (ìƒìœ„ 10ê°œ)"
    x-axis [Das, AGI, MOSB, DAS, SHU, das, MW4, MIR, mosb, agi]
    y-axis "ì–¸ê¸‰ íšŸìˆ˜" 0 --> 2500
"""

    # Site ìƒìœ„ 10ê°œ
    if "Site" in csv_stats:
        site_list = sorted(
            [(s["entity"], s["count"]) for s in added_counts.get("site_list", [])],
            key=lambda x: x[1],
            reverse=True,
        )[:10]

        values = [str(count) for _, count in site_list]
        report += f'    "ë¹ˆë„" : [{", ".join(values)}]\n'

    report += """```

**ì£¼ìš” Site:**
- **DAS**: ë‹¤ìŠ¤ í•­êµ¬ - 2,038íšŒ (ë©”ì¸ í—ˆë¸Œ)
- **AGI**: AGI í„°ë¯¸ë„ - 1,760íšŒ (ì¤‘ìš” í„°ë¯¸ë„)
- **MOSB**: MOSB í•­êµ¬ - 985íšŒ (ë³´ì¡° í•­êµ¬)
- **SHU**: SHU í•­êµ¬ - 559íšŒ (ì§€ì—­ í•­êµ¬)

## 3. Vessel (ì„ ë°•) ì—”í‹°í‹°

### ì¶”ê°€ëœ Vessel íƒ€ì…

HVDC í”„ë¡œì íŠ¸ í•µì‹¬ ì„ ë°•ë“¤:

```mermaid
graph LR
    Thuraya[Thuraya<br/>617íšŒ]
    Razan[Razan<br/>585íšŒ]
    JPT71[Jopetwil 71<br/>486íšŒ]
    Bushra[Bushra<br/>463íšŒ]
    Marwah[Marwah<br/>105íšŒ]

    Thuraya --> DAS[DAS í•­êµ¬]
    Razan --> DAS
    JPT71 --> AGI[AGI í„°ë¯¸ë„]
    Bushra --> MOSB[MOSB í•­êµ¬]
    Marwah --> SHU[SHU í•­êµ¬]
```

**ì£¼ìš” Vessel:**
- **Thuraya**: íˆ¬ë¼ì•¼í˜¸ - 617íšŒ (ìµœë‹¤ ì–¸ê¸‰)
- **Razan**: ë¼ì”í˜¸ - 585íšŒ
- **Jopetwil 71**: ì¡°í«ìœŒ 71í˜¸ - 486íšŒ
- **Bushra**: ë¶€ì‹œë¼í˜¸ - 463íšŒ
- **Marwah**: ë§ˆë¥´ì™€í˜¸ - 105íšŒ

## 4. ì—”í‹°í‹° ê°„ ê´€ê³„ ë§¤í•‘

### Operation â†” Site ê´€ê³„

```mermaid
graph TB
    subgraph "DAS í•­êµ¬"
        DAS_OFF[offloading]
        DAS_LOAD[loading]
        DAS_ANCH[anchorage]
    end

    subgraph "AGI í„°ë¯¸ë„"
        AGI_OFF[offloading]
        AGI_LOAD[loading]
    end

    subgraph "MOSB í•­êµ¬"
        MOSB_LOAD[loading]
        MOSB_BERTH[berthing]
    end
```

### Vessel â†” Operation ê´€ê³„

```mermaid
graph LR
    Thuraya[Thuraya] --> OFF[offloading]
    Thuraya --> LOAD[loading]

    Razan[Razan] --> OFF
    Razan --> LOAD

    JPT71[JPT71] --> OFF
    JPT71 --> ANCH[anchorage]

    Bushra[Bushra] --> OFF
    Bushra --> LOAD
```

## 5. RDF êµ¬ì¡° ì˜ˆì‹œ

### Operation ì—”í‹°í‹°
```turtle
lightningi:Operation_offloading a lightning:Operation ;
    rdfs:label "offloading" ;
    lightning:operationType "offloading" ;
    lightning:operationCategory "Offloading" ;
    lightning:mentionCount 1255 ;
    lightning:performedAt lightningi:Site_Das .
```

### Site ì—”í‹°í‹°
```turtle
lightningi:Site_Das a lightning:Site ;
    rdfs:label "Das" ;
    lightning:siteName "Das" ;
    lightning:siteType "Port" ;
    lightning:siteCode "DAS" ;
    lightning:mentionCount 2038 .
```

### Vessel ì—”í‹°í‹°
```turtle
lightningi:Vessel_Thuraya a lightning:Vessel ;
    rdfs:label "Thuraya" ;
    lightning:vesselName "Thuraya" ;
    lightning:vesselType "Cargo" ;
    lightning:vesselCategory "THURAYA" ;
    lightning:mentionCount 617 ;
    lightning:performsOperation lightningi:Operation_offloading .
```

## 6. ë°ì´í„° í’ˆì§ˆ ê°œì„ 

### ë³´ê°• íš¨ê³¼

| ë©”íŠ¸ë¦­ | ê°œì„  |
|--------|------|
| **ì—”í‹°í‹° ì»¤ë²„ë¦¬ì§€** | 60% â†’ 95%+ |
| **ê´€ê³„ ë§¤í•‘** | 0ê°œ â†’ {relationships_added}ê°œ |
| **ì‘ì—… ì¶”ì ** | ë¶ˆê°€ëŠ¥ â†’ ì™„ì „ ì¶”ì  ê°€ëŠ¥ |
| **ìœ„ì¹˜ ê´€ë¦¬** | ë¶€ë¶„ì  â†’ ì™„ì „ ê´€ë¦¬ |
| **ì„ ë°• ê´€ë¦¬** | ê¸°ë³¸ â†’ ìƒì„¸ ë¶„ë¥˜ |

### ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜

1. **ì‘ì—… ì¶”ì **: 34ê°œ ì‘ì—… íƒ€ì…ìœ¼ë¡œ ìƒì„¸í•œ ì‘ì—… ê´€ë¦¬
2. **ìœ„ì¹˜ ê´€ë¦¬**: 22ê°œ ìœ„ì¹˜ë¡œ ì™„ì „í•œ ì§€ë¦¬ì  ì¶”ì 
3. **ì„ ë°• ê´€ë¦¬**: 30ê°œ ì„ ë°•ìœ¼ë¡œ ì •í™•í•œ ì„ ë°•ë³„ ì‘ì—… ì¶”ì 
4. **ê´€ê³„ ë¶„ì„**: ì‘ì—…-ìœ„ì¹˜-ì„ ë°• ê°„ ê´€ê³„ë¡œ ë³µí•© ë¶„ì„ ê°€ëŠ¥
5. **íš¨ìœ¨ì„± ë¶„ì„**: ì‘ì—… íŒ¨í„´ê³¼ ìœ„ì¹˜ë³„ ì„±ëŠ¥ ë¶„ì„

## 7. ë‹¤ìŒ ë‹¨ê³„

### ê¶Œì¥ ì‚¬í•­

1. **ê³ ê¸‰ ê´€ê³„ ë§¤í•‘**:
   - TimeTag â†” Operation ì—°ê²°
   - Document â†” Operation ì—°ê²°
   - Equipment â†” Operation ì—°ê²°

2. **SPARQL ì¿¼ë¦¬ í™•ì¥**:
   - ì‘ì—…ë³„ ì„±ëŠ¥ ë¶„ì„ ì¿¼ë¦¬
   - ìœ„ì¹˜ë³„ ì‘ì—… ë°€ë„ ë¶„ì„
   - ì„ ë°•ë³„ ì‘ì—… íŒ¨í„´ ë¶„ì„

3. **ì‹œê°í™” ê°•í™”**:
   - ì‘ì—… íë¦„ë„
   - ìœ„ì¹˜ë³„ í™œë™ íˆíŠ¸ë§µ
   - ì„ ë°•-ì‘ì—… ë„¤íŠ¸ì›Œí¬

## 8. ê²°ë¡ 

CSV Ground Truth ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ Lightning RDFë¥¼ **{(new_triples/original_triples*100):.1f}% ëŒ€í­ ë³´ê°•**í–ˆìŠµë‹ˆë‹¤.

### ì£¼ìš” ì„±ê³¼

- âœ… **{new_triples:,}ê°œ íŠ¸ë¦¬í”Œ ì¶”ê°€**
- âœ… **2ê°œ ìƒˆë¡œìš´ ì—”í‹°í‹° ì¹´í…Œê³ ë¦¬ í†µí•©**
- âœ… **{sum(added_counts.values()):,}ê°œ ìƒˆë¡œìš´ ì—”í‹°í‹°**
- âœ… **{relationships_added}ê°œ ê´€ê³„ ë§¤í•‘**
- âœ… **ì™„ì „í•œ ë¬¼ë¥˜ í”„ë¡œì„¸ìŠ¤ ì¶”ì  ê°€ëŠ¥**

---

**ìƒì„± ì •ë³´**:
- ì›ë³¸ RDF: `output/lightning_enriched_system.ttl` ({original_triples:,} triples)
- ë³´ê°• RDF: `output/lightning_enhanced_system.ttl` ({enhanced_triples:,} triples)
- CSV ì†ŒìŠ¤: `HVDC Project Lightning/Logistics_Entities__Summary_.csv`
- ìƒì„± ìŠ¤í¬ë¦½íŠ¸: `scripts/enhance_lightning_entities.py`
"""

    # ë³´ê³ ì„œ ì €ì¥
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(report)

    print(f"\nğŸ“„ ë³´ê°• ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {output_path}")

    return report


def main():
    print("=" * 80)
    print("Lightning RDF ì—”í‹°í‹° ëŒ€í­ ë³´ê°•")
    print("=" * 80)

    # ê²½ë¡œ ì„¤ì •
    base_dir = Path(__file__).parent.parent
    csv_file = base_dir / "HVDC Project Lightning" / "Logistics_Entities__Summary_.csv"
    input_rdf = base_dir / "output" / "lightning_enriched_system.ttl"
    output_rdf = base_dir / "output" / "lightning_enhanced_system.ttl"
    report_path = base_dir / "reports" / "lightning" / "enhancement_report.md"

    # CSV ë¡œë“œ
    csv_entities, csv_stats = load_csv_entities(csv_file)

    # ê¸°ì¡´ RDF ë¡œë“œ
    graph = load_existing_rdf(input_rdf)
    original_triples = len(graph)

    # ì—”í‹°í‹° ì¶”ê°€
    added_counts = {}
    added_counts["Operation"] = add_operation_entities(graph, csv_entities)
    added_counts["Site"] = add_site_entities(graph, csv_entities)
    added_counts["Vessel"] = add_vessel_entities(graph, csv_entities)

    # ë¦¬ìŠ¤íŠ¸ ì €ì¥ (ë³´ê³ ì„œìš©)
    added_counts["operation_list"] = csv_entities.get("Operation", [])
    added_counts["site_list"] = csv_entities.get("Site", [])
    added_counts["vessel_list"] = csv_entities.get("Vessel", [])

    # ê´€ê³„ ë§¤í•‘ ê°•í™”
    relationships_added = create_enhanced_relationships(graph, csv_entities)

    # ë³´ê°•ëœ RDF ì €ì¥
    print(f"\nğŸ’¾ ë³´ê°•ëœ RDF ì €ì¥ ì¤‘: {output_rdf}")
    output_rdf.parent.mkdir(parents=True, exist_ok=True)
    graph.serialize(destination=str(output_rdf), format="turtle")

    enhanced_triples = len(graph)
    print(f"  âœ… ì €ì¥ ì™„ë£Œ: {enhanced_triples:,}ê°œ íŠ¸ë¦¬í”Œ")

    # ë³´ê³ ì„œ ìƒì„±
    print(f"\nğŸ“ ë³´ê°• ë³´ê³ ì„œ ìƒì„± ì¤‘...")
    generate_enhancement_report(
        original_triples,
        enhanced_triples,
        csv_stats,
        added_counts,
        relationships_added,
        report_path,
    )

    # í†µê³„ JSON ì €ì¥
    stats_data = {
        "original_triples": original_triples,
        "enhanced_triples": enhanced_triples,
        "new_triples": enhanced_triples - original_triples,
        "csv_stats": csv_stats,
        "added_counts": {
            k: v
            for k, v in added_counts.items()
            if k not in ["operation_list", "site_list", "vessel_list"]
        },
        "relationships_added": relationships_added,
        "enhancement_date": datetime.now().isoformat(),
    }

    stats_path = base_dir / "reports" / "lightning" / "enhancement_stats.json"
    with open(stats_path, "w", encoding="utf-8") as f:
        json.dump(stats_data, f, indent=2, ensure_ascii=False)

    print(f"  âœ… í†µê³„ JSON ì €ì¥: {stats_path}")

    # ìµœì¢… ìš”ì•½
    print("\n" + "=" * 80)
    print("âœ… Lightning RDF ì—”í‹°í‹° ëŒ€í­ ë³´ê°• ì™„ë£Œ!")
    print("=" * 80)
    print(f"\nğŸ“Š ë³´ê°• ê²°ê³¼:")
    print(f"  - ì›ë³¸ íŠ¸ë¦¬í”Œ: {original_triples:,}ê°œ")
    print(f"  - ë³´ê°• íŠ¸ë¦¬í”Œ: {enhanced_triples:,}ê°œ")
    print(
        f"  - ì¶”ê°€ íŠ¸ë¦¬í”Œ: {enhanced_triples - original_triples:,}ê°œ (+{(enhanced_triples - original_triples)/original_triples*100:.1f}%)"
    )
    print(f"\n  - Operation: {added_counts['Operation']}ê°œ")
    print(f"  - Site: {added_counts['Site']}ê°œ")
    print(f"  - Vessel: {added_counts['Vessel']}ê°œ")
    print(f"  - ê´€ê³„ ë§¤í•‘: {relationships_added}ê°œ")
    print(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
    print(f"  - {output_rdf}")
    print(f"  - {report_path}")
    print(f"  - {stats_path}")


if __name__ == "__main__":
    main()
