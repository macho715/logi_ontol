#!/usr/bin/env python3
"""
ì•„ë¶€ë‹¤ë¹„ ë¬¼ë¥˜ ë°ì´í„° ì‹œê°í™” ìŠ¤í¬ë¦½íŠ¸
RDF ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.
"""

import sys
import json
from pathlib import Path
from datetime import datetime
from collections import Counter, defaultdict
from typing import Dict, List, Any, Tuple

# RDF ì²˜ë¦¬
from rdflib import Graph, Namespace, RDF, RDFS, XSD, Literal, URIRef
from rdflib.namespace import NamespaceManager

# Unicode ì¶œë ¥ ì§€ì›
sys.stdout.reconfigure(encoding="utf-8")


def load_rdf_data(rdf_path: str) -> Tuple[Graph, Dict[str, Any]]:
    """RDF ë°ì´í„° ë¡œë“œ"""
    print(f"[INFO] RDF íŒŒì¼ ë¡œë“œ: {rdf_path}")

    g = Graph()
    g.parse(rdf_path, format="turtle")

    # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì¶”ì¶œ
    ns_dict = dict(g.namespaces())
    abu_uri = ns_dict.get("abu")

    if not abu_uri:
        print("[ERROR] abu ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return g, {}

    # Namespace ê°ì²´ ìƒì„±
    abu_ns = Namespace(abu_uri)

    # ë°ì´í„° ë¶„ì„
    data = {
        "containers": [],
        "deliveries": [],
        "shipments": [],
        "participants": [],
        "guidelines": [],
        "rules": [],
        "kpis": [],
    }

    # ì»¨í…Œì´ë„ˆ ë°ì´í„° ì¶”ì¶œ
    for s, p, o in g.triples((None, RDF.type, abu_ns["AbuDhabiContainer"])):
        container_data = {"uri": str(s)}
        for sp, so in g.predicate_objects(s):
            if "containerId" in str(sp):
                container_data["id"] = str(so)
            elif "containerType" in str(sp):
                container_data["type"] = str(so)
            elif "timestamp" in str(sp):
                container_data["timestamp"] = str(so)
            elif "reportedBy" in str(sp):
                container_data["reported_by"] = str(so)
        data["containers"].append(container_data)

    # ë°°ì†¡ ë°ì´í„° ì¶”ì¶œ
    for s, p, o in g.triples((None, RDF.type, abu_ns["AbuDhabiDelivery"])):
        delivery_data = {"uri": str(s)}
        for sp, so in g.predicate_objects(s):
            if "deliveryCompany" in str(sp):
                delivery_data["company"] = str(so)
            elif "timestamp" in str(sp):
                delivery_data["timestamp"] = str(so)
            elif "deliveryQuantity" in str(sp):
                delivery_data["quantity"] = str(so)
            elif "deliveryUnit" in str(sp):
                delivery_data["unit"] = str(so)
        data["deliveries"].append(delivery_data)

    # ì„ ë°• ë°ì´í„° ì¶”ì¶œ
    for s, p, o in g.triples((None, RDF.type, abu_ns["AbuDhabiShipment"])):
        shipment_data = {"uri": str(s)}
        for sp, so in g.predicate_objects(s):
            if "shipName" in str(sp):
                shipment_data["name"] = str(so)
            elif "timestamp" in str(sp):
                shipment_data["timestamp"] = str(so)
            elif "estimatedArrival" in str(sp):
                shipment_data["eta"] = str(so)
            elif "currentLocation" in str(sp):
                shipment_data["location"] = str(so)
            elif "shipStatus" in str(sp):
                shipment_data["status"] = str(so)
        data["shipments"].append(shipment_data)

    # ì°¸ì—¬ì ë°ì´í„° ì¶”ì¶œ
    for s, p, o in g.triples((None, RDF.type, abu_ns["Organization"])):
        participant_data = {"uri": str(s)}
        for sp, so in g.predicate_objects(s):
            if "participantName" in str(sp):
                participant_data["name"] = str(so)
            elif "participantRole" in str(sp):
                participant_data["role"] = str(so)
        data["participants"].append(participant_data)

    # ê°€ì´ë“œë¼ì¸ ë°ì´í„° ì¶”ì¶œ
    for s, p, o in g.triples((None, RDF.type, abu_ns["AbuDhabiGuideline"])):
        guideline_data = {"uri": str(s)}
        for sp, so in g.predicate_objects(s):
            if "guidelineTitle" in str(sp):
                guideline_data["title"] = str(so)
            elif "guidelineVersion" in str(sp):
                guideline_data["version"] = str(so)
        data["guidelines"].append(guideline_data)

    # ê·œì¹™ ë°ì´í„° ì¶”ì¶œ
    for s, p, o in g.triples((None, RDF.type, abu_ns["AbuDhabiRule"])):
        rule_data = {"uri": str(s)}
        for sp, so in g.predicate_objects(s):
            if "ruleCategory" in str(sp):
                rule_data["category"] = str(so)
            elif "ruleText" in str(sp):
                rule_data["text"] = str(so)
        data["rules"].append(rule_data)

    # KPI ë°ì´í„° ì¶”ì¶œ
    for s, p, o in g.triples((None, RDF.type, abu_ns["AbuDhabiKPI"])):
        kpi_data = {"uri": str(s)}
        for sp, so in g.predicate_objects(s):
            if "kpiDescription" in str(sp):
                kpi_data["description"] = str(so)
            elif "targetPercentage" in str(sp):
                kpi_data["target"] = str(so)
        data["kpis"].append(kpi_data)

    return g, data


def analyze_abu_data(data: Dict[str, Any]) -> Dict[str, Any]:
    """ABU ë°ì´í„° ë¶„ì„"""
    analysis = {
        "summary": {
            "total_containers": len(data["containers"]),
            "total_deliveries": len(data["deliveries"]),
            "total_shipments": len(data["shipments"]),
            "total_participants": len(data["participants"]),
            "total_guidelines": len(data["guidelines"]),
            "total_rules": len(data["rules"]),
            "total_kpis": len(data["kpis"]),
        },
        "container_analysis": {},
        "delivery_analysis": {},
        "shipment_analysis": {},
        "participant_analysis": {},
        "rule_analysis": {},
        "kpi_analysis": {},
    }

    # ì»¨í…Œì´ë„ˆ ë¶„ì„
    if data["containers"]:
        container_types = Counter(
            [c.get("type", "unknown") for c in data["containers"]]
        )
        reported_by = Counter(
            [c.get("reported_by", "unknown") for c in data["containers"]]
        )
        analysis["container_analysis"] = {
            "types": dict(container_types),
            "reported_by": dict(reported_by),
        }

    # ë°°ì†¡ ë¶„ì„
    if data["deliveries"]:
        companies = Counter([d.get("company", "unknown") for d in data["deliveries"]])
        analysis["delivery_analysis"] = {"companies": dict(companies)}

    # ì„ ë°• ë¶„ì„
    if data["shipments"]:
        ship_names = Counter([s.get("name", "unknown") for s in data["shipments"]])
        statuses = Counter([s.get("status", "unknown") for s in data["shipments"]])
        analysis["shipment_analysis"] = {
            "ship_names": dict(ship_names),
            "statuses": dict(statuses),
        }

    # ì°¸ì—¬ì ë¶„ì„
    if data["participants"]:
        roles = Counter([p.get("role", "unknown") for p in data["participants"]])
        analysis["participant_analysis"] = {"roles": dict(roles)}

    # ê·œì¹™ ë¶„ì„
    if data["rules"]:
        categories = Counter([r.get("category", "unknown") for r in data["rules"]])
        analysis["rule_analysis"] = {"categories": dict(categories)}

    return analysis


def generate_entity_relationship_diagram(data: Dict[str, Any]) -> str:
    """ì—”í‹°í‹° ê´€ê³„ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±"""
    mermaid = """graph TD
    subgraph "ì•„ë¶€ë‹¤ë¹„ ë¬¼ë¥˜ ì‹œìŠ¤í…œ"
        A[AbuDhabiGuideline] --> B[AbuDhabiRule]
        A --> C[AbuDhabiKPI]
        D[AbuDhabiShipment] --> E[AbuDhabiContainer]
        D --> F[AbuDhabiDelivery]
        G[Organization] --> D
        G --> E
        G --> F
    end

    subgraph "ë°ì´í„° í†µê³„"
        H["ì»¨í…Œì´ë„ˆ: {total_containers}ê°œ"]
        I["ë°°ì†¡: {total_deliveries}ê°œ"]
        J["ì„ ë°•: {total_shipments}ê°œ"]
        K["ì°¸ì—¬ì: {total_participants}ê°œ"]
        L["ê°€ì´ë“œë¼ì¸: {total_guidelines}ê°œ"]
        M["ê·œì¹™: {total_rules}ê°œ"]
        N["KPI: {total_kpis}ê°œ"]
    end
""".format(
        total_containers=data["summary"]["total_containers"],
        total_deliveries=data["summary"]["total_deliveries"],
        total_shipments=data["summary"]["total_shipments"],
        total_participants=data["summary"]["total_participants"],
        total_guidelines=data["summary"]["total_guidelines"],
        total_rules=data["summary"]["total_rules"],
        total_kpis=data["summary"]["total_kpis"],
    )

    return mermaid


def generate_container_type_chart(container_analysis: Dict[str, Any]) -> str:
    """ì»¨í…Œì´ë„ˆ íƒ€ì… ì°¨íŠ¸ ìƒì„±"""
    if not container_analysis.get("types"):
        return "pie title ì»¨í…Œì´ë„ˆ íƒ€ì…\n    ë°ì´í„° ì—†ìŒ : 1"

    mermaid = "pie title ì»¨í…Œì´ë„ˆ íƒ€ì…\n"
    for container_type, count in container_analysis["types"].items():
        mermaid += f'    "{container_type}" : {count}\n'

    return mermaid


def generate_delivery_company_chart(delivery_analysis: Dict[str, Any]) -> str:
    """ë°°ì†¡ íšŒì‚¬ ì°¨íŠ¸ ìƒì„±"""
    if not delivery_analysis.get("companies"):
        return "pie title ë°°ì†¡ íšŒì‚¬\n    ë°ì´í„° ì—†ìŒ : 1"

    mermaid = "pie title ë°°ì†¡ íšŒì‚¬\n"
    for company, count in delivery_analysis["companies"].items():
        mermaid += f'    "{company}" : {count}\n'

    return mermaid


def generate_shipment_status_chart(shipment_analysis: Dict[str, Any]) -> str:
    """ì„ ë°• ìƒíƒœ ì°¨íŠ¸ ìƒì„±"""
    if not shipment_analysis.get("statuses"):
        return "pie title ì„ ë°• ìƒíƒœ\n    ë°ì´í„° ì—†ìŒ : 1"

    mermaid = "pie title ì„ ë°• ìƒíƒœ\n"
    for status, count in shipment_analysis["statuses"].items():
        mermaid += f'    "{status}" : {count}\n'

    return mermaid


def generate_data_flow_diagram() -> str:
    """ë°ì´í„° í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±"""
    return """graph LR
    A[ê°€ì´ë“œë¼ì¸ ë¬¸ì„œ] --> B[êµ¬ì¡°í™”ëœ ë¶„ì„]
    C[WhatsApp ëŒ€í™”] --> D[ë¬¼ë¥˜ ë°ì´í„° ì¶”ì¶œ]
    B --> E[RDF ë³€í™˜]
    D --> E
    E --> F[ì•„ë¶€ë‹¤ë¹„ ë¬¼ë¥˜ ì˜¨í†¨ë¡œì§€]
    F --> G[ì‹œê°í™” ë° ë¶„ì„]
"""


def generate_ontology_class_diagram() -> str:
    """ì˜¨í†¨ë¡œì§€ í´ë˜ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±"""
    return """classDiagram
    class AbuDhabiGuideline {
        +String guidelineTitle
        +String guidelineVersion
        +String guidelineDescription
        +hasRule: AbuDhabiRule[]
        +hasKPI: AbuDhabiKPI[]
    }

    class AbuDhabiRule {
        +String ruleCategory
        +String ruleText
    }

    class AbuDhabiKPI {
        +String kpiDescription
        +Decimal targetPercentage
    }

    class AbuDhabiShipment {
        +String shipName
        +DateTime timestamp
        +String estimatedArrival
        +String currentLocation
        +String shipStatus
        +String[] cargoType
    }

    class AbuDhabiContainer {
        +String containerId
        +String containerType
        +DateTime timestamp
        +String reportedBy
    }

    class AbuDhabiDelivery {
        +String deliveryCompany
        +DateTime timestamp
        +Integer deliveryQuantity
        +String deliveryUnit
    }

    class Organization {
        +String participantName
        +String participantRole
    }

    AbuDhabiGuideline --> AbuDhabiRule
    AbuDhabiGuideline --> AbuDhabiKPI
    Organization --> AbuDhabiShipment
    Organization --> AbuDhabiContainer
    Organization --> AbuDhabiDelivery
"""


def generate_markdown_report(data: Dict[str, Any], analysis: Dict[str, Any]) -> str:
    """ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„±"""
    report = f"""# ì•„ë¶€ë‹¤ë¹„ ë¬¼ë¥˜ ë°ì´í„° ì‹œê°í™” ë³´ê³ ì„œ

**ìƒì„± ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š ì‹¤í–‰ ìš”ì•½

- **ì´ ì»¨í…Œì´ë„ˆ**: {analysis['summary']['total_containers']}ê°œ
- **ì´ ë°°ì†¡**: {analysis['summary']['total_deliveries']}ê°œ
- **ì´ ì„ ë°•**: {analysis['summary']['total_shipments']}ê°œ
- **ì´ ì°¸ì—¬ì**: {analysis['summary']['total_participants']}ê°œ
- **ì´ ê°€ì´ë“œë¼ì¸**: {analysis['summary']['total_guidelines']}ê°œ
- **ì´ ê·œì¹™**: {analysis['summary']['total_rules']}ê°œ
- **ì´ KPI**: {analysis['summary']['total_kpis']}ê°œ

## ğŸ”— ì—”í‹°í‹° ê´€ê³„ ë‹¤ì´ì–´ê·¸ë¨

```mermaid
{generate_entity_relationship_diagram(analysis)}
```

## ğŸ“¦ ì»¨í…Œì´ë„ˆ íƒ€ì… ë¶„í¬

```mermaid
{generate_container_type_chart(analysis['container_analysis'])}
```

## ğŸšš ë°°ì†¡ íšŒì‚¬ ë¶„í¬

```mermaid
{generate_delivery_company_chart(analysis['delivery_analysis'])}
```

## ğŸš¢ ì„ ë°• ìƒíƒœ ë¶„í¬

```mermaid
{generate_shipment_status_chart(analysis['shipment_analysis'])}
```

## ğŸ”„ ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```mermaid
{generate_data_flow_diagram()}
```

## ğŸ—ï¸ ì˜¨í†¨ë¡œì§€ í´ë˜ìŠ¤ êµ¬ì¡°

```mermaid
{generate_ontology_class_diagram()}
```

## ğŸ“ˆ ìƒì„¸ ë¶„ì„

### ì»¨í…Œì´ë„ˆ ë¶„ì„
- **íƒ€ì…ë³„ ë¶„í¬**: {analysis['container_analysis'].get('types', {})}
- **ë³´ê³ ìë³„ ë¶„í¬**: {analysis['container_analysis'].get('reported_by', {})}

### ë°°ì†¡ ë¶„ì„
- **íšŒì‚¬ë³„ ë¶„í¬**: {analysis['delivery_analysis'].get('companies', {})}

### ì„ ë°• ë¶„ì„
- **ì„ ë°•ëª…ë³„ ë¶„í¬**: {analysis['shipment_analysis'].get('ship_names', {})}
- **ìƒíƒœë³„ ë¶„í¬**: {analysis['shipment_analysis'].get('statuses', {})}

### ì°¸ì—¬ì ë¶„ì„
- **ì—­í• ë³„ ë¶„í¬**: {analysis['participant_analysis'].get('roles', {})}

### ê·œì¹™ ë¶„ì„
- **ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬**: {analysis['rule_analysis'].get('categories', {})}

## ğŸ¯ ì£¼ìš” ì¸ì‚¬ì´íŠ¸

1. **ë°ì´í„° í’ˆì§ˆ**: ì´ {analysis['summary']['total_containers'] + analysis['summary']['total_deliveries'] + analysis['summary']['total_shipments']}ê°œì˜ ë¬¼ë¥˜ ì—”í‹°í‹°ê°€ ì„±ê³µì ìœ¼ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.

2. **ì°¸ì—¬ì ë‹¤ì–‘ì„±**: {analysis['summary']['total_participants']}ëª…ì˜ ë‹¤ì–‘í•œ ì—­í• ì˜ ì°¸ì—¬ìê°€ ì‹œìŠ¤í…œì— ì°¸ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.

3. **ê·œì¹™ ì²´ê³„**: {analysis['summary']['total_rules']}ê°œì˜ êµ¬ì¡°í™”ëœ ê·œì¹™ê³¼ {analysis['summary']['total_kpis']}ê°œì˜ KPIê°€ ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

4. **ë°ì´í„° ì¼ê´€ì„±**: ëª¨ë“  íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ISO 8601 í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ğŸ“‹ ê¶Œì¥ì‚¬í•­

1. **ë°ì´í„° ê²€ì¦**: ì»¨í…Œì´ë„ˆ íƒ€ì… ì •ë³´ë¥¼ ë” ì •í™•í•˜ê²Œ ìˆ˜ì§‘í•˜ë„ë¡ ê°œì„ 
2. **ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸**: WhatsApp ë°ì´í„°ì˜ ì‹¤ì‹œê°„ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
3. **í’ˆì§ˆ ëª¨ë‹ˆí„°ë§**: KPI ê¸°ë°˜ ë°ì´í„° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ë„ì…
4. **í†µí•© ë¶„ì„**: ë‹¤ë¥¸ ë¬¼ë¥˜ ì‹œìŠ¤í…œê³¼ì˜ ë°ì´í„° í†µí•© ë¶„ì„

---
*ì´ ë³´ê³ ì„œëŠ” LogiOntology ì‹œìŠ¤í…œì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
"""

    return report


def save_json_summary(analysis: Dict[str, Any], output_path: str):
    """JSON ìš”ì•½ ì €ì¥"""
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(analysis, f, ensure_ascii=False, indent=2)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("ì•„ë¶€ë‹¤ë¹„ ë¬¼ë¥˜ ë°ì´í„° ì‹œê°í™” ìŠ¤í¬ë¦½íŠ¸")
    print("=" * 60)

    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    rdf_path = "output/abu_logistics_data.ttl"
    report_path = "reports/abu_visualization_report.md"
    json_path = "reports/abu_data_summary.json"

    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not Path(rdf_path).exists():
        print(f"[ERROR] RDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {rdf_path}")
        return

    try:
        # RDF ë°ì´í„° ë¡œë“œ
        g, data = load_rdf_data(rdf_path)
        print(f"[SUCCESS] RDF ë°ì´í„° ë¡œë“œ ì™„ë£Œ")

        # ë°ì´í„° ë¶„ì„
        analysis = analyze_abu_data(data)
        print(f"[SUCCESS] ë°ì´í„° ë¶„ì„ ì™„ë£Œ")

        # ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„±
        report = generate_markdown_report(data, analysis)

        # ë³´ê³ ì„œ ì €ì¥
        Path("reports").mkdir(exist_ok=True)
        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report)
        print(f"[SUCCESS] ì‹œê°í™” ë³´ê³ ì„œ ì €ì¥: {report_path}")

        # JSON ìš”ì•½ ì €ì¥
        save_json_summary(analysis, json_path)
        print(f"[SUCCESS] JSON ìš”ì•½ ì €ì¥: {json_path}")

        print("\n" + "=" * 60)
        print("ì‹œê°í™” ì™„ë£Œ!")
        print("=" * 60)

    except Exception as e:
        print(f"[ERROR] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
