#!/usr/bin/env python3
"""
ABU WhatsApp ëŒ€í™”ì—ì„œ ì¶”ì¶œí•œ LPO ë°ì´í„°ë¥¼ RDFë¡œ ë³€í™˜
"""

import sys
import json
import yaml
import re
from datetime import datetime
from pathlib import Path
from rdflib import Graph, Namespace, Literal, URIRef
from rdflib.namespace import RDF, RDFS, XSD

# UTF-8 ì¸ì½”ë”© ì„¤ì •
sys.stdout.reconfigure(encoding="utf-8")


def setup_namespaces():
    """RDF ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì„¤ì •"""
    namespaces = {
        "hvdc": Namespace("https://hvdc.example.org/ns#"),
        "hvdci": Namespace("https://hvdc.example.org/id/"),
        "lpo": Namespace("https://hvdc.example.org/ns/lpo#"),
        "org": Namespace("http://www.w3.org/ns/org#"),
        "abu": Namespace("https://abu-dhabi.example.org/ns#"),
        "rdf": RDF,
        "rdfs": RDFS,
        "xsd": XSD,
    }
    return namespaces


def load_mapping_rules():
    """LPO ë§¤í•‘ ê·œì¹™ ë¡œë“œ"""
    rules_file = Path("logiontology/configs/lpo_mapping_rules.yaml")
    with open(rules_file, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def normalize_vendor_name(vendor_name):
    """ê³µê¸‰ì—…ì²´ ì´ë¦„ ì •ê·œí™”"""
    # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
    normalized = re.sub(r"[^\w\s]", "", vendor_name)
    normalized = re.sub(r"\s+", "_", normalized.strip())
    return normalized


def normalize_location_name(location_name):
    """ìœ„ì¹˜ ì´ë¦„ ì •ê·œí™”"""
    if not location_name:
        return "Unknown_Location"
    return location_name.strip()


def convert_whatsapp_date(date_str):
    """WhatsApp ë‚ ì§œ í˜•ì‹ì„ ISO í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if not date_str:
        return "1900-01-01"

    try:
        # 24/8/21 í˜•ì‹ì„ 2024-08-21ë¡œ ë³€í™˜
        date_obj = datetime.strptime(date_str, "%y/%m/%d")
        return date_obj.strftime("%Y-%m-%d")
    except:
        return "1900-01-01"


def categorize_lpo_item(description):
    """LPO í•­ëª© ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
    category_keywords = {
        "Stationary": ["stationary", "office", "paper", "cup", "tissue"],
        "Electrical": ["elec", "wire", "cable", "electrical", "power"],
        "Construction": ["upvc", "steel", "conduit", "scaffolding", "kerb"],
        "Maintenance": ["maintenance", "filter", "grease", "chemical"],
        "Furniture": ["furniture", "bed", "cabinet", "shelving"],
        "Kitchen": ["kitchen", "dish", "pantry", "food"],
        "Safety": ["protective", "sling", "webbing", "rope"],
        "General": ["general", "consumable", "items"],
    }

    description_lower = description.lower()
    for category, keywords in category_keywords.items():
        if any(keyword in description_lower for keyword in keywords):
            return category
    return "Other"


def create_lpo_uri(lpo_number, ns_dict):
    """LPO URI ìƒì„±"""
    return ns_dict["hvdci"][f"LPO/{lpo_number}"]


def create_vendor_uri(vendor_name, ns_dict):
    """ê³µê¸‰ì—…ì²´ URI ìƒì„±"""
    normalized_name = normalize_vendor_name(vendor_name)
    return ns_dict["hvdci"][f"Organization/{normalized_name}"]


def create_location_uri(location_name, ns_dict):
    """ìœ„ì¹˜ URI ìƒì„±"""
    normalized_name = normalize_location_name(location_name)
    return ns_dict["hvdci"][f"Location/{normalized_name}"]


def process_lpo_data(lpo_data, mapping_rules, ns_dict):
    """LPO ë°ì´í„°ë¥¼ RDFë¡œ ë³€í™˜"""
    g = Graph()

    # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë°”ì¸ë”©
    for prefix, namespace in ns_dict.items():
        g.bind(prefix, namespace)

    # ì²˜ë¦¬ëœ ì—”í‹°í‹° ì¶”ì 
    processed_lpos = set()
    processed_vendors = set()
    processed_locations = set()

    for item in lpo_data:
        lpo_number = item["lpo_number"]

        # LPO ì—”í‹°í‹° ìƒì„± (ì¤‘ë³µ ë°©ì§€)
        if lpo_number not in processed_lpos:
            lpo_uri = create_lpo_uri(lpo_number, ns_dict)

            # LPO íƒ€ì… ì„¤ì •
            g.add((lpo_uri, RDF.type, ns_dict["lpo"]["LocalPurchaseOrder"]))

            # LPO ì†ì„± ì¶”ê°€
            g.add((lpo_uri, ns_dict["lpo"]["lpoNumber"], Literal(lpo_number)))
            g.add(
                (lpo_uri, ns_dict["lpo"]["description"], Literal(item["description"]))
            )
            g.add((lpo_uri, ns_dict["lpo"]["vendorName"], Literal(item["vendor"])))

            # ë‚ ì§œ ë³€í™˜ ë° ì¶”ê°€
            iso_date = convert_whatsapp_date(item["date"])
            g.add(
                (
                    lpo_uri,
                    ns_dict["lpo"]["issueDate"],
                    Literal(iso_date, datatype=XSD.date),
                )
            )

            # ìœ„ì¹˜ ì¶”ê°€
            if item["location"]:
                g.add(
                    (
                        lpo_uri,
                        ns_dict["lpo"]["deliveryLocation"],
                        Literal(item["location"]),
                    )
                )

            # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ë° ì¶”ê°€
            category = categorize_lpo_item(item["description"])
            g.add((lpo_uri, ns_dict["lpo"]["category"], Literal(category)))

            # ê¸°ë³¸ ìƒíƒœ ì„¤ì •
            g.add((lpo_uri, ns_dict["lpo"]["status"], Literal("Issued")))
            g.add((lpo_uri, ns_dict["lpo"]["currency"], Literal("AED")))

            processed_lpos.add(lpo_number)

        # ê³µê¸‰ì—…ì²´ ì—”í‹°í‹° ìƒì„± (ì¤‘ë³µ ë°©ì§€)
        vendor_name = item["vendor"]
        if vendor_name not in processed_vendors:
            vendor_uri = create_vendor_uri(vendor_name, ns_dict)

            g.add((vendor_uri, RDF.type, ns_dict["org"]["Organization"]))
            g.add((vendor_uri, ns_dict["org"]["name"], Literal(vendor_name)))
            g.add((vendor_uri, RDFS.label, Literal(vendor_name)))

            processed_vendors.add(vendor_name)

        # ìœ„ì¹˜ ì—”í‹°í‹° ìƒì„± (ì¤‘ë³µ ë°©ì§€)
        location_name = item["location"]
        if location_name and location_name not in processed_locations:
            location_uri = create_location_uri(location_name, ns_dict)

            g.add((location_uri, RDF.type, ns_dict["abu"]["AbuDhabiLocation"]))
            g.add(
                (location_uri, ns_dict["abu"]["locationName"], Literal(location_name))
            )
            g.add((location_uri, RDFS.label, Literal(location_name)))

            processed_locations.add(location_name)

        # ê´€ê³„ ì„¤ì •
        lpo_uri = create_lpo_uri(lpo_number, ns_dict)
        vendor_uri = create_vendor_uri(vendor_name, ns_dict)

        # LPO â†’ Vendor ê´€ê³„
        g.add((lpo_uri, ns_dict["lpo"]["hasVendor"], vendor_uri))

        # LPO â†’ Location ê´€ê³„
        if location_name:
            location_uri = create_location_uri(location_name, ns_dict)
            g.add((lpo_uri, ns_dict["lpo"]["hasDeliveryLocation"], location_uri))

    return g


def save_rdf_graph(graph, output_file):
    """RDF ê·¸ë˜í”„ë¥¼ TTL íŒŒì¼ë¡œ ì €ì¥"""
    output_path = Path(output_file)
    output_path.parent.mkdir(exist_ok=True)

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(graph.serialize(format="turtle"))

    return output_path


def generate_processing_report(lpo_data, graph, output_file):
    """ì²˜ë¦¬ ë³´ê³ ì„œ ìƒì„±"""
    report = {
        "processing_timestamp": datetime.now().isoformat(),
        "input_statistics": {
            "total_lpo_entries": len(lpo_data),
            "unique_lpo_numbers": len(set(item["lpo_number"] for item in lpo_data)),
            "unique_vendors": len(set(item["vendor"] for item in lpo_data)),
            "unique_locations": len(
                set(item["location"] for item in lpo_data if item["location"])
            ),
        },
        "rdf_statistics": {
            "total_triples": len(graph),
            "lpo_entities": len(list(graph.subjects(RDF.type, None))),
            "namespaces_used": list(graph.namespaces()),
        },
        "output_file": str(output_file),
        "processing_status": "SUCCESS",
    }

    # ë³´ê³ ì„œ ì €ì¥
    report_file = Path("reports/lpo_processing_report.md")
    report_file.parent.mkdir(exist_ok=True)

    with open(report_file, "w", encoding="utf-8") as f:
        f.write(f"# LPO RDF ë³€í™˜ ë³´ê³ ì„œ\n\n")
        f.write(f"**ì²˜ë¦¬ ì‹œê°„**: {report['processing_timestamp']}\n\n")
        f.write(f"## ì…ë ¥ ë°ì´í„° í†µê³„\n")
        f.write(f"- ì´ LPO í•­ëª©: {report['input_statistics']['total_lpo_entries']}ê°œ\n")
        f.write(
            f"- ê³ ìœ  LPO ë²ˆí˜¸: {report['input_statistics']['unique_lpo_numbers']}ê°œ\n"
        )
        f.write(f"- ê³ ìœ  ê³µê¸‰ì—…ì²´: {report['input_statistics']['unique_vendors']}ê°œ\n")
        f.write(f"- ê³ ìœ  ìœ„ì¹˜: {report['input_statistics']['unique_locations']}ê°œ\n\n")
        f.write(f"## RDF ë³€í™˜ ê²°ê³¼\n")
        f.write(f"- ì´ íŠ¸ë¦¬í”Œ: {report['rdf_statistics']['total_triples']}ê°œ\n")
        f.write(f"- LPO ì—”í‹°í‹°: {report['rdf_statistics']['lpo_entities']}ê°œ\n")
        f.write(f"- ì¶œë ¥ íŒŒì¼: {report['output_file']}\n\n")
        f.write(f"## ì²˜ë¦¬ ìƒíƒœ: {report['processing_status']}\n")

    return report


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ”„ ABU LPO ë°ì´í„°ë¥¼ RDFë¡œ ë³€í™˜ ì‹œì‘...")

    # ì…ë ¥ íŒŒì¼ í™•ì¸
    lpo_analysis_file = Path("reports/abu_lpo_analysis.json")
    if not lpo_analysis_file.exists():
        print(
            "âŒ LPO ë¶„ì„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € analyze_lpo_data.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”."
        )
        return

    # LPO ë°ì´í„° ë¡œë“œ
    print("ğŸ“Š LPO ë¶„ì„ ë°ì´í„° ë¡œë“œ ì¤‘...")
    with open(lpo_analysis_file, "r", encoding="utf-8") as f:
        analysis_data = json.load(f)

    lpo_data = analysis_data["lpo_list"]
    print(f"âœ… {len(lpo_data)}ê°œì˜ LPO í•­ëª©ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")

    # ë§¤í•‘ ê·œì¹™ ë¡œë“œ
    print("ğŸ“‹ ë§¤í•‘ ê·œì¹™ ë¡œë“œ ì¤‘...")
    mapping_rules = load_mapping_rules()

    # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì„¤ì •
    print("ğŸ”— RDF ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì„¤ì • ì¤‘...")
    ns_dict = setup_namespaces()

    # RDF ë³€í™˜
    print("ğŸ”„ RDF ë³€í™˜ ì¤‘...")
    graph = process_lpo_data(lpo_data, mapping_rules, ns_dict)

    # ê²°ê³¼ ì €ì¥
    output_file = Path("output/abu_lpo_data.ttl")
    print(f"ğŸ’¾ RDF íŒŒì¼ ì €ì¥ ì¤‘: {output_file}")
    saved_path = save_rdf_graph(graph, output_file)

    # ì²˜ë¦¬ ë³´ê³ ì„œ ìƒì„±
    print("ğŸ“‹ ì²˜ë¦¬ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
    report = generate_processing_report(lpo_data, graph, saved_path)

    print(f"âœ… LPO RDF ë³€í™˜ ì™„ë£Œ!")
    print(f"  - ì¶œë ¥ íŒŒì¼: {saved_path}")
    print(f"  - ì´ íŠ¸ë¦¬í”Œ: {len(graph)}ê°œ")
    print(f"  - LPO ì—”í‹°í‹°: {len(list(graph.subjects(RDF.type, None)))}ê°œ")
    print(f"  - ë³´ê³ ì„œ: reports/lpo_processing_report.md")


if __name__ == "__main__":
    main()
